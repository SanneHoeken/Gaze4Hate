{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook does the followings:\n",
    "### + read sentence csv file, tokenize the assertions \n",
    "### + create list of tokens, word lenght and word frequency lists (based on wordnet) exported as orig_df.to_csv('processed_data/processed_sentences_tokenize_cloze_etc.csv')\n",
    "### + also calculates cloze probabilities, entropy etc.  based on GPT-2  exported to processed_data/gpt_cloze_probabilities.csv', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_837306/2145724294.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#orig_sentence_file = \"exported_data/sentences_All-in-one_01Feb23.xlsx\"\n",
    "orig_sentence_file = \"exported_data/sentences_23Jan24.xlsx\"\n",
    "\n",
    "orig_df = pd.read_excel(open(orig_sentence_file, 'rb'), sheet_name='stimuli') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sno</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Cond_remark</th>\n",
       "      <th>ID</th>\n",
       "      <th>orig_ID</th>\n",
       "      <th>Ling_type</th>\n",
       "      <th>Comp</th>\n",
       "      <th>remarks_2</th>\n",
       "      <th>remarks_1</th>\n",
       "      <th>processed_assertion</th>\n",
       "      <th>mw_mark</th>\n",
       "      <th>H_P_mw</th>\n",
       "      <th>H_N_mw</th>\n",
       "      <th>change_remark</th>\n",
       "      <th>image_name</th>\n",
       "      <th>aoi_name</th>\n",
       "      <th>overlay_name</th>\n",
       "      <th>Check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>hate_w_high</td>\n",
       "      <td>27</td>\n",
       "      <td>140</td>\n",
       "      <td>lexical</td>\n",
       "      <td>1.0</td>\n",
       "      <td>comp</td>\n",
       "      <td>HighHateLowDiff</td>\n",
       "      <td>Frauen haben einen signifikant geringeren Durc...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[5,6]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>no_change</td>\n",
       "      <td>img_1.png</td>\n",
       "      <td>img_1.ias</td>\n",
       "      <td>img_overlay_1.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>hate_w_high</td>\n",
       "      <td>26</td>\n",
       "      <td>196</td>\n",
       "      <td>lexical</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>HighHateLowDiff</td>\n",
       "      <td>Frauen sind psychisch nicht für komplexe Arbei...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>no_change</td>\n",
       "      <td>img_2.png</td>\n",
       "      <td>img_2.ias</td>\n",
       "      <td>img_overlay_2.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>hate_w_high</td>\n",
       "      <td>16</td>\n",
       "      <td>144</td>\n",
       "      <td>lexical</td>\n",
       "      <td>1.0</td>\n",
       "      <td>comp</td>\n",
       "      <td>HighHateLowDiff</td>\n",
       "      <td>Frauen haben im statistischen Mittel ein klein...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[7,8]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>no_change</td>\n",
       "      <td>img_3.png</td>\n",
       "      <td>img_3.ias</td>\n",
       "      <td>img_overlay_3.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>hate_w_high</td>\n",
       "      <td>14</td>\n",
       "      <td>233</td>\n",
       "      <td>lexical</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>HighHateLowDiff</td>\n",
       "      <td>Frauenförderung hat fast nur Nachteile für die...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>no_change</td>\n",
       "      <td>img_4.png</td>\n",
       "      <td>img_4.ias</td>\n",
       "      <td>img_overlay_4.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>hate_w_high</td>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>lexical</td>\n",
       "      <td>1.0</td>\n",
       "      <td>comp</td>\n",
       "      <td>HighHateLowDiff</td>\n",
       "      <td>Frauen sind im Durchschnitt dümmer als Männer.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[1,7]</td>\n",
       "      <td>no_change</td>\n",
       "      <td>img_5.png</td>\n",
       "      <td>img_5.ias</td>\n",
       "      <td>img_overlay_5.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sno  Condition  Cond_remark  ID orig_ID Ling_type  Comp remarks_2  \\\n",
       "0    1          1  hate_w_high  27     140   lexical   1.0      comp   \n",
       "1    2          1  hate_w_high  26     196   lexical   0.0     derog   \n",
       "2    3          1  hate_w_high  16     144   lexical   1.0      comp   \n",
       "3    4          1  hate_w_high  14     233   lexical   0.0     derog   \n",
       "4    5          1  hate_w_high   2     175   lexical   1.0      comp   \n",
       "\n",
       "         remarks_1                                processed_assertion  \\\n",
       "0  HighHateLowDiff  Frauen haben einen signifikant geringeren Durc...   \n",
       "1  HighHateLowDiff  Frauen sind psychisch nicht für komplexe Arbei...   \n",
       "2  HighHateLowDiff  Frauen haben im statistischen Mittel ein klein...   \n",
       "3  HighHateLowDiff  Frauenförderung hat fast nur Nachteile für die...   \n",
       "4  HighHateLowDiff     Frauen sind im Durchschnitt dümmer als Männer.   \n",
       "\n",
       "   mw_mark H_P_mw H_N_mw change_remark image_name   aoi_name  \\\n",
       "0      0.0  [5,6]    [1]     no_change  img_1.png  img_1.ias   \n",
       "1      1.0    [4]    [1]     no_change  img_2.png  img_2.ias   \n",
       "2      1.0  [7,8]    [1]     no_change  img_3.png  img_3.ias   \n",
       "3      0.0    [5]    [1]     no_change  img_4.png  img_4.ias   \n",
       "4      0.0    [5]  [1,7]     no_change  img_5.png  img_5.ias   \n",
       "\n",
       "        overlay_name  Check  \n",
       "0  img_overlay_1.bmp      1  \n",
       "1  img_overlay_2.bmp      1  \n",
       "2  img_overlay_3.bmp      1  \n",
       "3  img_overlay_4.bmp      1  \n",
       "4  img_overlay_5.bmp      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sno</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Cond_remark</th>\n",
       "      <th>ID</th>\n",
       "      <th>orig_ID</th>\n",
       "      <th>Ling_type</th>\n",
       "      <th>Comp</th>\n",
       "      <th>remarks_2</th>\n",
       "      <th>remarks_1</th>\n",
       "      <th>processed_assertion</th>\n",
       "      <th>mw_mark</th>\n",
       "      <th>H_P_mw</th>\n",
       "      <th>H_N_mw</th>\n",
       "      <th>change_remark</th>\n",
       "      <th>image_name</th>\n",
       "      <th>aoi_name</th>\n",
       "      <th>overlay_name</th>\n",
       "      <th>Check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>hate_m</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>lexical</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>generated</td>\n",
       "      <td>Männer sind nicht die hellsten.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>generated</td>\n",
       "      <td>img_46.png</td>\n",
       "      <td>img_46.ias</td>\n",
       "      <td>img_overlay_46.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "      <td>hate_m</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>social</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>HighHateLowDiff</td>\n",
       "      <td>Der Mann verprasst das Geld.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>generated</td>\n",
       "      <td>img_47.png</td>\n",
       "      <td>img_47.ias</td>\n",
       "      <td>img_overlay_47.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>hate_m</td>\n",
       "      <td>1</td>\n",
       "      <td>503</td>\n",
       "      <td>social</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>generated</td>\n",
       "      <td>Männer gehören auf den Bau.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 5]</td>\n",
       "      <td>[1,5]</td>\n",
       "      <td>generated</td>\n",
       "      <td>img_48.png</td>\n",
       "      <td>img_48.ias</td>\n",
       "      <td>img_overlay_48.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>hate_m</td>\n",
       "      <td>504</td>\n",
       "      <td>504</td>\n",
       "      <td>social</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>generated</td>\n",
       "      <td>Männer sind bei Stellenvergaben privilegiert.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>generated</td>\n",
       "      <td>img_49.png</td>\n",
       "      <td>img_49.ias</td>\n",
       "      <td>img_overlay_49.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>hate_m</td>\n",
       "      <td>505</td>\n",
       "      <td>505</td>\n",
       "      <td>social</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>generated</td>\n",
       "      <td>Männer verbingen wenig Zeit mit ihren Kindern.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>generated</td>\n",
       "      <td>img_50.png</td>\n",
       "      <td>img_50.ias</td>\n",
       "      <td>img_overlay_50.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>hate_m</td>\n",
       "      <td>506</td>\n",
       "      <td>506</td>\n",
       "      <td>social</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>generated</td>\n",
       "      <td>Alle Männer sind ausgewachsene Kinder.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>generated</td>\n",
       "      <td>img_51.png</td>\n",
       "      <td>img_51.ias</td>\n",
       "      <td>img_overlay_51.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral_w</td>\n",
       "      <td>27</td>\n",
       "      <td>140</td>\n",
       "      <td>lexical</td>\n",
       "      <td>1.0</td>\n",
       "      <td>comp</td>\n",
       "      <td>HighHateLowDiff-Neutral</td>\n",
       "      <td>Pokemons haben einen signifikant geringeren Du...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>subject</td>\n",
       "      <td>img_52.png</td>\n",
       "      <td>img_52.ias</td>\n",
       "      <td>img_overlay_52.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral_w</td>\n",
       "      <td>26</td>\n",
       "      <td>196</td>\n",
       "      <td>lexical</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dep</td>\n",
       "      <td>HighHateLowDiff-Neutral</td>\n",
       "      <td>Kinder sind psychisch nicht für komplexe Arbei...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>subject</td>\n",
       "      <td>img_53.png</td>\n",
       "      <td>img_53.ias</td>\n",
       "      <td>img_overlay_53.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral_w</td>\n",
       "      <td>16</td>\n",
       "      <td>144</td>\n",
       "      <td>lexical</td>\n",
       "      <td>1.0</td>\n",
       "      <td>comp</td>\n",
       "      <td>HighHateLowDiff-Neutral</td>\n",
       "      <td>Kinder haben im statistischen Mittel ein klein...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>subject</td>\n",
       "      <td>img_54.png</td>\n",
       "      <td>img_54.ias</td>\n",
       "      <td>img_overlay_54.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral_w</td>\n",
       "      <td>14</td>\n",
       "      <td>233</td>\n",
       "      <td>lexical</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>HighHateLowDiff-Neutral</td>\n",
       "      <td>Egoismus hat fast nur Nachteile für die Gesell...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Subject</td>\n",
       "      <td>img_55.png</td>\n",
       "      <td>img_55.ias</td>\n",
       "      <td>img_overlay_55.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral_w</td>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>lexical</td>\n",
       "      <td>1.0</td>\n",
       "      <td>comp</td>\n",
       "      <td>HighHateLowDiff-Neutral</td>\n",
       "      <td>Fische sind im Durchschnitt dümmer als Oktopusse.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[1,7]</td>\n",
       "      <td>subject object</td>\n",
       "      <td>img_56.png</td>\n",
       "      <td>img_56.ias</td>\n",
       "      <td>img_overlay_56.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral_w</td>\n",
       "      <td>11</td>\n",
       "      <td>191</td>\n",
       "      <td>lexical</td>\n",
       "      <td>1.0</td>\n",
       "      <td>comp</td>\n",
       "      <td>HighHateLowDiff-Neutral</td>\n",
       "      <td>Hunde sind Menschen geistig in einigen Bereich...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[1,3]</td>\n",
       "      <td>subject object</td>\n",
       "      <td>img_57.png</td>\n",
       "      <td>img_57.ias</td>\n",
       "      <td>img_overlay_57.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral_w</td>\n",
       "      <td>3</td>\n",
       "      <td>192</td>\n",
       "      <td>lexical</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>HighHateLowDiff-Neutral</td>\n",
       "      <td>Kricketteams  sind Minderleister in unseren Kn...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[1,6]</td>\n",
       "      <td>subject</td>\n",
       "      <td>img_58.png</td>\n",
       "      <td>img_58.ias</td>\n",
       "      <td>img_overlay_58.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral_w</td>\n",
       "      <td>5</td>\n",
       "      <td>159</td>\n",
       "      <td>lexical</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>HighHateLowDiff-Neutral</td>\n",
       "      <td>Minions können nichts und sind zu dumm.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>subject</td>\n",
       "      <td>img_59.png</td>\n",
       "      <td>img_59.ias</td>\n",
       "      <td>img_overlay_59.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral_w</td>\n",
       "      <td>25</td>\n",
       "      <td>172</td>\n",
       "      <td>lexical</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>HighHateLowDiff-Neutral</td>\n",
       "      <td>Regen ruiniert oft den größten Spaß.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>subject</td>\n",
       "      <td>img_60.png</td>\n",
       "      <td>img_60.ias</td>\n",
       "      <td>img_overlay_60.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral_w</td>\n",
       "      <td>31</td>\n",
       "      <td>44</td>\n",
       "      <td>lexical</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>HighHateLowDiff-Neutral</td>\n",
       "      <td>Die #keinurlaub-Bewegung ist hysterisch.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>subject</td>\n",
       "      <td>img_61.png</td>\n",
       "      <td>img_61.ias</td>\n",
       "      <td>img_overlay_61.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral_w</td>\n",
       "      <td>20</td>\n",
       "      <td>362</td>\n",
       "      <td>social</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>HighHateLowDiff-Neutral</td>\n",
       "      <td>Babysitter sollten zu Hause bleiben und sich u...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>subject</td>\n",
       "      <td>img_62.png</td>\n",
       "      <td>img_62.ias</td>\n",
       "      <td>img_overlay_62.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral_w</td>\n",
       "      <td>29</td>\n",
       "      <td>120</td>\n",
       "      <td>social</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>HighHateLowDiff-Neutral</td>\n",
       "      <td>Wissenschaftler sind überwiegend angetrieben d...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[1,6]</td>\n",
       "      <td>subject mod</td>\n",
       "      <td>img_64.png</td>\n",
       "      <td>img_64.ias</td>\n",
       "      <td>img_overlay_64.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral_w</td>\n",
       "      <td>30</td>\n",
       "      <td>128</td>\n",
       "      <td>social</td>\n",
       "      <td>1.0</td>\n",
       "      <td>comp</td>\n",
       "      <td>HighHateLowDiff-Neutral</td>\n",
       "      <td>Programme altern wie Milch, Programmierer alte...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[1,6]</td>\n",
       "      <td>subject subject</td>\n",
       "      <td>img_65.png</td>\n",
       "      <td>img_65.ias</td>\n",
       "      <td>img_overlay_65.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral_w</td>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>social</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dep</td>\n",
       "      <td>HighHateLowDiff-Neutral</td>\n",
       "      <td>Ein gesundes Sexualleben in der Ehe ist zu bev...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[2,3]</td>\n",
       "      <td>subject</td>\n",
       "      <td>img_66.png</td>\n",
       "      <td>img_66.ias</td>\n",
       "      <td>img_overlay_66.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral_w</td>\n",
       "      <td>18</td>\n",
       "      <td>146</td>\n",
       "      <td>social</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dep</td>\n",
       "      <td>HighHateLowDiff-Neutral</td>\n",
       "      <td>Nachteulen  sind für bestimmte Berufe nicht ge...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>subject</td>\n",
       "      <td>img_67.png</td>\n",
       "      <td>img_67.ias</td>\n",
       "      <td>img_overlay_67.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral_w</td>\n",
       "      <td>28</td>\n",
       "      <td>273</td>\n",
       "      <td>social</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>HighHateLowDiff-Neutral</td>\n",
       "      <td>Gleichstellung der Geschlechter findet zunehme...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[4,5,6,7]</td>\n",
       "      <td>subject</td>\n",
       "      <td>img_68.png</td>\n",
       "      <td>img_68.ias</td>\n",
       "      <td>img_overlay_68.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral_w</td>\n",
       "      <td>32</td>\n",
       "      <td>152</td>\n",
       "      <td>social</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>HighHateLowDiff-Neutral</td>\n",
       "      <td>Menschen in führenden Positionen haben häufig ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[1,8]</td>\n",
       "      <td>subject</td>\n",
       "      <td>img_69.png</td>\n",
       "      <td>img_69.ias</td>\n",
       "      <td>img_overlay_69.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral_w</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>social</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>HighHateLowDiff-Neutral</td>\n",
       "      <td>Töpfe gehören in die Küche.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>subject</td>\n",
       "      <td>img_70.png</td>\n",
       "      <td>img_70.ias</td>\n",
       "      <td>img_overlay_70.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>71</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral_w</td>\n",
       "      <td>12</td>\n",
       "      <td>208</td>\n",
       "      <td>social</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>HighHateLowDiff-Neutral</td>\n",
       "      <td>Hühner sollten ihre klassische Gluckenrolle au...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>subject object</td>\n",
       "      <td>img_71.png</td>\n",
       "      <td>img_71.ias</td>\n",
       "      <td>img_overlay_71.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral_w</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>social</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dep</td>\n",
       "      <td>HighHateLowDiff-Neutral</td>\n",
       "      <td>Alles was ein Film tun muss, ist seine Zuschau...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[4,9]</td>\n",
       "      <td>subject object</td>\n",
       "      <td>img_72.png</td>\n",
       "      <td>img_72.ias</td>\n",
       "      <td>img_overlay_72.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "      <td>pos_w</td>\n",
       "      <td>27</td>\n",
       "      <td>140</td>\n",
       "      <td>lexical</td>\n",
       "      <td>1.0</td>\n",
       "      <td>comp</td>\n",
       "      <td>HighHateLowDiff-Positive</td>\n",
       "      <td>Frauen haben einen signifikant höre Schmerztol...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[5,6]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>object</td>\n",
       "      <td>img_73.png</td>\n",
       "      <td>img_73.ias</td>\n",
       "      <td>img_overlay_73.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>pos_w</td>\n",
       "      <td>26</td>\n",
       "      <td>196</td>\n",
       "      <td>lexical</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dep</td>\n",
       "      <td>HighHateLowDiff-Positive</td>\n",
       "      <td>Frauen sind psychisch für komplexe Arbeit gesc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>object</td>\n",
       "      <td>img_74.png</td>\n",
       "      <td>img_74.ias</td>\n",
       "      <td>img_overlay_74.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>pos_w</td>\n",
       "      <td>16</td>\n",
       "      <td>144</td>\n",
       "      <td>lexical</td>\n",
       "      <td>1.0</td>\n",
       "      <td>comp</td>\n",
       "      <td>HighHateLowDiff-Positive</td>\n",
       "      <td>Frauen haben im statistischen Mittel in einen ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[8,9]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>object</td>\n",
       "      <td>img_75.png</td>\n",
       "      <td>img_75.ias</td>\n",
       "      <td>img_overlay_75.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>pos_w</td>\n",
       "      <td>14</td>\n",
       "      <td>233</td>\n",
       "      <td>lexical</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>HighHateLowDiff-Positive</td>\n",
       "      <td>Frauenförderung hat fast nur Vorteile für die ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>object</td>\n",
       "      <td>img_76.png</td>\n",
       "      <td>img_76.ias</td>\n",
       "      <td>img_overlay_76.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "      <td>pos_w</td>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>lexical</td>\n",
       "      <td>1.0</td>\n",
       "      <td>comp</td>\n",
       "      <td>HighHateLowDiff-Positive</td>\n",
       "      <td>Frauen sind im Durchschnitt sozialer als Männer.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>img_77.png</td>\n",
       "      <td>img_77.ias</td>\n",
       "      <td>img_overlay_77.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "      <td>pos_w</td>\n",
       "      <td>11</td>\n",
       "      <td>191</td>\n",
       "      <td>lexical</td>\n",
       "      <td>1.0</td>\n",
       "      <td>comp</td>\n",
       "      <td>HighHateLowDiff-Positive</td>\n",
       "      <td>Frauen sind Männern im Erinnerungsvermögen übe...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>Mod</td>\n",
       "      <td>img_78.png</td>\n",
       "      <td>img_78.ias</td>\n",
       "      <td>img_overlay_78.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>79</td>\n",
       "      <td>3</td>\n",
       "      <td>pos_w</td>\n",
       "      <td>3</td>\n",
       "      <td>192</td>\n",
       "      <td>lexical</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>HighHateLowDiff-Positive</td>\n",
       "      <td>Frauen sind Säulen in unserer Gesellschaft.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>object</td>\n",
       "      <td>img_79.png</td>\n",
       "      <td>img_79.ias</td>\n",
       "      <td>img_overlay_79.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>pos_w</td>\n",
       "      <td>5</td>\n",
       "      <td>159</td>\n",
       "      <td>lexical</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>HighHateLowDiff-Positive</td>\n",
       "      <td>Frauen können alles und sind sehr kreativ.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[3,6,7]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>img_80.png</td>\n",
       "      <td>img_80.ias</td>\n",
       "      <td>img_overlay_80.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>pos_w</td>\n",
       "      <td>25</td>\n",
       "      <td>172</td>\n",
       "      <td>lexical</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>HighHateLowDiff-Positive</td>\n",
       "      <td>Frauen schaffen oft den größten Spaß.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>Verb</td>\n",
       "      <td>img_81.png</td>\n",
       "      <td>img_81.ias</td>\n",
       "      <td>img_overlay_81.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>pos_w</td>\n",
       "      <td>31</td>\n",
       "      <td>44</td>\n",
       "      <td>lexical</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>HighHateLowDiff-Positive</td>\n",
       "      <td>Die #metoo-Bewegung ist wirkmächtig.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>img_82.png</td>\n",
       "      <td>img_82.ias</td>\n",
       "      <td>img_overlay_82.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>pos_w</td>\n",
       "      <td>20</td>\n",
       "      <td>362</td>\n",
       "      <td>social</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>HighHateLowDiff-Positive</td>\n",
       "      <td>Frauen sollten nicht zu Hause bleiben und sich...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3,10,11]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>img_83.png</td>\n",
       "      <td>img_83.ias</td>\n",
       "      <td>img_overlay_83.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>85</td>\n",
       "      <td>3</td>\n",
       "      <td>pos_w</td>\n",
       "      <td>29</td>\n",
       "      <td>120</td>\n",
       "      <td>social</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>HighHateLowDiff-Positive</td>\n",
       "      <td>Feministen sind überwiegend angetrieben durch ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>object</td>\n",
       "      <td>img_85.png</td>\n",
       "      <td>img_85.ias</td>\n",
       "      <td>img_overlay_85.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "      <td>pos_w</td>\n",
       "      <td>30</td>\n",
       "      <td>128</td>\n",
       "      <td>social</td>\n",
       "      <td>1.0</td>\n",
       "      <td>comp</td>\n",
       "      <td>HighHateLowDiff-Positive</td>\n",
       "      <td>Gerüchte  altern wie Milch, Frauen altern wie ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1,6]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>elision object</td>\n",
       "      <td>img_86.png</td>\n",
       "      <td>img_86.ias</td>\n",
       "      <td>img_overlay_86.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>pos_w</td>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>social</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dep</td>\n",
       "      <td>HighHateLowDiff-Positive</td>\n",
       "      <td>Eine moderne Rollenverteilung in der Ehe ist z...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>verb</td>\n",
       "      <td>img_87.png</td>\n",
       "      <td>img_87.ias</td>\n",
       "      <td>img_overlay_87.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>88</td>\n",
       "      <td>3</td>\n",
       "      <td>pos_w</td>\n",
       "      <td>18</td>\n",
       "      <td>146</td>\n",
       "      <td>social</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dep</td>\n",
       "      <td>HighHateLowDiff-Positive</td>\n",
       "      <td>Frauen sind für alle Berufe gut geeignet.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4, 6]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>object</td>\n",
       "      <td>img_88.png</td>\n",
       "      <td>img_88.ias</td>\n",
       "      <td>img_overlay_88.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>89</td>\n",
       "      <td>3</td>\n",
       "      <td>pos_w</td>\n",
       "      <td>28</td>\n",
       "      <td>273</td>\n",
       "      <td>social</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>HighHateLowDiff-Positive</td>\n",
       "      <td>Gleichstellung der Geschlechter ist ein Traum ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[6,7,8,9]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>object</td>\n",
       "      <td>img_89.png</td>\n",
       "      <td>img_89.ias</td>\n",
       "      <td>img_overlay_89.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>pos_w</td>\n",
       "      <td>32</td>\n",
       "      <td>152</td>\n",
       "      <td>social</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>HighHateLowDiff-Positive</td>\n",
       "      <td>Frauen in führenden Positionen haben häufig st...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>img_90.png</td>\n",
       "      <td>img_90.ias</td>\n",
       "      <td>img_overlay_90.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>91</td>\n",
       "      <td>3</td>\n",
       "      <td>pos_w</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>social</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>HighHateLowDiff-Positive</td>\n",
       "      <td>Frauen gehören in die Regierung.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>object</td>\n",
       "      <td>img_91.png</td>\n",
       "      <td>img_91.ias</td>\n",
       "      <td>img_overlay_91.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>pos_w</td>\n",
       "      <td>12</td>\n",
       "      <td>208</td>\n",
       "      <td>social</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>HighHateLowDiff-Positive</td>\n",
       "      <td>Frauen sollten ihren Traumberuf ausüben.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>img_92.png</td>\n",
       "      <td>img_92.ias</td>\n",
       "      <td>img_overlay_92.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>pos_w</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>social</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dep</td>\n",
       "      <td>HighHateLowDiff-Positive</td>\n",
       "      <td>Alles was eine Frau tun muss, ist ihre Wünsche...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>img_93.png</td>\n",
       "      <td>img_93.ias</td>\n",
       "      <td>img_overlay_93.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>fam</td>\n",
       "      <td>fam1</td>\n",
       "      <td>fam1</td>\n",
       "      <td>fam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HighHateLowDiff</td>\n",
       "      <td>Männer sind im Schnitt biologisch intelligenter.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>img_94.png</td>\n",
       "      <td>img_94.ias</td>\n",
       "      <td>img_overlay_94.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>fam</td>\n",
       "      <td>fam2</td>\n",
       "      <td>fam2</td>\n",
       "      <td>fam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "      <td>Alle Feministinnen sind Helden.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>img_95.png</td>\n",
       "      <td>img_95.ias</td>\n",
       "      <td>img_overlay_95.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>fam</td>\n",
       "      <td>fam3</td>\n",
       "      <td>fam3</td>\n",
       "      <td>fam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Ab und zu eine erzieherische Ohrfeige hat noch...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>img_96.png</td>\n",
       "      <td>img_96.ias</td>\n",
       "      <td>img_overlay_96.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>fam</td>\n",
       "      <td>fam4</td>\n",
       "      <td>fam4</td>\n",
       "      <td>fam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HighHateLowDiff</td>\n",
       "      <td>Der aktuelle Drang zur Emanzipation schlägt te...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>img_97.png</td>\n",
       "      <td>img_97.ias</td>\n",
       "      <td>img_overlay_97.bmp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sno  Condition Cond_remark    ID orig_ID Ling_type  Comp remarks_2  \\\n",
       "44   46          6      hate_m   502     502   lexical   0.0     other   \n",
       "45   47          6      hate_m    37      37    social   0.0     other   \n",
       "46   48          6      hate_m     1     503    social   0.0     other   \n",
       "47   49          6      hate_m   504     504    social   0.0     other   \n",
       "48   50          6      hate_m   505     505    social   0.0     other   \n",
       "49   51          6      hate_m   506     506    social   0.0     derog   \n",
       "50   52          2   neutral_w    27     140   lexical   1.0      comp   \n",
       "51   53          2   neutral_w    26     196   lexical   0.0       dep   \n",
       "52   54          2   neutral_w    16     144   lexical   1.0      comp   \n",
       "53   55          2   neutral_w    14     233   lexical   0.0     derog   \n",
       "54   56          2   neutral_w     2     175   lexical   1.0      comp   \n",
       "55   57          2   neutral_w    11     191   lexical   1.0      comp   \n",
       "56   58          2   neutral_w     3     192   lexical   0.0     derog   \n",
       "57   59          2   neutral_w     5     159   lexical   0.0     derog   \n",
       "58   60          2   neutral_w    25     172   lexical   0.0     derog   \n",
       "59   61          2   neutral_w    31      44   lexical   0.0     derog   \n",
       "60   62          2   neutral_w    20     362    social   0.0     derog   \n",
       "61   64          2   neutral_w    29     120    social   0.0     derog   \n",
       "62   65          2   neutral_w    30     128    social   1.0      comp   \n",
       "63   66          2   neutral_w     4      82    social   0.0       dep   \n",
       "64   67          2   neutral_w    18     146    social   0.0       dep   \n",
       "65   68          2   neutral_w    28     273    social   0.0     derog   \n",
       "66   69          2   neutral_w    32     152    social   0.0     derog   \n",
       "67   70          2   neutral_w     1     135    social   0.0     derog   \n",
       "68   71          2   neutral_w    12     208    social   0.0     derog   \n",
       "69   72          2   neutral_w     7       7    social   0.0       dep   \n",
       "70   73          3       pos_w    27     140   lexical   1.0      comp   \n",
       "71   74          3       pos_w    26     196   lexical   0.0       dep   \n",
       "72   75          3       pos_w    16     144   lexical   1.0      comp   \n",
       "73   76          3       pos_w    14     233   lexical   0.0     derog   \n",
       "74   77          3       pos_w     2     175   lexical   1.0      comp   \n",
       "75   78          3       pos_w    11     191   lexical   1.0      comp   \n",
       "76   79          3       pos_w     3     192   lexical   0.0     derog   \n",
       "77   80          3       pos_w     5     159   lexical   0.0     derog   \n",
       "78   81          3       pos_w    25     172   lexical   0.0     derog   \n",
       "79   82          3       pos_w    31      44   lexical   0.0     derog   \n",
       "80   83          3       pos_w    20     362    social   0.0     derog   \n",
       "81   85          3       pos_w    29     120    social   0.0     derog   \n",
       "82   86          3       pos_w    30     128    social   1.0      comp   \n",
       "83   87          3       pos_w     4      82    social   0.0       dep   \n",
       "84   88          3       pos_w    18     146    social   0.0       dep   \n",
       "85   89          3       pos_w    28     273    social   0.0     derog   \n",
       "86   90          3       pos_w    32     152    social   0.0     derog   \n",
       "87   91          3       pos_w     1     135    social   0.0     derog   \n",
       "88   92          3       pos_w    12     208    social   0.0     derog   \n",
       "89   93          3       pos_w     7       7    social   0.0       dep   \n",
       "90   94          0         fam  fam1    fam1       fam   NaN       NaN   \n",
       "91   95          0         fam  fam2    fam2       fam   NaN       NaN   \n",
       "92   96          0         fam  fam3    fam3       fam   NaN       NaN   \n",
       "93   97          0         fam  fam4    fam4       fam   NaN       NaN   \n",
       "\n",
       "                   remarks_1  \\\n",
       "44                 generated   \n",
       "45           HighHateLowDiff   \n",
       "46                 generated   \n",
       "47                 generated   \n",
       "48                 generated   \n",
       "49                 generated   \n",
       "50   HighHateLowDiff-Neutral   \n",
       "51   HighHateLowDiff-Neutral   \n",
       "52   HighHateLowDiff-Neutral   \n",
       "53   HighHateLowDiff-Neutral   \n",
       "54   HighHateLowDiff-Neutral   \n",
       "55   HighHateLowDiff-Neutral   \n",
       "56   HighHateLowDiff-Neutral   \n",
       "57   HighHateLowDiff-Neutral   \n",
       "58   HighHateLowDiff-Neutral   \n",
       "59   HighHateLowDiff-Neutral   \n",
       "60   HighHateLowDiff-Neutral   \n",
       "61   HighHateLowDiff-Neutral   \n",
       "62   HighHateLowDiff-Neutral   \n",
       "63   HighHateLowDiff-Neutral   \n",
       "64   HighHateLowDiff-Neutral   \n",
       "65   HighHateLowDiff-Neutral   \n",
       "66   HighHateLowDiff-Neutral   \n",
       "67   HighHateLowDiff-Neutral   \n",
       "68   HighHateLowDiff-Neutral   \n",
       "69   HighHateLowDiff-Neutral   \n",
       "70  HighHateLowDiff-Positive   \n",
       "71  HighHateLowDiff-Positive   \n",
       "72  HighHateLowDiff-Positive   \n",
       "73  HighHateLowDiff-Positive   \n",
       "74  HighHateLowDiff-Positive   \n",
       "75  HighHateLowDiff-Positive   \n",
       "76  HighHateLowDiff-Positive   \n",
       "77  HighHateLowDiff-Positive   \n",
       "78  HighHateLowDiff-Positive   \n",
       "79  HighHateLowDiff-Positive   \n",
       "80  HighHateLowDiff-Positive   \n",
       "81  HighHateLowDiff-Positive   \n",
       "82  HighHateLowDiff-Positive   \n",
       "83  HighHateLowDiff-Positive   \n",
       "84  HighHateLowDiff-Positive   \n",
       "85  HighHateLowDiff-Positive   \n",
       "86  HighHateLowDiff-Positive   \n",
       "87  HighHateLowDiff-Positive   \n",
       "88  HighHateLowDiff-Positive   \n",
       "89  HighHateLowDiff-Positive   \n",
       "90           HighHateLowDiff   \n",
       "91                  positive   \n",
       "92                   neutral   \n",
       "93           HighHateLowDiff   \n",
       "\n",
       "                                  processed_assertion  mw_mark     H_P_mw  \\\n",
       "44                    Männer sind nicht die hellsten.      2.0       [99]   \n",
       "45                       Der Mann verprasst das Geld.      2.0       [99]   \n",
       "46                        Männer gehören auf den Bau.      NaN     [1, 5]   \n",
       "47      Männer sind bei Stellenvergaben privilegiert.      2.0       [99]   \n",
       "48     Männer verbingen wenig Zeit mit ihren Kindern.      2.0       [99]   \n",
       "49             Alle Männer sind ausgewachsene Kinder.      2.0       [99]   \n",
       "50  Pokemons haben einen signifikant geringeren Du...      0.0       [99]   \n",
       "51  Kinder sind psychisch nicht für komplexe Arbei...      1.0       [99]   \n",
       "52  Kinder haben im statistischen Mittel ein klein...      1.0       [99]   \n",
       "53  Egoismus hat fast nur Nachteile für die Gesell...      0.0       [99]   \n",
       "54  Fische sind im Durchschnitt dümmer als Oktopusse.      0.0       [99]   \n",
       "55  Hunde sind Menschen geistig in einigen Bereich...      1.0       [99]   \n",
       "56  Kricketteams  sind Minderleister in unseren Kn...      0.0       [99]   \n",
       "57            Minions können nichts und sind zu dumm.      0.0       [99]   \n",
       "58               Regen ruiniert oft den größten Spaß.      0.0       [99]   \n",
       "59           Die #keinurlaub-Bewegung ist hysterisch.      0.0       [99]   \n",
       "60  Babysitter sollten zu Hause bleiben und sich u...      1.0       [99]   \n",
       "61  Wissenschaftler sind überwiegend angetrieben d...      0.0       [99]   \n",
       "62  Programme altern wie Milch, Programmierer alte...      0.0       [99]   \n",
       "63  Ein gesundes Sexualleben in der Ehe ist zu bev...      0.0       [99]   \n",
       "64  Nachteulen  sind für bestimmte Berufe nicht ge...      1.0       [99]   \n",
       "65  Gleichstellung der Geschlechter findet zunehme...      1.0       [99]   \n",
       "66  Menschen in führenden Positionen haben häufig ...      0.0       [99]   \n",
       "67                        Töpfe gehören in die Küche.      0.0       [99]   \n",
       "68  Hühner sollten ihre klassische Gluckenrolle au...      1.0       [99]   \n",
       "69  Alles was ein Film tun muss, ist seine Zuschau...      0.0       [99]   \n",
       "70  Frauen haben einen signifikant höre Schmerztol...      0.0      [5,6]   \n",
       "71  Frauen sind psychisch für komplexe Arbeit gesc...      1.0         []   \n",
       "72  Frauen haben im statistischen Mittel in einen ...      1.0      [8,9]   \n",
       "73  Frauenförderung hat fast nur Vorteile für die ...      0.0        [5]   \n",
       "74   Frauen sind im Durchschnitt sozialer als Männer.      0.0        [5]   \n",
       "75  Frauen sind Männern im Erinnerungsvermögen übe...      1.0        [5]   \n",
       "76        Frauen sind Säulen in unserer Gesellschaft.      0.0        [3]   \n",
       "77         Frauen können alles und sind sehr kreativ.      0.0    [3,6,7]   \n",
       "78              Frauen schaffen oft den größten Spaß.      0.0        [2]   \n",
       "79               Die #metoo-Bewegung ist wirkmächtig.      0.0        [5]   \n",
       "80  Frauen sollten nicht zu Hause bleiben und sich...      1.0  [3,10,11]   \n",
       "81  Feministen sind überwiegend angetrieben durch ...      0.0        [6]   \n",
       "82  Gerüchte  altern wie Milch, Frauen altern wie ...      0.0      [1,6]   \n",
       "83  Eine moderne Rollenverteilung in der Ehe ist z...      0.0        [2]   \n",
       "84          Frauen sind für alle Berufe gut geeignet.      1.0     [4, 6]   \n",
       "85  Gleichstellung der Geschlechter ist ein Traum ...      1.0  [6,7,8,9]   \n",
       "86  Frauen in führenden Positionen haben häufig st...      0.0        [7]   \n",
       "87                   Frauen gehören in die Regierung.      0.0        [5]   \n",
       "88           Frauen sollten ihren Traumberuf ausüben.      1.0        [4]   \n",
       "89  Alles was eine Frau tun muss, ist ihre Wünsche...      0.0        [9]   \n",
       "90   Männer sind im Schnitt biologisch intelligenter.      2.0       [99]   \n",
       "91                    Alle Feministinnen sind Helden.      2.0       [99]   \n",
       "92  Ab und zu eine erzieherische Ohrfeige hat noch...      2.0       [99]   \n",
       "93  Der aktuelle Drang zur Emanzipation schlägt te...      2.0       [99]   \n",
       "\n",
       "       H_N_mw    change_remark  image_name    aoi_name        overlay_name  \\\n",
       "44       [99]        generated  img_46.png  img_46.ias  img_overlay_46.bmp   \n",
       "45       [99]        generated  img_47.png  img_47.ias  img_overlay_47.bmp   \n",
       "46      [1,5]        generated  img_48.png  img_48.ias  img_overlay_48.bmp   \n",
       "47       [99]        generated  img_49.png  img_49.ias  img_overlay_49.bmp   \n",
       "48       [99]        generated  img_50.png  img_50.ias  img_overlay_50.bmp   \n",
       "49       [99]        generated  img_51.png  img_51.ias  img_overlay_51.bmp   \n",
       "50        [1]          subject  img_52.png  img_52.ias  img_overlay_52.bmp   \n",
       "51        [1]          subject  img_53.png  img_53.ias  img_overlay_53.bmp   \n",
       "52        [1]          subject  img_54.png  img_54.ias  img_overlay_54.bmp   \n",
       "53        [1]         Subject   img_55.png  img_55.ias  img_overlay_55.bmp   \n",
       "54      [1,7]   subject object  img_56.png  img_56.ias  img_overlay_56.bmp   \n",
       "55      [1,3]   subject object  img_57.png  img_57.ias  img_overlay_57.bmp   \n",
       "56      [1,6]          subject  img_58.png  img_58.ias  img_overlay_58.bmp   \n",
       "57        [1]          subject  img_59.png  img_59.ias  img_overlay_59.bmp   \n",
       "58        [1]          subject  img_60.png  img_60.ias  img_overlay_60.bmp   \n",
       "59        [3]          subject  img_61.png  img_61.ias  img_overlay_61.bmp   \n",
       "60        [1]          subject  img_62.png  img_62.ias  img_overlay_62.bmp   \n",
       "61      [1,6]      subject mod  img_64.png  img_64.ias  img_overlay_64.bmp   \n",
       "62      [1,6]  subject subject  img_65.png  img_65.ias  img_overlay_65.bmp   \n",
       "63      [2,3]          subject  img_66.png  img_66.ias  img_overlay_66.bmp   \n",
       "64     [1, 4]          subject  img_67.png  img_67.ias  img_overlay_67.bmp   \n",
       "65  [4,5,6,7]          subject  img_68.png  img_68.ias  img_overlay_68.bmp   \n",
       "66      [1,8]          subject  img_69.png  img_69.ias  img_overlay_69.bmp   \n",
       "67        [1]          subject  img_70.png  img_70.ias  img_overlay_70.bmp   \n",
       "68        [5]   subject object  img_71.png  img_71.ias  img_overlay_71.bmp   \n",
       "69      [4,9]   subject object  img_72.png  img_72.ias  img_overlay_72.bmp   \n",
       "70       [99]           object  img_73.png  img_73.ias  img_overlay_73.bmp   \n",
       "71       [99]           object  img_74.png  img_74.ias  img_overlay_74.bmp   \n",
       "72       [99]           object  img_75.png  img_75.ias  img_overlay_75.bmp   \n",
       "73       [99]           object  img_76.png  img_76.ias  img_overlay_76.bmp   \n",
       "74       [99]              ADJ  img_77.png  img_77.ias  img_overlay_77.bmp   \n",
       "75       [99]              Mod  img_78.png  img_78.ias  img_overlay_78.bmp   \n",
       "76       [99]           object  img_79.png  img_79.ias  img_overlay_79.bmp   \n",
       "77       [99]              ADJ  img_80.png  img_80.ias  img_overlay_80.bmp   \n",
       "78       [99]             Verb  img_81.png  img_81.ias  img_overlay_81.bmp   \n",
       "79       [99]              ADJ  img_82.png  img_82.ias  img_overlay_82.bmp   \n",
       "80       [99]              NaN  img_83.png  img_83.ias  img_overlay_83.bmp   \n",
       "81       [99]           object  img_85.png  img_85.ias  img_overlay_85.bmp   \n",
       "82       [99]   elision object  img_86.png  img_86.ias  img_overlay_86.bmp   \n",
       "83       [99]             verb  img_87.png  img_87.ias  img_overlay_87.bmp   \n",
       "84       [99]           object  img_88.png  img_88.ias  img_overlay_88.bmp   \n",
       "85       [99]           object  img_89.png  img_89.ias  img_overlay_89.bmp   \n",
       "86       [99]              ADJ  img_90.png  img_90.ias  img_overlay_90.bmp   \n",
       "87       [99]           object  img_91.png  img_91.ias  img_overlay_91.bmp   \n",
       "88       [99]              NaN  img_92.png  img_92.ias  img_overlay_92.bmp   \n",
       "89       [99]              NaN  img_93.png  img_93.ias  img_overlay_93.bmp   \n",
       "90       [99]              NaN  img_94.png  img_94.ias  img_overlay_94.bmp   \n",
       "91       [99]              NaN  img_95.png  img_95.ias  img_overlay_95.bmp   \n",
       "92       [99]              NaN  img_96.png  img_96.ias  img_overlay_96.bmp   \n",
       "93       [99]              NaN  img_97.png  img_97.ias  img_overlay_97.bmp   \n",
       "\n",
       "    Check  \n",
       "44      1  \n",
       "45      1  \n",
       "46      1  \n",
       "47      1  \n",
       "48      1  \n",
       "49      1  \n",
       "50      1  \n",
       "51      1  \n",
       "52      1  \n",
       "53      1  \n",
       "54      1  \n",
       "55      1  \n",
       "56      1  \n",
       "57      1  \n",
       "58      1  \n",
       "59      1  \n",
       "60      1  \n",
       "61      1  \n",
       "62      1  \n",
       "63      1  \n",
       "64      1  \n",
       "65      1  \n",
       "66      1  \n",
       "67      1  \n",
       "68      1  \n",
       "69      1  \n",
       "70      1  \n",
       "71      1  \n",
       "72      1  \n",
       "73      1  \n",
       "74      1  \n",
       "75      1  \n",
       "76      1  \n",
       "77      1  \n",
       "78      1  \n",
       "79      1  \n",
       "80      1  \n",
       "81      1  \n",
       "82      1  \n",
       "83      1  \n",
       "84      1  \n",
       "85      1  \n",
       "86      1  \n",
       "87      1  \n",
       "88      1  \n",
       "89      1  \n",
       "90      1  \n",
       "91      1  \n",
       "92      1  \n",
       "93      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#orig_df.drop(orig_df.tail(1).index,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SENTENCE/TOKEN PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df = pd.read_csv('processed_data/dewiki-wordrank_result.txt', delimiter='\\t', header=None ) # columns=['word', 'freq']\n",
    "freq_df.columns = ['word', 'freq']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34671177"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_df.loc[freq_df['word']== 'der','freq'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_items_from_list(orig_list, items_to_remove):\n",
    "    return [i for i in orig_list if not i in items_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sno</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Cond_remark</th>\n",
       "      <th>ID</th>\n",
       "      <th>orig_ID</th>\n",
       "      <th>Ling_type</th>\n",
       "      <th>Comp</th>\n",
       "      <th>remarks_2</th>\n",
       "      <th>remarks_1</th>\n",
       "      <th>processed_assertion</th>\n",
       "      <th>mw_mark</th>\n",
       "      <th>H_P_mw</th>\n",
       "      <th>H_N_mw</th>\n",
       "      <th>change_remark</th>\n",
       "      <th>image_name</th>\n",
       "      <th>aoi_name</th>\n",
       "      <th>overlay_name</th>\n",
       "      <th>Check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Sno, Condition, Cond_remark, ID, orig_ID, Ling_type, Comp, remarks_2, remarks_1, processed_assertion, mw_mark, H_P_mw, H_N_mw, change_remark, image_name, aoi_name, overlay_name, Check]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#orig_df.loc[orig_df['processed_assertion']=='Nachteulen sind für bestimmte Berufe nich geeignet.', 'assertion']= 'Nachteulen sind für bestimmte Berufe nicht geeignet.'\n",
    "orig_df.loc[orig_df['processed_assertion']=='Nachteulen sind für bestimmte Berufe nich geeignet.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df['tokens'] = np.nan\n",
    "orig_df['tokens'] = orig_df['tokens'].astype('object')\n",
    "\n",
    "orig_df['cleaned_tokens'] = np.nan\n",
    "orig_df['cleaned_tokens'] = orig_df['cleaned_tokens'].astype('object')\n",
    "\n",
    "orig_df['word_length'] = np.nan\n",
    "orig_df['word_length'] = orig_df['word_length'].astype('object')\n",
    "\n",
    "orig_df['word_freq'] = np.nan\n",
    "orig_df['word_freq'] = orig_df['word_freq'].astype('object')\n",
    "\n",
    "items_to_remove = ['.', ',']\n",
    "for index, row in orig_df.iterrows():\n",
    "    try:\n",
    "        sentence = row['processed_assertion']\n",
    "        \n",
    "        tokens = nltk.word_tokenize(sentence.lower(), language='german')\n",
    "        cleaned_tokens = remove_items_from_list(tokens, items_to_remove)\n",
    "        #we don't want to have a special token for # e.g. in #metoo-bewegung\n",
    "        if \"#\" in cleaned_tokens:\n",
    "            \n",
    "            sp_index = cleaned_tokens.index('#')\n",
    "            #\n",
    "            #print(sp_index, ''.join(['#', cleaned_tokens[sp_index+1]]))\n",
    "            cleaned_tokens[sp_index+1] = ''.join(['#', cleaned_tokens[sp_index+1]])\n",
    "            cleaned_tokens.remove(\"#\")\n",
    "        \n",
    "        #print(tokens)\n",
    "        orig_df.at[index, 'tokens'] = tokens\n",
    "        orig_df.at[index, 'cleaned_tokens'] = cleaned_tokens\n",
    "        word_length_list = []\n",
    "        word_freq_list =[]\n",
    "        \n",
    "        for token in tokens:\n",
    "            #print(token)\n",
    "            word_length_list.append(len(token))\n",
    "            \n",
    "            if len(freq_df.loc[freq_df['word']== token,'freq']) >0:\n",
    "                word_freq = freq_df.loc[freq_df['word']== token,'freq'].values[0]\n",
    "            else:\n",
    "                word_freq = None     \n",
    "            word_freq_list.append(word_freq)\n",
    "            \n",
    "        #print(word_freq_list, word_length_list) \n",
    "           \n",
    "        orig_df.at[index, 'word_length'] = word_length_list\n",
    "        orig_df.at[index, 'word_freq'] = word_freq_list\n",
    "    except:\n",
    "        print('Problem with the sentence :', index)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sno</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Cond_remark</th>\n",
       "      <th>ID</th>\n",
       "      <th>orig_ID</th>\n",
       "      <th>Ling_type</th>\n",
       "      <th>Comp</th>\n",
       "      <th>remarks_2</th>\n",
       "      <th>remarks_1</th>\n",
       "      <th>processed_assertion</th>\n",
       "      <th>...</th>\n",
       "      <th>H_N_mw</th>\n",
       "      <th>change_remark</th>\n",
       "      <th>image_name</th>\n",
       "      <th>aoi_name</th>\n",
       "      <th>overlay_name</th>\n",
       "      <th>Check</th>\n",
       "      <th>tokens</th>\n",
       "      <th>cleaned_tokens</th>\n",
       "      <th>word_length</th>\n",
       "      <th>word_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>hate_w_high</td>\n",
       "      <td>31</td>\n",
       "      <td>44</td>\n",
       "      <td>lexical</td>\n",
       "      <td>0.0</td>\n",
       "      <td>derog</td>\n",
       "      <td>HighHateLowDiff</td>\n",
       "      <td>Die #metoo-Bewegung ist hysterisch.</td>\n",
       "      <td>...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>no_change</td>\n",
       "      <td>img_10.png</td>\n",
       "      <td>img_10.ias</td>\n",
       "      <td>img_overlay_10.bmp</td>\n",
       "      <td>1</td>\n",
       "      <td>[die, #, metoo-bewegung, ist, hysterisch, .]</td>\n",
       "      <td>[die, #metoo-bewegung, ist, hysterisch]</td>\n",
       "      <td>[3, 1, 14, 3, 10, 1]</td>\n",
       "      <td>[26485493, None, None, 6149650, 272, None]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sno  Condition  Cond_remark  ID orig_ID Ling_type  Comp remarks_2  \\\n",
       "9   10          1  hate_w_high  31      44   lexical   0.0     derog   \n",
       "\n",
       "         remarks_1                  processed_assertion  ...  H_N_mw  \\\n",
       "9  HighHateLowDiff  Die #metoo-Bewegung ist hysterisch.  ...     [3]   \n",
       "\n",
       "  change_remark  image_name    aoi_name        overlay_name Check  \\\n",
       "9     no_change  img_10.png  img_10.ias  img_overlay_10.bmp     1   \n",
       "\n",
       "                                         tokens  \\\n",
       "9  [die, #, metoo-bewegung, ist, hysterisch, .]   \n",
       "\n",
       "                            cleaned_tokens           word_length  \\\n",
       "9  [die, #metoo-bewegung, ist, hysterisch]  [3, 1, 14, 3, 10, 1]   \n",
       "\n",
       "                                    word_freq  \n",
       "9  [26485493, None, None, 6149650, 272, None]  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_df.loc[orig_df['processed_assertion']=='Die #metoo-Bewegung ist hysterisch.']                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sno', 'Condition', 'Cond_remark', 'ID', 'orig_ID', 'Ling_type', 'Comp',\n",
       "       'remarks_2', 'remarks_1', 'processed_assertion', 'mw_mark', 'H_P_mw',\n",
       "       'H_N_mw', 'change_remark', 'image_name', 'aoi_name', 'overlay_name',\n",
       "       'Check', 'tokens', 'cleaned_tokens', 'word_length', 'word_freq'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['die', '#metoo-bewegung', 'ist', 'hysterisch']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_df.loc[9, 'cleaned_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['die', '#keinurlaub-bewegung', 'ist', 'hysterisch']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_df.loc[59, 'cleaned_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df['cleaned_token_count'] = orig_df['cleaned_tokens'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[1,3]'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_df.loc[5,'H_N_mw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ast.literal_eval(orig_df.loc[2,'H_N_mw'])\n",
    "\n",
    "orig_df['H_N_mw']= orig_df['H_N_mw'].apply(lambda x: ast.literal_eval(x))\n",
    "orig_df['H_P_mw']= orig_df['H_P_mw'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_df.loc[5,'H_N_mw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sno', 'Condition', 'Cond_remark', 'ID', 'orig_ID', 'Ling_type', 'Comp',\n",
       "       'remarks_2', 'remarks_1', 'processed_assertion', 'mw_mark', 'H_P_mw',\n",
       "       'H_N_mw', 'change_remark', 'image_name', 'aoi_name', 'overlay_name',\n",
       "       'Check', 'tokens', 'cleaned_tokens', 'word_length', 'word_freq',\n",
       "       'cleaned_token_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df.to_csv('processed_data/processed_sentences_tokenize_cloze_etc.csv', sep='\\t', index=False)\n",
    "\n",
    "\n",
    "orig_df.to_pickle('processed_data/processed_sentences_tokenize_cloze_etc.pkl')  ## it is easier to read the cells with list values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLOZE PROBABILITIES FROM GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Frauen\n",
      "1 haben\n",
      "2 einen\n",
      "3 signifikant\n",
      "4 geringeren\n",
      "5 Durchsetzungswillen\n",
      "0 Frauen\n",
      "1 sind\n",
      "2 psychisch\n",
      "3 nicht\n",
      "4 für\n",
      "5 komplexe\n",
      "6 Arbeit\n",
      "7 geschaffen\n",
      "0 Frauen\n",
      "1 haben\n",
      "2 im\n",
      "3 statistischen\n",
      "4 Mittel\n",
      "5 ein\n",
      "6 kleineres\n",
      "7 Allgemeinwissen\n",
      "0 Frauenförderung\n",
      "1 hat\n",
      "2 fast\n",
      "3 nur\n",
      "4 Nachteile\n",
      "5 für\n",
      "6 die\n",
      "7 Gesellschaft\n",
      "0 Frauen\n",
      "1 sind\n",
      "2 im\n",
      "3 Durchschnitt\n",
      "4 dümmer\n",
      "5 als\n",
      "6 Männer\n",
      "0 Frauen\n",
      "1 sind\n",
      "2 Männern\n",
      "3 geistig\n",
      "4 in\n",
      "5 einigen\n",
      "6 Bereichen\n",
      "7 unterlegen\n",
      "0 Frauen\n",
      "1 sind\n",
      "2 Minderleister\n",
      "3 in\n",
      "4 unserer\n",
      "5 Gesellschaft\n",
      "0 Frauen\n",
      "1 können\n",
      "2 nichts\n",
      "3 und\n",
      "4 sind\n",
      "5 zu\n",
      "6 dumm\n",
      "0 Frauen\n",
      "1 ruinieren\n",
      "2 oft\n",
      "3 den\n",
      "4 größten\n",
      "5 Spaß\n",
      "0 Die\n",
      "1 #metoo-Bewegung\n",
      "2 ist\n",
      "3 hysterisch\n",
      "0 Frauen\n",
      "1 sollten\n",
      "2 zu\n",
      "3 Hause\n",
      "4 bleiben\n",
      "5 und\n",
      "6 sich\n",
      "7 um\n",
      "8 das\n",
      "9 Kind\n",
      "10 kümmern\n",
      "0 Feministen\n",
      "1 sind\n",
      "2 überwiegend\n",
      "3 angetrieben\n",
      "4 durch\n",
      "5 Männerhass\n",
      "0 Frauen\n",
      "1 altern\n",
      "2 wie\n",
      "3 Milch,\n",
      "4 Männer\n",
      "5 altern\n",
      "6 wie\n",
      "7 Wein\n",
      "0 Eine\n",
      "1 klassische\n",
      "2 Rollenverteilung\n",
      "3 in\n",
      "4 der\n",
      "5 Ehe\n",
      "6 ist\n",
      "7 zu\n",
      "8 bevorzugen\n",
      "0 Frauen\n",
      "1 sind\n",
      "2 für\n",
      "3 gewisse\n",
      "4 Berufen\n",
      "5 nicht\n",
      "6 geeignet\n",
      "0 Gleichstellung\n",
      "1 der\n",
      "2 Geschlechter\n",
      "3 ist\n",
      "4 eine\n",
      "5 Überbevorteilung\n",
      "6 von\n",
      "7 Frauen\n",
      "0 Frauen\n",
      "1 in\n",
      "2 führenden\n",
      "3 Positionen\n",
      "4 haben\n",
      "5 häufig\n",
      "6 komplizierte\n",
      "7 Persönlichkeiten\n",
      "0 Frauen\n",
      "1 gehören\n",
      "2 in\n",
      "3 die\n",
      "4 Küche\n",
      "0 Frauen\n",
      "1 sollten\n",
      "2 ihre\n",
      "3 klassische\n",
      "4 Geschlechterrolle\n",
      "5 ausüben\n",
      "0 Alles\n",
      "1 was\n",
      "2 eine\n",
      "3 Frau\n",
      "4 tun\n",
      "5 muss,\n",
      "6 ist\n",
      "7 ihren\n",
      "8 Mann\n",
      "9 zu\n",
      "10 befriedigen\n",
      "0 Frauen\n",
      "1 machen\n",
      "2 jedes\n",
      "3 wirtschaftliche\n",
      "4 Unternehmen\n",
      "5 stärker\n",
      "0 Männer\n",
      "1 und\n",
      "2 Frauen\n",
      "3 sind\n",
      "4 gleich\n",
      "5 intelligent\n",
      "0 Frauen\n",
      "1 können\n",
      "2 ohne\n",
      "3 Kinder\n",
      "4 glücklich\n",
      "5 sein\n",
      "0 Frauen\n",
      "1 sind\n",
      "2 nicht\n",
      "3 schwach\n",
      "4 und\n",
      "5 sollten\n",
      "6 sich\n",
      "7 so\n",
      "8 auch\n",
      "9 nicht\n",
      "10 fühlen\n",
      "0 Frauen\n",
      "1 sollen\n",
      "2 das\n",
      "3 gleiche\n",
      "4 machen\n",
      "5 dürfen\n",
      "6 wie\n",
      "7 Männer\n",
      "0 Beide\n",
      "1 Geschlechter\n",
      "2 sollten\n",
      "3 gleich\n",
      "4 bezahlt\n",
      "5 werden\n",
      "0 Gleichberechtigung\n",
      "1 ist\n",
      "2 eine\n",
      "3 menschenrechtliche\n",
      "4 Frage\n",
      "0 Väter\n",
      "1 müssen\n",
      "2 im\n",
      "3 gleichen\n",
      "4 Umfang\n",
      "5 wie\n",
      "6 Mütter\n",
      "7 Verantwortung\n",
      "8 für\n",
      "9 ihre\n",
      "10 Kinder\n",
      "11 übernehmen\n",
      "0 Die\n",
      "1 Geschlechter\n",
      "2 sind\n",
      "3 nicht\n",
      "4 immer\n",
      "5 gleich,\n",
      "6 jedoch\n",
      "7 nicht\n",
      "8 minderwertiger\n",
      "0 Alleinerziehende\n",
      "1 Mütter\n",
      "2 sind\n",
      "3 Heldinnen\n",
      "0 Es\n",
      "1 gibt\n",
      "2 Frauenberufe\n",
      "3 und\n",
      "4 es\n",
      "5 gibt\n",
      "6 Männerberufe\n",
      "0 Männer\n",
      "1 fühlen\n",
      "2 sich\n",
      "3 von\n",
      "4 Frauen\n",
      "5 in\n",
      "6 Führungspositionen\n",
      "7 bedroht\n",
      "0 Frauenquote\n",
      "1 muss\n",
      "2 überall\n",
      "3 sein\n",
      "0 Männer\n",
      "1 und\n",
      "2 Frauen\n",
      "3 sind\n",
      "4 in\n",
      "5 einer\n",
      "6 traditionellen\n",
      "7 Familie\n",
      "8 am\n",
      "9 glücklichsten\n",
      "0 Frauen\n",
      "1 sind\n",
      "2 bei\n",
      "3 Sorgerechtsfragen\n",
      "4 privilegiert\n",
      "0 Frauen\n",
      "1 haben\n",
      "2 große\n",
      "3 Vorteile\n",
      "4 bei\n",
      "5 Gerichtsentscheidungen\n",
      "6 über\n",
      "7 den\n",
      "8 Verbleib\n",
      "9 der\n",
      "10 eigenen\n",
      "11 Kinder\n",
      "0 Frauen\n",
      "1 sind\n",
      "2 im\n",
      "3 Durchschnitt\n",
      "4 schwächer\n",
      "5 als\n",
      "6 Männer\n",
      "7 in\n",
      "8 physischen\n",
      "9 Aspekten\n",
      "0 Die\n",
      "1 Gender-Pay-Gap\n",
      "2 ist\n",
      "3 kein\n",
      "4 Problem\n",
      "5 des\n",
      "6 Sexismus\n",
      "0 Frauen\n",
      "1 können\n",
      "2 sich\n",
      "3 besser\n",
      "4 um\n",
      "5 Kinder\n",
      "6 und\n",
      "7 Familie\n",
      "8 kümmern,\n",
      "9 es\n",
      "10 liegt\n",
      "11 in\n",
      "12 ihrer\n",
      "13 Natur\n",
      "0 Spezielle\n",
      "1 Frauenquoten\n",
      "2 \n",
      "3 sind\n",
      "4 unnötig\n",
      "5 und\n",
      "6 kontraproduktiv\n",
      "0 Männer\n",
      "1 sind\n",
      "2 unsozial\n",
      "0 Männer\n",
      "1 sind\n",
      "2 dümmer\n",
      "3 als\n",
      "4 Frauen\n",
      "0 Männer\n",
      "1 sind\n",
      "2 unzuverlässiger\n",
      "3 als\n",
      "4 Frauen\n",
      "0 Alle\n",
      "1 Männer\n",
      "2 \n",
      "3 sind\n",
      "4 Machos\n",
      "0 Männer\n",
      "1 sind\n",
      "2 nicht\n",
      "3 die\n",
      "4 hellsten\n",
      "0 Der\n",
      "1 Mann\n",
      "2 verprasst\n",
      "3 das\n",
      "4 Geld\n",
      "0 Männer\n",
      "1 gehören\n",
      "2 auf\n",
      "3 den\n",
      "4 Bau\n",
      "0 Männer\n",
      "1 sind\n",
      "2 bei\n",
      "3 Stellenvergaben\n",
      "4 privilegiert\n",
      "0 Männer\n",
      "1 verbingen\n",
      "2 wenig\n",
      "3 Zeit\n",
      "4 mit\n",
      "5 ihren\n",
      "6 Kindern\n",
      "0 Alle\n",
      "1 Männer\n",
      "2 sind\n",
      "3 ausgewachsene\n",
      "4 Kinder\n",
      "0 Pokemons\n",
      "1 haben\n",
      "2 einen\n",
      "3 signifikant\n",
      "4 geringeren\n",
      "5 Durchsetzungswillen\n",
      "0 Kinder\n",
      "1 sind\n",
      "2 psychisch\n",
      "3 nicht\n",
      "4 für\n",
      "5 komplexe\n",
      "6 Arbeit\n",
      "7 geschaffen\n",
      "0 Kinder\n",
      "1 haben\n",
      "2 im\n",
      "3 statistischen\n",
      "4 Mittel\n",
      "5 ein\n",
      "6 kleineres\n",
      "7 Allgemeinwissen\n",
      "0 Egoismus\n",
      "1 hat\n",
      "2 fast\n",
      "3 nur\n",
      "4 Nachteile\n",
      "5 für\n",
      "6 die\n",
      "7 Gesellschaft\n",
      "0 Fische\n",
      "1 sind\n",
      "2 im\n",
      "3 Durchschnitt\n",
      "4 dümmer\n",
      "5 als\n",
      "6 Oktopusse\n",
      "0 Hunde\n",
      "1 sind\n",
      "2 Menschen\n",
      "3 geistig\n",
      "4 in\n",
      "5 einigen\n",
      "6 Bereichen\n",
      "7 unterlegen\n",
      "0 Kricketteams\n",
      "1 \n",
      "2 sind\n",
      "3 Minderleister\n",
      "4 in\n",
      "5 unseren\n",
      "6 Kneipen\n",
      "0 Minions\n",
      "1 können\n",
      "2 nichts\n",
      "3 und\n",
      "4 sind\n",
      "5 zu\n",
      "6 dumm\n",
      "0 Regen\n",
      "1 ruiniert\n",
      "2 oft\n",
      "3 den\n",
      "4 größten\n",
      "5 Spaß\n",
      "0 Die\n",
      "1 #keinurlaub-Bewegung\n",
      "2 ist\n",
      "3 hysterisch\n",
      "0 Babysitter\n",
      "1 sollten\n",
      "2 zu\n",
      "3 Hause\n",
      "4 bleiben\n",
      "5 und\n",
      "6 sich\n",
      "7 um\n",
      "8 das\n",
      "9 Kind\n",
      "10 kümmern\n",
      "0 Wissenschaftler\n",
      "1 sind\n",
      "2 überwiegend\n",
      "3 angetrieben\n",
      "4 durch\n",
      "5 Neugierde\n",
      "0 Programme\n",
      "1 altern\n",
      "2 wie\n",
      "3 Milch,\n",
      "4 Programmierer\n",
      "5 altern\n",
      "6 wie\n",
      "7 Wein\n",
      "0 Ein\n",
      "1 gesundes\n",
      "2 Sexualleben\n",
      "3 in\n",
      "4 der\n",
      "5 Ehe\n",
      "6 ist\n",
      "7 zu\n",
      "8 bevorzugen\n",
      "0 Nachteulen\n",
      "1 \n",
      "2 sind\n",
      "3 für\n",
      "4 bestimmte\n",
      "5 Berufe\n",
      "6 nicht\n",
      "7 geeignet\n",
      "0 Gleichstellung\n",
      "1 der\n",
      "2 Geschlechter\n",
      "3 findet\n",
      "4 zunehmend\n",
      "5 häufiger\n",
      "6 statt\n",
      "0 Menschen\n",
      "1 in\n",
      "2 führenden\n",
      "3 Positionen\n",
      "4 haben\n",
      "5 häufig\n",
      "6 komplizierte\n",
      "7 Terminpläne\n",
      "0 Töpfe\n",
      "1 gehören\n",
      "2 in\n",
      "3 die\n",
      "4 Küche\n",
      "0 Hühner\n",
      "1 sollten\n",
      "2 ihre\n",
      "3 klassische\n",
      "4 Gluckenrolle\n",
      "5 ausüben\n",
      "0 Alles\n",
      "1 was\n",
      "2 ein\n",
      "3 Film\n",
      "4 tun\n",
      "5 muss,\n",
      "6 ist\n",
      "7 seine\n",
      "8 Zuschauer\n",
      "9 zu\n",
      "10 befriedigen\n",
      "0 Frauen\n",
      "1 haben\n",
      "2 einen\n",
      "3 signifikant\n",
      "4 höre\n",
      "5 Schmerztoleranz\n",
      "6 \n",
      "0 Frauen\n",
      "1 sind\n",
      "2 psychisch\n",
      "3 für\n",
      "4 komplexe\n",
      "5 Arbeit\n",
      "6 geschaffen\n",
      "0 Frauen\n",
      "1 haben\n",
      "2 im\n",
      "3 statistischen\n",
      "4 Mittel\n",
      "5 in\n",
      "6 einen\n",
      "7 größeren\n",
      "8 Wortschatz\n",
      "0 Frauenförderung\n",
      "1 hat\n",
      "2 fast\n",
      "3 nur\n",
      "4 Vorteile\n",
      "5 für\n",
      "6 die\n",
      "7 Gesellschaft\n",
      "0 Frauen\n",
      "1 sind\n",
      "2 im\n",
      "3 Durchschnitt\n",
      "4 sozialer\n",
      "5 als\n",
      "6 Männer\n",
      "0 Frauen\n",
      "1 sind\n",
      "2 Männern\n",
      "3 im\n",
      "4 Erinnerungsvermögen\n",
      "5 überlegen\n",
      "0 Frauen\n",
      "1 sind\n",
      "2 Säulen\n",
      "3 in\n",
      "4 unserer\n",
      "5 Gesellschaft\n",
      "0 Frauen\n",
      "1 können\n",
      "2 alles\n",
      "3 und\n",
      "4 sind\n",
      "5 sehr\n",
      "6 kreativ\n",
      "0 Frauen\n",
      "1 schaffen\n",
      "2 oft\n",
      "3 den\n",
      "4 größten\n",
      "5 Spaß\n",
      "0 Die\n",
      "1 #metoo-Bewegung\n",
      "2 ist\n",
      "3 wirkmächtig\n",
      "0 Frauen\n",
      "1 sollten\n",
      "2 nicht\n",
      "3 zu\n",
      "4 Hause\n",
      "5 bleiben\n",
      "6 und\n",
      "7 sich\n",
      "8 um\n",
      "9 ihre\n",
      "10 Karriere\n",
      "11 kümmern\n",
      "0 Feministen\n",
      "1 sind\n",
      "2 überwiegend\n",
      "3 angetrieben\n",
      "4 durch\n",
      "5 Gerechtigkeitswünsche\n",
      "0 Gerüchte\n",
      "1 \n",
      "2 altern\n",
      "3 wie\n",
      "4 Milch,\n",
      "5 Frauen\n",
      "6 altern\n",
      "7 wie\n",
      "8 Wein\n",
      "0 Eine\n",
      "1 moderne\n",
      "2 Rollenverteilung\n",
      "3 in\n",
      "4 der\n",
      "5 Ehe\n",
      "6 ist\n",
      "7 zu\n",
      "8 bevorzugen\n",
      "0 Frauen\n",
      "1 sind\n",
      "2 für\n",
      "3 alle\n",
      "4 Berufe\n",
      "5 gut\n",
      "6 geeignet\n",
      "0 Gleichstellung\n",
      "1 der\n",
      "2 Geschlechter\n",
      "3 ist\n",
      "4 ein\n",
      "5 Traum\n",
      "6 der\n",
      "7 Gesellschaft\n",
      "0 Frauen\n",
      "1 in\n",
      "2 führenden\n",
      "3 Positionen\n",
      "4 haben\n",
      "5 häufig\n",
      "6 starke\n",
      "7 Persönlichkeiten\n",
      "0 Frauen\n",
      "1 gehören\n",
      "2 in\n",
      "3 die\n",
      "4 Regierung\n",
      "0 Frauen\n",
      "1 sollten\n",
      "2 ihren\n",
      "3 Traumberuf\n",
      "4 ausüben\n",
      "0 Alles\n",
      "1 was\n",
      "2 eine\n",
      "3 Frau\n",
      "4 tun\n",
      "5 muss,\n",
      "6 ist\n",
      "7 ihre\n",
      "8 Wünsche\n",
      "9 zu\n",
      "10 befriedigen\n",
      "0 Männer\n",
      "1 sind\n",
      "2 im\n",
      "3 Schnitt\n",
      "4 biologisch\n",
      "5 intelligenter\n",
      "0 Alle\n",
      "1 Feministinnen\n",
      "2 sind\n",
      "3 Helden\n",
      "0 Ab\n",
      "1 und\n",
      "2 zu\n",
      "3 eine\n",
      "4 erzieherische\n",
      "5 Ohrfeige\n",
      "6 hat\n",
      "7 noch\n",
      "8 niemand\n",
      "9 geschadet,\n",
      "10 auch\n",
      "11 nicht\n",
      "12 Mickey\n",
      "13 Mouse\n",
      "0 Der\n",
      "1 aktuelle\n",
      "2 Drang\n",
      "3 zur\n",
      "4 Emanzipation\n",
      "5 schlägt\n",
      "6 teilweise\n",
      "7 um\n",
      "8 in\n",
      "9 eine\n",
      "10 Rachsucht\n"
     ]
    }
   ],
   "source": [
    "cloze_df= pd.DataFrame(columns=['Sno', 'Ino', 'tokens', 'sentence', 'masked_token'])\n",
    "for index, row in orig_df.iterrows():\n",
    "    sentence= row['processed_assertion'].replace('.', '')\n",
    "    tokens = sentence.split(' ')\n",
    "    inc_tokens = []\n",
    "    for i, value in enumerate(tokens):\n",
    "        print(i, value)\n",
    "        if i < len(tokens)-1:\n",
    "            inc_tokens.append(value)\n",
    "            new_row= len(cloze_df)\n",
    "            \n",
    "            cloze_df.at[new_row, 'sentence']=\" \".join(inc_tokens) #+ ' [MASK]'\n",
    "            cloze_df.at[new_row, 'Sno']=row['Sno']\n",
    "            cloze_df.at[new_row, 'Ino']=i\n",
    "            cloze_df.at[new_row, 'tokens']=inc_tokens\n",
    "            cloze_df.at[new_row, 'masked_token']=tokens[i+1]\n",
    "        \n",
    "cloze_df.to_csv(\"sentences_cloze.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sno</th>\n",
       "      <th>Ino</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentence</th>\n",
       "      <th>masked_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Frauen, haben, einen, signifikant, geringeren]</td>\n",
       "      <td>Frauen</td>\n",
       "      <td>haben</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[Frauen, haben, einen, signifikant, geringeren]</td>\n",
       "      <td>Frauen haben</td>\n",
       "      <td>einen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[Frauen, haben, einen, signifikant, geringeren]</td>\n",
       "      <td>Frauen haben einen</td>\n",
       "      <td>signifikant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[Frauen, haben, einen, signifikant, geringeren]</td>\n",
       "      <td>Frauen haben einen signifikant</td>\n",
       "      <td>geringeren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[Frauen, haben, einen, signifikant, geringeren]</td>\n",
       "      <td>Frauen haben einen signifikant geringeren</td>\n",
       "      <td>Durchsetzungswillen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[Frauen, sind, psychisch, nicht, für, komplexe...</td>\n",
       "      <td>Frauen</td>\n",
       "      <td>sind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[Frauen, sind, psychisch, nicht, für, komplexe...</td>\n",
       "      <td>Frauen sind</td>\n",
       "      <td>psychisch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[Frauen, sind, psychisch, nicht, für, komplexe...</td>\n",
       "      <td>Frauen sind psychisch</td>\n",
       "      <td>nicht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[Frauen, sind, psychisch, nicht, für, komplexe...</td>\n",
       "      <td>Frauen sind psychisch nicht</td>\n",
       "      <td>für</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>[Frauen, sind, psychisch, nicht, für, komplexe...</td>\n",
       "      <td>Frauen sind psychisch nicht für</td>\n",
       "      <td>komplexe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>[Frauen, sind, psychisch, nicht, für, komplexe...</td>\n",
       "      <td>Frauen sind psychisch nicht für komplexe</td>\n",
       "      <td>Arbeit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>[Frauen, sind, psychisch, nicht, für, komplexe...</td>\n",
       "      <td>Frauen sind psychisch nicht für komplexe Arbeit</td>\n",
       "      <td>geschaffen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[Frauen, haben, im, statistischen, Mittel, ein...</td>\n",
       "      <td>Frauen</td>\n",
       "      <td>haben</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[Frauen, haben, im, statistischen, Mittel, ein...</td>\n",
       "      <td>Frauen haben</td>\n",
       "      <td>im</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[Frauen, haben, im, statistischen, Mittel, ein...</td>\n",
       "      <td>Frauen haben im</td>\n",
       "      <td>statistischen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[Frauen, haben, im, statistischen, Mittel, ein...</td>\n",
       "      <td>Frauen haben im statistischen</td>\n",
       "      <td>Mittel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[Frauen, haben, im, statistischen, Mittel, ein...</td>\n",
       "      <td>Frauen haben im statistischen Mittel</td>\n",
       "      <td>ein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>[Frauen, haben, im, statistischen, Mittel, ein...</td>\n",
       "      <td>Frauen haben im statistischen Mittel ein</td>\n",
       "      <td>kleineres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>[Frauen, haben, im, statistischen, Mittel, ein...</td>\n",
       "      <td>Frauen haben im statistischen Mittel ein klein...</td>\n",
       "      <td>Allgemeinwissen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[Frauenförderung, hat, fast, nur, Nachteile, f...</td>\n",
       "      <td>Frauenförderung</td>\n",
       "      <td>hat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sno Ino                                             tokens  \\\n",
       "0    1   0    [Frauen, haben, einen, signifikant, geringeren]   \n",
       "1    1   1    [Frauen, haben, einen, signifikant, geringeren]   \n",
       "2    1   2    [Frauen, haben, einen, signifikant, geringeren]   \n",
       "3    1   3    [Frauen, haben, einen, signifikant, geringeren]   \n",
       "4    1   4    [Frauen, haben, einen, signifikant, geringeren]   \n",
       "5    2   0  [Frauen, sind, psychisch, nicht, für, komplexe...   \n",
       "6    2   1  [Frauen, sind, psychisch, nicht, für, komplexe...   \n",
       "7    2   2  [Frauen, sind, psychisch, nicht, für, komplexe...   \n",
       "8    2   3  [Frauen, sind, psychisch, nicht, für, komplexe...   \n",
       "9    2   4  [Frauen, sind, psychisch, nicht, für, komplexe...   \n",
       "10   2   5  [Frauen, sind, psychisch, nicht, für, komplexe...   \n",
       "11   2   6  [Frauen, sind, psychisch, nicht, für, komplexe...   \n",
       "12   3   0  [Frauen, haben, im, statistischen, Mittel, ein...   \n",
       "13   3   1  [Frauen, haben, im, statistischen, Mittel, ein...   \n",
       "14   3   2  [Frauen, haben, im, statistischen, Mittel, ein...   \n",
       "15   3   3  [Frauen, haben, im, statistischen, Mittel, ein...   \n",
       "16   3   4  [Frauen, haben, im, statistischen, Mittel, ein...   \n",
       "17   3   5  [Frauen, haben, im, statistischen, Mittel, ein...   \n",
       "18   3   6  [Frauen, haben, im, statistischen, Mittel, ein...   \n",
       "19   4   0  [Frauenförderung, hat, fast, nur, Nachteile, f...   \n",
       "\n",
       "                                             sentence         masked_token  \n",
       "0                                              Frauen                haben  \n",
       "1                                        Frauen haben                einen  \n",
       "2                                  Frauen haben einen          signifikant  \n",
       "3                      Frauen haben einen signifikant           geringeren  \n",
       "4           Frauen haben einen signifikant geringeren  Durchsetzungswillen  \n",
       "5                                              Frauen                 sind  \n",
       "6                                         Frauen sind            psychisch  \n",
       "7                               Frauen sind psychisch                nicht  \n",
       "8                         Frauen sind psychisch nicht                  für  \n",
       "9                     Frauen sind psychisch nicht für             komplexe  \n",
       "10           Frauen sind psychisch nicht für komplexe               Arbeit  \n",
       "11    Frauen sind psychisch nicht für komplexe Arbeit           geschaffen  \n",
       "12                                             Frauen                haben  \n",
       "13                                       Frauen haben                   im  \n",
       "14                                    Frauen haben im        statistischen  \n",
       "15                      Frauen haben im statistischen               Mittel  \n",
       "16               Frauen haben im statistischen Mittel                  ein  \n",
       "17           Frauen haben im statistischen Mittel ein            kleineres  \n",
       "18  Frauen haben im statistischen Mittel ein klein...      Allgemeinwissen  \n",
       "19                                    Frauenförderung                  hat  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloze_df.head(20)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sno</th>\n",
       "      <th>Ino</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentence</th>\n",
       "      <th>masked_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "      <td>[Ab, und, zu, eine, erzieherische, Ohrfeige, h...</td>\n",
       "      <td>Ab und zu eine</td>\n",
       "      <td>erzieherische</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>96</td>\n",
       "      <td>4</td>\n",
       "      <td>[Ab, und, zu, eine, erzieherische, Ohrfeige, h...</td>\n",
       "      <td>Ab und zu eine erzieherische</td>\n",
       "      <td>Ohrfeige</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>[Ab, und, zu, eine, erzieherische, Ohrfeige, h...</td>\n",
       "      <td>Ab und zu eine erzieherische Ohrfeige</td>\n",
       "      <td>hat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>96</td>\n",
       "      <td>6</td>\n",
       "      <td>[Ab, und, zu, eine, erzieherische, Ohrfeige, h...</td>\n",
       "      <td>Ab und zu eine erzieherische Ohrfeige hat</td>\n",
       "      <td>noch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>96</td>\n",
       "      <td>7</td>\n",
       "      <td>[Ab, und, zu, eine, erzieherische, Ohrfeige, h...</td>\n",
       "      <td>Ab und zu eine erzieherische Ohrfeige hat noch</td>\n",
       "      <td>niemand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>96</td>\n",
       "      <td>8</td>\n",
       "      <td>[Ab, und, zu, eine, erzieherische, Ohrfeige, h...</td>\n",
       "      <td>Ab und zu eine erzieherische Ohrfeige hat noch...</td>\n",
       "      <td>geschadet,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>96</td>\n",
       "      <td>9</td>\n",
       "      <td>[Ab, und, zu, eine, erzieherische, Ohrfeige, h...</td>\n",
       "      <td>Ab und zu eine erzieherische Ohrfeige hat noch...</td>\n",
       "      <td>auch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>96</td>\n",
       "      <td>10</td>\n",
       "      <td>[Ab, und, zu, eine, erzieherische, Ohrfeige, h...</td>\n",
       "      <td>Ab und zu eine erzieherische Ohrfeige hat noch...</td>\n",
       "      <td>nicht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>96</td>\n",
       "      <td>11</td>\n",
       "      <td>[Ab, und, zu, eine, erzieherische, Ohrfeige, h...</td>\n",
       "      <td>Ab und zu eine erzieherische Ohrfeige hat noch...</td>\n",
       "      <td>Mickey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>96</td>\n",
       "      <td>12</td>\n",
       "      <td>[Ab, und, zu, eine, erzieherische, Ohrfeige, h...</td>\n",
       "      <td>Ab und zu eine erzieherische Ohrfeige hat noch...</td>\n",
       "      <td>Mouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>[Der, aktuelle, Drang, zur, Emanzipation, schl...</td>\n",
       "      <td>Der</td>\n",
       "      <td>aktuelle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>[Der, aktuelle, Drang, zur, Emanzipation, schl...</td>\n",
       "      <td>Der aktuelle</td>\n",
       "      <td>Drang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>[Der, aktuelle, Drang, zur, Emanzipation, schl...</td>\n",
       "      <td>Der aktuelle Drang</td>\n",
       "      <td>zur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>97</td>\n",
       "      <td>3</td>\n",
       "      <td>[Der, aktuelle, Drang, zur, Emanzipation, schl...</td>\n",
       "      <td>Der aktuelle Drang zur</td>\n",
       "      <td>Emanzipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>97</td>\n",
       "      <td>4</td>\n",
       "      <td>[Der, aktuelle, Drang, zur, Emanzipation, schl...</td>\n",
       "      <td>Der aktuelle Drang zur Emanzipation</td>\n",
       "      <td>schlägt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>97</td>\n",
       "      <td>5</td>\n",
       "      <td>[Der, aktuelle, Drang, zur, Emanzipation, schl...</td>\n",
       "      <td>Der aktuelle Drang zur Emanzipation schlägt</td>\n",
       "      <td>teilweise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>97</td>\n",
       "      <td>6</td>\n",
       "      <td>[Der, aktuelle, Drang, zur, Emanzipation, schl...</td>\n",
       "      <td>Der aktuelle Drang zur Emanzipation schlägt te...</td>\n",
       "      <td>um</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>97</td>\n",
       "      <td>7</td>\n",
       "      <td>[Der, aktuelle, Drang, zur, Emanzipation, schl...</td>\n",
       "      <td>Der aktuelle Drang zur Emanzipation schlägt te...</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>97</td>\n",
       "      <td>8</td>\n",
       "      <td>[Der, aktuelle, Drang, zur, Emanzipation, schl...</td>\n",
       "      <td>Der aktuelle Drang zur Emanzipation schlägt te...</td>\n",
       "      <td>eine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>97</td>\n",
       "      <td>9</td>\n",
       "      <td>[Der, aktuelle, Drang, zur, Emanzipation, schl...</td>\n",
       "      <td>Der aktuelle Drang zur Emanzipation schlägt te...</td>\n",
       "      <td>Rachsucht</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sno Ino                                             tokens  \\\n",
       "570  96   3  [Ab, und, zu, eine, erzieherische, Ohrfeige, h...   \n",
       "571  96   4  [Ab, und, zu, eine, erzieherische, Ohrfeige, h...   \n",
       "572  96   5  [Ab, und, zu, eine, erzieherische, Ohrfeige, h...   \n",
       "573  96   6  [Ab, und, zu, eine, erzieherische, Ohrfeige, h...   \n",
       "574  96   7  [Ab, und, zu, eine, erzieherische, Ohrfeige, h...   \n",
       "575  96   8  [Ab, und, zu, eine, erzieherische, Ohrfeige, h...   \n",
       "576  96   9  [Ab, und, zu, eine, erzieherische, Ohrfeige, h...   \n",
       "577  96  10  [Ab, und, zu, eine, erzieherische, Ohrfeige, h...   \n",
       "578  96  11  [Ab, und, zu, eine, erzieherische, Ohrfeige, h...   \n",
       "579  96  12  [Ab, und, zu, eine, erzieherische, Ohrfeige, h...   \n",
       "580  97   0  [Der, aktuelle, Drang, zur, Emanzipation, schl...   \n",
       "581  97   1  [Der, aktuelle, Drang, zur, Emanzipation, schl...   \n",
       "582  97   2  [Der, aktuelle, Drang, zur, Emanzipation, schl...   \n",
       "583  97   3  [Der, aktuelle, Drang, zur, Emanzipation, schl...   \n",
       "584  97   4  [Der, aktuelle, Drang, zur, Emanzipation, schl...   \n",
       "585  97   5  [Der, aktuelle, Drang, zur, Emanzipation, schl...   \n",
       "586  97   6  [Der, aktuelle, Drang, zur, Emanzipation, schl...   \n",
       "587  97   7  [Der, aktuelle, Drang, zur, Emanzipation, schl...   \n",
       "588  97   8  [Der, aktuelle, Drang, zur, Emanzipation, schl...   \n",
       "589  97   9  [Der, aktuelle, Drang, zur, Emanzipation, schl...   \n",
       "\n",
       "                                              sentence   masked_token  \n",
       "570                                     Ab und zu eine  erzieherische  \n",
       "571                       Ab und zu eine erzieherische       Ohrfeige  \n",
       "572              Ab und zu eine erzieherische Ohrfeige            hat  \n",
       "573          Ab und zu eine erzieherische Ohrfeige hat           noch  \n",
       "574     Ab und zu eine erzieherische Ohrfeige hat noch        niemand  \n",
       "575  Ab und zu eine erzieherische Ohrfeige hat noch...     geschadet,  \n",
       "576  Ab und zu eine erzieherische Ohrfeige hat noch...           auch  \n",
       "577  Ab und zu eine erzieherische Ohrfeige hat noch...          nicht  \n",
       "578  Ab und zu eine erzieherische Ohrfeige hat noch...         Mickey  \n",
       "579  Ab und zu eine erzieherische Ohrfeige hat noch...          Mouse  \n",
       "580                                                Der       aktuelle  \n",
       "581                                       Der aktuelle          Drang  \n",
       "582                                 Der aktuelle Drang            zur  \n",
       "583                             Der aktuelle Drang zur   Emanzipation  \n",
       "584                Der aktuelle Drang zur Emanzipation        schlägt  \n",
       "585        Der aktuelle Drang zur Emanzipation schlägt      teilweise  \n",
       "586  Der aktuelle Drang zur Emanzipation schlägt te...             um  \n",
       "587  Der aktuelle Drang zur Emanzipation schlägt te...             in  \n",
       "588  Der aktuelle Drang zur Emanzipation schlägt te...           eine  \n",
       "589  Der aktuelle Drang zur Emanzipation schlägt te...      Rachsucht  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloze_df.tail(20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Using Series.values.tolist()\n",
    "masked_sentence_list = cloze_df[\"sentence\"].values.tolist()\n",
    "label_list= cloze_df[\"masked_token\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Frauen',\n",
       " 'Frauen haben',\n",
       " 'Frauen haben einen',\n",
       " 'Frauen haben einen signifikant',\n",
       " 'Frauen haben einen signifikant geringeren',\n",
       " 'Frauen',\n",
       " 'Frauen sind',\n",
       " 'Frauen sind psychisch',\n",
       " 'Frauen sind psychisch nicht',\n",
       " 'Frauen sind psychisch nicht für',\n",
       " 'Frauen sind psychisch nicht für komplexe',\n",
       " 'Frauen sind psychisch nicht für komplexe Arbeit',\n",
       " 'Frauen',\n",
       " 'Frauen haben',\n",
       " 'Frauen haben im',\n",
       " 'Frauen haben im statistischen',\n",
       " 'Frauen haben im statistischen Mittel',\n",
       " 'Frauen haben im statistischen Mittel ein',\n",
       " 'Frauen haben im statistischen Mittel ein kleineres',\n",
       " 'Frauenförderung',\n",
       " 'Frauenförderung hat',\n",
       " 'Frauenförderung hat fast',\n",
       " 'Frauenförderung hat fast nur',\n",
       " 'Frauenförderung hat fast nur Nachteile',\n",
       " 'Frauenförderung hat fast nur Nachteile für',\n",
       " 'Frauenförderung hat fast nur Nachteile für die',\n",
       " 'Frauen',\n",
       " 'Frauen sind',\n",
       " 'Frauen sind im',\n",
       " 'Frauen sind im Durchschnitt',\n",
       " 'Frauen sind im Durchschnitt dümmer',\n",
       " 'Frauen sind im Durchschnitt dümmer als',\n",
       " 'Frauen',\n",
       " 'Frauen sind',\n",
       " 'Frauen sind Männern',\n",
       " 'Frauen sind Männern geistig',\n",
       " 'Frauen sind Männern geistig in',\n",
       " 'Frauen sind Männern geistig in einigen',\n",
       " 'Frauen sind Männern geistig in einigen Bereichen',\n",
       " 'Frauen',\n",
       " 'Frauen sind',\n",
       " 'Frauen sind Minderleister',\n",
       " 'Frauen sind Minderleister in',\n",
       " 'Frauen sind Minderleister in unserer',\n",
       " 'Frauen',\n",
       " 'Frauen können',\n",
       " 'Frauen können nichts',\n",
       " 'Frauen können nichts und',\n",
       " 'Frauen können nichts und sind',\n",
       " 'Frauen können nichts und sind zu',\n",
       " 'Frauen',\n",
       " 'Frauen ruinieren',\n",
       " 'Frauen ruinieren oft',\n",
       " 'Frauen ruinieren oft den',\n",
       " 'Frauen ruinieren oft den größten',\n",
       " 'Die',\n",
       " 'Die #metoo-Bewegung',\n",
       " 'Die #metoo-Bewegung ist',\n",
       " 'Frauen',\n",
       " 'Frauen sollten',\n",
       " 'Frauen sollten zu',\n",
       " 'Frauen sollten zu Hause',\n",
       " 'Frauen sollten zu Hause bleiben',\n",
       " 'Frauen sollten zu Hause bleiben und',\n",
       " 'Frauen sollten zu Hause bleiben und sich',\n",
       " 'Frauen sollten zu Hause bleiben und sich um',\n",
       " 'Frauen sollten zu Hause bleiben und sich um das',\n",
       " 'Frauen sollten zu Hause bleiben und sich um das Kind',\n",
       " 'Feministen',\n",
       " 'Feministen sind',\n",
       " 'Feministen sind überwiegend',\n",
       " 'Feministen sind überwiegend angetrieben',\n",
       " 'Feministen sind überwiegend angetrieben durch',\n",
       " 'Frauen',\n",
       " 'Frauen altern',\n",
       " 'Frauen altern wie',\n",
       " 'Frauen altern wie Milch,',\n",
       " 'Frauen altern wie Milch, Männer',\n",
       " 'Frauen altern wie Milch, Männer altern',\n",
       " 'Frauen altern wie Milch, Männer altern wie',\n",
       " 'Eine',\n",
       " 'Eine klassische',\n",
       " 'Eine klassische Rollenverteilung',\n",
       " 'Eine klassische Rollenverteilung in',\n",
       " 'Eine klassische Rollenverteilung in der',\n",
       " 'Eine klassische Rollenverteilung in der Ehe',\n",
       " 'Eine klassische Rollenverteilung in der Ehe ist',\n",
       " 'Eine klassische Rollenverteilung in der Ehe ist zu',\n",
       " 'Frauen',\n",
       " 'Frauen sind',\n",
       " 'Frauen sind für',\n",
       " 'Frauen sind für gewisse',\n",
       " 'Frauen sind für gewisse Berufen',\n",
       " 'Frauen sind für gewisse Berufen nicht',\n",
       " 'Gleichstellung',\n",
       " 'Gleichstellung der',\n",
       " 'Gleichstellung der Geschlechter',\n",
       " 'Gleichstellung der Geschlechter ist',\n",
       " 'Gleichstellung der Geschlechter ist eine',\n",
       " 'Gleichstellung der Geschlechter ist eine Überbevorteilung',\n",
       " 'Gleichstellung der Geschlechter ist eine Überbevorteilung von',\n",
       " 'Frauen',\n",
       " 'Frauen in',\n",
       " 'Frauen in führenden',\n",
       " 'Frauen in führenden Positionen',\n",
       " 'Frauen in führenden Positionen haben',\n",
       " 'Frauen in führenden Positionen haben häufig',\n",
       " 'Frauen in führenden Positionen haben häufig komplizierte',\n",
       " 'Frauen',\n",
       " 'Frauen gehören',\n",
       " 'Frauen gehören in',\n",
       " 'Frauen gehören in die',\n",
       " 'Frauen',\n",
       " 'Frauen sollten',\n",
       " 'Frauen sollten ihre',\n",
       " 'Frauen sollten ihre klassische',\n",
       " 'Frauen sollten ihre klassische Geschlechterrolle',\n",
       " 'Alles',\n",
       " 'Alles was',\n",
       " 'Alles was eine',\n",
       " 'Alles was eine Frau',\n",
       " 'Alles was eine Frau tun',\n",
       " 'Alles was eine Frau tun muss,',\n",
       " 'Alles was eine Frau tun muss, ist',\n",
       " 'Alles was eine Frau tun muss, ist ihren',\n",
       " 'Alles was eine Frau tun muss, ist ihren Mann',\n",
       " 'Alles was eine Frau tun muss, ist ihren Mann zu',\n",
       " 'Frauen',\n",
       " 'Frauen machen',\n",
       " 'Frauen machen jedes',\n",
       " 'Frauen machen jedes wirtschaftliche',\n",
       " 'Frauen machen jedes wirtschaftliche Unternehmen',\n",
       " 'Männer',\n",
       " 'Männer und',\n",
       " 'Männer und Frauen',\n",
       " 'Männer und Frauen sind',\n",
       " 'Männer und Frauen sind gleich',\n",
       " 'Frauen',\n",
       " 'Frauen können',\n",
       " 'Frauen können ohne',\n",
       " 'Frauen können ohne Kinder',\n",
       " 'Frauen können ohne Kinder glücklich',\n",
       " 'Frauen',\n",
       " 'Frauen sind',\n",
       " 'Frauen sind nicht',\n",
       " 'Frauen sind nicht schwach',\n",
       " 'Frauen sind nicht schwach und',\n",
       " 'Frauen sind nicht schwach und sollten',\n",
       " 'Frauen sind nicht schwach und sollten sich',\n",
       " 'Frauen sind nicht schwach und sollten sich so',\n",
       " 'Frauen sind nicht schwach und sollten sich so auch',\n",
       " 'Frauen sind nicht schwach und sollten sich so auch nicht',\n",
       " 'Frauen',\n",
       " 'Frauen sollen',\n",
       " 'Frauen sollen das',\n",
       " 'Frauen sollen das gleiche',\n",
       " 'Frauen sollen das gleiche machen',\n",
       " 'Frauen sollen das gleiche machen dürfen',\n",
       " 'Frauen sollen das gleiche machen dürfen wie',\n",
       " 'Beide',\n",
       " 'Beide Geschlechter',\n",
       " 'Beide Geschlechter sollten',\n",
       " 'Beide Geschlechter sollten gleich',\n",
       " 'Beide Geschlechter sollten gleich bezahlt',\n",
       " 'Gleichberechtigung',\n",
       " 'Gleichberechtigung ist',\n",
       " 'Gleichberechtigung ist eine',\n",
       " 'Gleichberechtigung ist eine menschenrechtliche',\n",
       " 'Väter',\n",
       " 'Väter müssen',\n",
       " 'Väter müssen im',\n",
       " 'Väter müssen im gleichen',\n",
       " 'Väter müssen im gleichen Umfang',\n",
       " 'Väter müssen im gleichen Umfang wie',\n",
       " 'Väter müssen im gleichen Umfang wie Mütter',\n",
       " 'Väter müssen im gleichen Umfang wie Mütter Verantwortung',\n",
       " 'Väter müssen im gleichen Umfang wie Mütter Verantwortung für',\n",
       " 'Väter müssen im gleichen Umfang wie Mütter Verantwortung für ihre',\n",
       " 'Väter müssen im gleichen Umfang wie Mütter Verantwortung für ihre Kinder',\n",
       " 'Die',\n",
       " 'Die Geschlechter',\n",
       " 'Die Geschlechter sind',\n",
       " 'Die Geschlechter sind nicht',\n",
       " 'Die Geschlechter sind nicht immer',\n",
       " 'Die Geschlechter sind nicht immer gleich,',\n",
       " 'Die Geschlechter sind nicht immer gleich, jedoch',\n",
       " 'Die Geschlechter sind nicht immer gleich, jedoch nicht',\n",
       " 'Alleinerziehende',\n",
       " 'Alleinerziehende Mütter',\n",
       " 'Alleinerziehende Mütter sind',\n",
       " 'Es',\n",
       " 'Es gibt',\n",
       " 'Es gibt Frauenberufe',\n",
       " 'Es gibt Frauenberufe und',\n",
       " 'Es gibt Frauenberufe und es',\n",
       " 'Es gibt Frauenberufe und es gibt',\n",
       " 'Männer',\n",
       " 'Männer fühlen',\n",
       " 'Männer fühlen sich',\n",
       " 'Männer fühlen sich von',\n",
       " 'Männer fühlen sich von Frauen',\n",
       " 'Männer fühlen sich von Frauen in',\n",
       " 'Männer fühlen sich von Frauen in Führungspositionen',\n",
       " 'Frauenquote',\n",
       " 'Frauenquote muss',\n",
       " 'Frauenquote muss überall',\n",
       " 'Männer',\n",
       " 'Männer und',\n",
       " 'Männer und Frauen',\n",
       " 'Männer und Frauen sind',\n",
       " 'Männer und Frauen sind in',\n",
       " 'Männer und Frauen sind in einer',\n",
       " 'Männer und Frauen sind in einer traditionellen',\n",
       " 'Männer und Frauen sind in einer traditionellen Familie',\n",
       " 'Männer und Frauen sind in einer traditionellen Familie am',\n",
       " 'Frauen',\n",
       " 'Frauen sind',\n",
       " 'Frauen sind bei',\n",
       " 'Frauen sind bei Sorgerechtsfragen',\n",
       " 'Frauen',\n",
       " 'Frauen haben',\n",
       " 'Frauen haben große',\n",
       " 'Frauen haben große Vorteile',\n",
       " 'Frauen haben große Vorteile bei',\n",
       " 'Frauen haben große Vorteile bei Gerichtsentscheidungen',\n",
       " 'Frauen haben große Vorteile bei Gerichtsentscheidungen über',\n",
       " 'Frauen haben große Vorteile bei Gerichtsentscheidungen über den',\n",
       " 'Frauen haben große Vorteile bei Gerichtsentscheidungen über den Verbleib',\n",
       " 'Frauen haben große Vorteile bei Gerichtsentscheidungen über den Verbleib der',\n",
       " 'Frauen haben große Vorteile bei Gerichtsentscheidungen über den Verbleib der eigenen',\n",
       " 'Frauen',\n",
       " 'Frauen sind',\n",
       " 'Frauen sind im',\n",
       " 'Frauen sind im Durchschnitt',\n",
       " 'Frauen sind im Durchschnitt schwächer',\n",
       " 'Frauen sind im Durchschnitt schwächer als',\n",
       " 'Frauen sind im Durchschnitt schwächer als Männer',\n",
       " 'Frauen sind im Durchschnitt schwächer als Männer in',\n",
       " 'Frauen sind im Durchschnitt schwächer als Männer in physischen',\n",
       " 'Die',\n",
       " 'Die Gender-Pay-Gap',\n",
       " 'Die Gender-Pay-Gap ist',\n",
       " 'Die Gender-Pay-Gap ist kein',\n",
       " 'Die Gender-Pay-Gap ist kein Problem',\n",
       " 'Die Gender-Pay-Gap ist kein Problem des',\n",
       " 'Frauen',\n",
       " 'Frauen können',\n",
       " 'Frauen können sich',\n",
       " 'Frauen können sich besser',\n",
       " 'Frauen können sich besser um',\n",
       " 'Frauen können sich besser um Kinder',\n",
       " 'Frauen können sich besser um Kinder und',\n",
       " 'Frauen können sich besser um Kinder und Familie',\n",
       " 'Frauen können sich besser um Kinder und Familie kümmern,',\n",
       " 'Frauen können sich besser um Kinder und Familie kümmern, es',\n",
       " 'Frauen können sich besser um Kinder und Familie kümmern, es liegt',\n",
       " 'Frauen können sich besser um Kinder und Familie kümmern, es liegt in',\n",
       " 'Frauen können sich besser um Kinder und Familie kümmern, es liegt in ihrer',\n",
       " 'Spezielle',\n",
       " 'Spezielle Frauenquoten',\n",
       " 'Spezielle Frauenquoten ',\n",
       " 'Spezielle Frauenquoten  sind',\n",
       " 'Spezielle Frauenquoten  sind unnötig',\n",
       " 'Spezielle Frauenquoten  sind unnötig und',\n",
       " 'Männer',\n",
       " 'Männer sind',\n",
       " 'Männer',\n",
       " 'Männer sind',\n",
       " 'Männer sind dümmer',\n",
       " 'Männer sind dümmer als',\n",
       " 'Männer',\n",
       " 'Männer sind',\n",
       " 'Männer sind unzuverlässiger',\n",
       " 'Männer sind unzuverlässiger als',\n",
       " 'Alle',\n",
       " 'Alle Männer',\n",
       " 'Alle Männer ',\n",
       " 'Alle Männer  sind',\n",
       " 'Männer',\n",
       " 'Männer sind',\n",
       " 'Männer sind nicht',\n",
       " 'Männer sind nicht die',\n",
       " 'Der',\n",
       " 'Der Mann',\n",
       " 'Der Mann verprasst',\n",
       " 'Der Mann verprasst das',\n",
       " 'Männer',\n",
       " 'Männer gehören',\n",
       " 'Männer gehören auf',\n",
       " 'Männer gehören auf den',\n",
       " 'Männer',\n",
       " 'Männer sind',\n",
       " 'Männer sind bei',\n",
       " 'Männer sind bei Stellenvergaben',\n",
       " 'Männer',\n",
       " 'Männer verbingen',\n",
       " 'Männer verbingen wenig',\n",
       " 'Männer verbingen wenig Zeit',\n",
       " 'Männer verbingen wenig Zeit mit',\n",
       " 'Männer verbingen wenig Zeit mit ihren',\n",
       " 'Alle',\n",
       " 'Alle Männer',\n",
       " 'Alle Männer sind',\n",
       " 'Alle Männer sind ausgewachsene',\n",
       " 'Pokemons',\n",
       " 'Pokemons haben',\n",
       " 'Pokemons haben einen',\n",
       " 'Pokemons haben einen signifikant',\n",
       " 'Pokemons haben einen signifikant geringeren',\n",
       " 'Kinder',\n",
       " 'Kinder sind',\n",
       " 'Kinder sind psychisch',\n",
       " 'Kinder sind psychisch nicht',\n",
       " 'Kinder sind psychisch nicht für',\n",
       " 'Kinder sind psychisch nicht für komplexe',\n",
       " 'Kinder sind psychisch nicht für komplexe Arbeit',\n",
       " 'Kinder',\n",
       " 'Kinder haben',\n",
       " 'Kinder haben im',\n",
       " 'Kinder haben im statistischen',\n",
       " 'Kinder haben im statistischen Mittel',\n",
       " 'Kinder haben im statistischen Mittel ein',\n",
       " 'Kinder haben im statistischen Mittel ein kleineres',\n",
       " 'Egoismus',\n",
       " 'Egoismus hat',\n",
       " 'Egoismus hat fast',\n",
       " 'Egoismus hat fast nur',\n",
       " 'Egoismus hat fast nur Nachteile',\n",
       " 'Egoismus hat fast nur Nachteile für',\n",
       " 'Egoismus hat fast nur Nachteile für die',\n",
       " 'Fische',\n",
       " 'Fische sind',\n",
       " 'Fische sind im',\n",
       " 'Fische sind im Durchschnitt',\n",
       " 'Fische sind im Durchschnitt dümmer',\n",
       " 'Fische sind im Durchschnitt dümmer als',\n",
       " 'Hunde',\n",
       " 'Hunde sind',\n",
       " 'Hunde sind Menschen',\n",
       " 'Hunde sind Menschen geistig',\n",
       " 'Hunde sind Menschen geistig in',\n",
       " 'Hunde sind Menschen geistig in einigen',\n",
       " 'Hunde sind Menschen geistig in einigen Bereichen',\n",
       " 'Kricketteams',\n",
       " 'Kricketteams ',\n",
       " 'Kricketteams  sind',\n",
       " 'Kricketteams  sind Minderleister',\n",
       " 'Kricketteams  sind Minderleister in',\n",
       " 'Kricketteams  sind Minderleister in unseren',\n",
       " 'Minions',\n",
       " 'Minions können',\n",
       " 'Minions können nichts',\n",
       " 'Minions können nichts und',\n",
       " 'Minions können nichts und sind',\n",
       " 'Minions können nichts und sind zu',\n",
       " 'Regen',\n",
       " 'Regen ruiniert',\n",
       " 'Regen ruiniert oft',\n",
       " 'Regen ruiniert oft den',\n",
       " 'Regen ruiniert oft den größten',\n",
       " 'Die',\n",
       " 'Die #keinurlaub-Bewegung',\n",
       " 'Die #keinurlaub-Bewegung ist',\n",
       " 'Babysitter',\n",
       " 'Babysitter sollten',\n",
       " 'Babysitter sollten zu',\n",
       " 'Babysitter sollten zu Hause',\n",
       " 'Babysitter sollten zu Hause bleiben',\n",
       " 'Babysitter sollten zu Hause bleiben und',\n",
       " 'Babysitter sollten zu Hause bleiben und sich',\n",
       " 'Babysitter sollten zu Hause bleiben und sich um',\n",
       " 'Babysitter sollten zu Hause bleiben und sich um das',\n",
       " 'Babysitter sollten zu Hause bleiben und sich um das Kind',\n",
       " 'Wissenschaftler',\n",
       " 'Wissenschaftler sind',\n",
       " 'Wissenschaftler sind überwiegend',\n",
       " 'Wissenschaftler sind überwiegend angetrieben',\n",
       " 'Wissenschaftler sind überwiegend angetrieben durch',\n",
       " 'Programme',\n",
       " 'Programme altern',\n",
       " 'Programme altern wie',\n",
       " 'Programme altern wie Milch,',\n",
       " 'Programme altern wie Milch, Programmierer',\n",
       " 'Programme altern wie Milch, Programmierer altern',\n",
       " 'Programme altern wie Milch, Programmierer altern wie',\n",
       " 'Ein',\n",
       " 'Ein gesundes',\n",
       " 'Ein gesundes Sexualleben',\n",
       " 'Ein gesundes Sexualleben in',\n",
       " 'Ein gesundes Sexualleben in der',\n",
       " 'Ein gesundes Sexualleben in der Ehe',\n",
       " 'Ein gesundes Sexualleben in der Ehe ist',\n",
       " 'Ein gesundes Sexualleben in der Ehe ist zu',\n",
       " 'Nachteulen',\n",
       " 'Nachteulen ',\n",
       " 'Nachteulen  sind',\n",
       " 'Nachteulen  sind für',\n",
       " 'Nachteulen  sind für bestimmte',\n",
       " 'Nachteulen  sind für bestimmte Berufe',\n",
       " 'Nachteulen  sind für bestimmte Berufe nicht',\n",
       " 'Gleichstellung',\n",
       " 'Gleichstellung der',\n",
       " 'Gleichstellung der Geschlechter',\n",
       " 'Gleichstellung der Geschlechter findet',\n",
       " 'Gleichstellung der Geschlechter findet zunehmend',\n",
       " 'Gleichstellung der Geschlechter findet zunehmend häufiger',\n",
       " 'Menschen',\n",
       " 'Menschen in',\n",
       " 'Menschen in führenden',\n",
       " 'Menschen in führenden Positionen',\n",
       " 'Menschen in führenden Positionen haben',\n",
       " 'Menschen in führenden Positionen haben häufig',\n",
       " 'Menschen in führenden Positionen haben häufig komplizierte',\n",
       " 'Töpfe',\n",
       " 'Töpfe gehören',\n",
       " 'Töpfe gehören in',\n",
       " 'Töpfe gehören in die',\n",
       " 'Hühner',\n",
       " 'Hühner sollten',\n",
       " 'Hühner sollten ihre',\n",
       " 'Hühner sollten ihre klassische',\n",
       " 'Hühner sollten ihre klassische Gluckenrolle',\n",
       " 'Alles',\n",
       " 'Alles was',\n",
       " 'Alles was ein',\n",
       " 'Alles was ein Film',\n",
       " 'Alles was ein Film tun',\n",
       " 'Alles was ein Film tun muss,',\n",
       " 'Alles was ein Film tun muss, ist',\n",
       " 'Alles was ein Film tun muss, ist seine',\n",
       " 'Alles was ein Film tun muss, ist seine Zuschauer',\n",
       " 'Alles was ein Film tun muss, ist seine Zuschauer zu',\n",
       " 'Frauen',\n",
       " 'Frauen haben',\n",
       " 'Frauen haben einen',\n",
       " 'Frauen haben einen signifikant',\n",
       " 'Frauen haben einen signifikant höre',\n",
       " 'Frauen haben einen signifikant höre Schmerztoleranz',\n",
       " 'Frauen',\n",
       " 'Frauen sind',\n",
       " 'Frauen sind psychisch',\n",
       " 'Frauen sind psychisch für',\n",
       " 'Frauen sind psychisch für komplexe',\n",
       " 'Frauen sind psychisch für komplexe Arbeit',\n",
       " 'Frauen',\n",
       " 'Frauen haben',\n",
       " 'Frauen haben im',\n",
       " 'Frauen haben im statistischen',\n",
       " 'Frauen haben im statistischen Mittel',\n",
       " 'Frauen haben im statistischen Mittel in',\n",
       " 'Frauen haben im statistischen Mittel in einen',\n",
       " 'Frauen haben im statistischen Mittel in einen größeren',\n",
       " 'Frauenförderung',\n",
       " 'Frauenförderung hat',\n",
       " 'Frauenförderung hat fast',\n",
       " 'Frauenförderung hat fast nur',\n",
       " 'Frauenförderung hat fast nur Vorteile',\n",
       " 'Frauenförderung hat fast nur Vorteile für',\n",
       " 'Frauenförderung hat fast nur Vorteile für die',\n",
       " 'Frauen',\n",
       " 'Frauen sind',\n",
       " 'Frauen sind im',\n",
       " 'Frauen sind im Durchschnitt',\n",
       " 'Frauen sind im Durchschnitt sozialer',\n",
       " 'Frauen sind im Durchschnitt sozialer als',\n",
       " 'Frauen',\n",
       " 'Frauen sind',\n",
       " 'Frauen sind Männern',\n",
       " 'Frauen sind Männern im',\n",
       " 'Frauen sind Männern im Erinnerungsvermögen',\n",
       " 'Frauen',\n",
       " 'Frauen sind',\n",
       " 'Frauen sind Säulen',\n",
       " 'Frauen sind Säulen in',\n",
       " 'Frauen sind Säulen in unserer',\n",
       " 'Frauen',\n",
       " 'Frauen können',\n",
       " 'Frauen können alles',\n",
       " 'Frauen können alles und',\n",
       " 'Frauen können alles und sind',\n",
       " 'Frauen können alles und sind sehr',\n",
       " 'Frauen',\n",
       " 'Frauen schaffen',\n",
       " 'Frauen schaffen oft',\n",
       " 'Frauen schaffen oft den',\n",
       " 'Frauen schaffen oft den größten',\n",
       " 'Die',\n",
       " 'Die #metoo-Bewegung',\n",
       " 'Die #metoo-Bewegung ist',\n",
       " 'Frauen',\n",
       " 'Frauen sollten',\n",
       " 'Frauen sollten nicht',\n",
       " 'Frauen sollten nicht zu',\n",
       " 'Frauen sollten nicht zu Hause',\n",
       " 'Frauen sollten nicht zu Hause bleiben',\n",
       " 'Frauen sollten nicht zu Hause bleiben und',\n",
       " 'Frauen sollten nicht zu Hause bleiben und sich',\n",
       " 'Frauen sollten nicht zu Hause bleiben und sich um',\n",
       " 'Frauen sollten nicht zu Hause bleiben und sich um ihre',\n",
       " 'Frauen sollten nicht zu Hause bleiben und sich um ihre Karriere',\n",
       " 'Feministen',\n",
       " 'Feministen sind',\n",
       " 'Feministen sind überwiegend',\n",
       " 'Feministen sind überwiegend angetrieben',\n",
       " 'Feministen sind überwiegend angetrieben durch',\n",
       " 'Gerüchte',\n",
       " 'Gerüchte ',\n",
       " 'Gerüchte  altern',\n",
       " 'Gerüchte  altern wie',\n",
       " 'Gerüchte  altern wie Milch,',\n",
       " 'Gerüchte  altern wie Milch, Frauen',\n",
       " 'Gerüchte  altern wie Milch, Frauen altern',\n",
       " 'Gerüchte  altern wie Milch, Frauen altern wie',\n",
       " 'Eine',\n",
       " 'Eine moderne',\n",
       " 'Eine moderne Rollenverteilung',\n",
       " 'Eine moderne Rollenverteilung in',\n",
       " 'Eine moderne Rollenverteilung in der',\n",
       " 'Eine moderne Rollenverteilung in der Ehe',\n",
       " 'Eine moderne Rollenverteilung in der Ehe ist',\n",
       " 'Eine moderne Rollenverteilung in der Ehe ist zu',\n",
       " 'Frauen',\n",
       " 'Frauen sind',\n",
       " 'Frauen sind für',\n",
       " 'Frauen sind für alle',\n",
       " 'Frauen sind für alle Berufe',\n",
       " 'Frauen sind für alle Berufe gut',\n",
       " 'Gleichstellung',\n",
       " 'Gleichstellung der',\n",
       " 'Gleichstellung der Geschlechter',\n",
       " 'Gleichstellung der Geschlechter ist',\n",
       " 'Gleichstellung der Geschlechter ist ein',\n",
       " 'Gleichstellung der Geschlechter ist ein Traum',\n",
       " 'Gleichstellung der Geschlechter ist ein Traum der',\n",
       " 'Frauen',\n",
       " 'Frauen in',\n",
       " 'Frauen in führenden',\n",
       " 'Frauen in führenden Positionen',\n",
       " 'Frauen in führenden Positionen haben',\n",
       " 'Frauen in führenden Positionen haben häufig',\n",
       " 'Frauen in führenden Positionen haben häufig starke',\n",
       " 'Frauen',\n",
       " 'Frauen gehören',\n",
       " 'Frauen gehören in',\n",
       " 'Frauen gehören in die',\n",
       " 'Frauen',\n",
       " 'Frauen sollten',\n",
       " 'Frauen sollten ihren',\n",
       " 'Frauen sollten ihren Traumberuf',\n",
       " 'Alles',\n",
       " 'Alles was',\n",
       " 'Alles was eine',\n",
       " 'Alles was eine Frau',\n",
       " 'Alles was eine Frau tun',\n",
       " 'Alles was eine Frau tun muss,',\n",
       " 'Alles was eine Frau tun muss, ist',\n",
       " 'Alles was eine Frau tun muss, ist ihre',\n",
       " 'Alles was eine Frau tun muss, ist ihre Wünsche',\n",
       " 'Alles was eine Frau tun muss, ist ihre Wünsche zu',\n",
       " 'Männer',\n",
       " 'Männer sind',\n",
       " 'Männer sind im',\n",
       " 'Männer sind im Schnitt',\n",
       " 'Männer sind im Schnitt biologisch',\n",
       " 'Alle',\n",
       " 'Alle Feministinnen',\n",
       " 'Alle Feministinnen sind',\n",
       " 'Ab',\n",
       " 'Ab und',\n",
       " 'Ab und zu',\n",
       " 'Ab und zu eine',\n",
       " 'Ab und zu eine erzieherische',\n",
       " 'Ab und zu eine erzieherische Ohrfeige',\n",
       " 'Ab und zu eine erzieherische Ohrfeige hat',\n",
       " 'Ab und zu eine erzieherische Ohrfeige hat noch',\n",
       " 'Ab und zu eine erzieherische Ohrfeige hat noch niemand',\n",
       " 'Ab und zu eine erzieherische Ohrfeige hat noch niemand geschadet,',\n",
       " 'Ab und zu eine erzieherische Ohrfeige hat noch niemand geschadet, auch',\n",
       " 'Ab und zu eine erzieherische Ohrfeige hat noch niemand geschadet, auch nicht',\n",
       " 'Ab und zu eine erzieherische Ohrfeige hat noch niemand geschadet, auch nicht Mickey',\n",
       " 'Der',\n",
       " 'Der aktuelle',\n",
       " 'Der aktuelle Drang',\n",
       " 'Der aktuelle Drang zur',\n",
       " 'Der aktuelle Drang zur Emanzipation',\n",
       " 'Der aktuelle Drang zur Emanzipation schlägt',\n",
       " 'Der aktuelle Drang zur Emanzipation schlägt teilweise',\n",
       " 'Der aktuelle Drang zur Emanzipation schlägt teilweise um',\n",
       " 'Der aktuelle Drang zur Emanzipation schlägt teilweise um in',\n",
       " 'Der aktuelle Drang zur Emanzipation schlägt teilweise um in eine']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oalacam/projects/gaze4hate/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer, AutoModel, AutoConfig, utils\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import functional as F\n",
    "from scipy.stats import entropy\n",
    "from statistics import mean, median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using GPT, compute probability over its entire vocabulary, returning logits, ranks, entropy_lists and attention maps\n",
    "def get_gpt_predictions(masked_sentence_list, label_list, vocabulary=None):\n",
    "    \"\"\"\n",
    "    Reproduces what get_bert_predictions() does for the gpt model\n",
    "    (i.e. compute probability over its entire vocabulary, returning logits, ranks, entropy_lists and attention maps).\n",
    "    \n",
    "    If vocabulary = None (default), then the computed values for the (sub-)tokens refer to the entire GPT vocabulary.\n",
    "    \n",
    "    If vocabulary != None, then the computed values for the tokens are calculated only for the vocabulary\n",
    "    that appeared in the human produced data, i.e. the vocabulary that is passed as \"vocabulary\"\n",
    "    (*** --> I'm not so sure about these values here !! This is still work in progress***)\n",
    "    \n",
    "    \"\"\"\n",
    "    if vocabulary is not None:\n",
    "        ### add tokens from the vocabulary to the tokenizer and resize model embeddings\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/german-gpt2\",output_hidden_states=True, return_dict=True, output_attentions=True)\n",
    "        model = AutoModelWithLMHead.from_pretrained(\"dbmdz/german-gpt2\",output_hidden_states=True, return_dict=True, output_attentions=True)\n",
    "        #print(\"Add vocabulary to the tokenizer...\")\n",
    "        tokenizer.add_tokens(vocabulary)\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/german-gpt2\",output_hidden_states=True, return_dict=True, output_attentions=True)\n",
    "        model = AutoModelWithLMHead.from_pretrained(\"dbmdz/german-gpt2\",output_hidden_states=True, return_dict=True, output_attentions=True)\n",
    "\n",
    "    scores=[]\n",
    "    ranks=[]\n",
    "    entropy_list =[]\n",
    "    target_probabilities =[]\n",
    "    target_prob=[]\n",
    "    attention_list = []\n",
    "    \n",
    "    input_text_list = []\n",
    "    target_text_list = []\n",
    "\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    \n",
    "    for i,sentence in enumerate(masked_sentence_list):\n",
    "        #print(i, \"sentence:\", sentence)\n",
    "        \n",
    "        input = tokenizer(sentence, return_tensors='pt', padding='longest')\n",
    "        #print(\"sentence tokenized (input):\", input)\n",
    "        input_text = tokenizer.convert_ids_to_tokens(input['input_ids'][0])\n",
    "        #print(\"input_ids converted to tokens (input_text):\", input_text)\n",
    "        \n",
    "        ### mask index = place of the MASK token in the tensor;\n",
    "        ### here it is an \"x\" token instead of MASK\n",
    "        mask_index = len(input[\"input_ids\"][0])-1  #named liked that so it mirrors  Özge's code\n",
    "        #print(\"Mask index:\", mask_index)\n",
    "       \n",
    "        ### encode the corresponding label from the label list as the target token\n",
    "        #print(\"Label/Target token from the label list:\", label_list[i])\n",
    "        target_token = tokenizer(label_list[i], return_tensors = \"pt\")\n",
    "        #print('Target token encoded: ', target_token)\n",
    "        target_text = tokenizer.convert_ids_to_tokens(target_token['input_ids'][0])\n",
    "        #print('Target text converted to tokens: ', target_text) \n",
    "        \n",
    "        input_text_list.append(input_text)\n",
    "        target_text_list.append(target_text)\n",
    "        #print(\"input_text_list\", input_text_list)\n",
    "        #print(\"target_text_list\", target_text_list)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(**input, \n",
    "                          output_attentions=True)\n",
    "        \n",
    "        ### softmax/ get probabilities \n",
    "        softmax = F.softmax(output.logits[0], dim=-1)\n",
    "        #print(\"softmax:\", softmax)\n",
    "        #print(\"dimension softmax:\", softmax.size())\n",
    "        maskP=[]\n",
    "        \n",
    "        ### attentions\n",
    "        attention_scores = output.attentions#[0].detach().cpu().numpy() # extract the attention scores from all layers\n",
    "        attention_list.append(attention_scores)\n",
    "        #print(\"Attention scores:\", attention_scores)\n",
    "        \n",
    "        ## initialize variables rank_min and avg_token_entropy\n",
    "        rank_min = softmax.size(1) \n",
    "        avg_token_entropy = 0.0   \n",
    "    \n",
    "        ## now iterate over each token in the target_text\n",
    "        for token in target_text:\n",
    "            ## For each token, calculate the probability (tokenP)\n",
    "            print('--------------------------') \n",
    "            print(\"Target token:\", token)\n",
    "            token_idx = tokenizer.encode(token)[0]\n",
    "            print(\"token_idx:\", token_idx)\n",
    "\n",
    "            tokenP = softmax[mask_index, token_idx].item()\n",
    "            #print(\"Token probability (for x-token position):\", tokenP)\n",
    "            ## i.e. probability of word to be the last token\n",
    "            ## I replaced the MASK-token with an \"x\"\n",
    "            \n",
    "            ### Either: restrict calculation to given vocabulary (** not so sure about this option **)\n",
    "            if vocabulary is not None:\n",
    "                ## initialize mask_over_vocab_list as an array of zeros with the length of the vocabulary\n",
    "                ## this array will store the probabilities of each token in the vocabulary at the \"mask\" position:\n",
    "                mask_over_vocab_list = np.zeros(len(vocabulary))\n",
    "                ## iterate over the token in the vocabulary:\n",
    "                for j, vocab_token in enumerate(vocabulary):\n",
    "                    # print(j, vocab_token)\n",
    "                    ## obtain the token index of the current vocabulary token: \n",
    "                    vocab_token_idx = tokenizer.encode(vocab_token)[0]\n",
    "                    ## use this index to access the corresponding probability in the softmax tensor at the x-position\n",
    "                    ## and assign the probability of the vocabulary token to the corresponding index: \n",
    "                    mask_over_vocab_list[j] = softmax[mask_index, vocab_token_idx].item()\n",
    "                    \n",
    "            ### Or: calculate values for GPT's entire vocabulary...       \n",
    "            else: \n",
    "                mask_over_vocab_list = softmax[torch.tensor([mask_index], dtype=torch.long)].numpy()[0]\n",
    "\n",
    "            #### \n",
    "            #print(\"probabilities over the vocabulary for the mask position (mask over vocab list):\", mask_over_vocab_list)\n",
    "            #print(\"number of probabilities:\", len(mask_over_vocab_list))\n",
    "    \n",
    "            token_entropy = entropy(mask_over_vocab_list)\n",
    "            #print(\"entropy of these probabilities/ token entropy:\", token_entropy)\n",
    "            \n",
    "            ## Update the average token entropy accordingly:\n",
    "            avg_token_entropy += token_entropy\n",
    "        \n",
    "            ## sort the mask_over_vocab_list in descending order \n",
    "            sorted_array = np.sort(mask_over_vocab_list)\n",
    "            reverse_array = list(sorted_array[::-1])    \n",
    "                \n",
    "            ## find the rank of the current token's probability (tokenP) in this sorted list. \n",
    "            ## Özge: \"It is not the perfect solution , but it will give us a good estimate\"\n",
    "            rank = reverse_array.index(tokenP)\n",
    "            #print(\"current token's rank:\", rank)\n",
    "            \n",
    "            if rank <= rank_min:\n",
    "                ## store the minimum rank encountered in the variable rank_min:\n",
    "                rank_min = rank\n",
    "                \n",
    "            #print('Token and its rank: ', token, rank)\n",
    "                \n",
    "            ## append the tokenP to the maskP list.\n",
    "            maskP.append(tokenP) \n",
    "\n",
    "        #### For each sentence in the sentence list:\n",
    "        ## After iterating over all tokens, the average token entropy is divided by the number of tokens\n",
    "        ## to compute the average token entropy: \n",
    "        if avg_token_entropy>0:\n",
    "            \n",
    "            avg_token_entropy = avg_token_entropy/(len(target_text)) \n",
    "        \n",
    "        ## rank_min represents the rank of the target token with the lowest rank among all tokens:\n",
    "        target_rank = rank_min\n",
    "        \n",
    "        ## the mean of the probabilities in maskP represents the target probability:\n",
    "        print('maskP', maskP)\n",
    "        if maskP != []:\n",
    "            target_probability = mean(maskP)\n",
    "        \n",
    "        else:\n",
    "            print('WARNING: maskp is empty list', tokenP)\n",
    "            target_probability = 'warning'\n",
    "        \n",
    "        print(target_text)\n",
    "        print('-- Target Probability (mean of probabilities in maskP): ', target_probability)\n",
    "        print('-- Target Rank: ', target_rank)\n",
    "        print('-- Target Entropy: ', avg_token_entropy)                   \n",
    "        \n",
    "        scores.append(target_probability)\n",
    "        ranks.append(target_rank)\n",
    "        entropy_list.append(avg_token_entropy)\n",
    "        \n",
    "        #print(\"\\n \\n \\n\")\n",
    "            \n",
    "    return scores, ranks, entropy_list, attention_list, input_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oalacam/projects/gaze4hate/venv/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:1581: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Target token: haben\n",
      "token_idx: 4199\n",
      "maskP [7.831689799786545e-06]\n",
      "['haben']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.831689799786545e-06\n",
      "-- Target Rank:  5047\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: einen\n",
      "token_idx: 946\n",
      "maskP [5.625740868708817e-06]\n",
      "['einen']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.625740868708817e-06\n",
      "-- Target Rank:  5263\n",
      "-- Target Entropy:  5.9237775802612305\n",
      "--------------------------\n",
      "Target token: sign\n",
      "token_idx: 29597\n",
      "--------------------------\n",
      "Target token: if\n",
      "token_idx: 1038\n",
      "--------------------------\n",
      "Target token: ikant\n",
      "token_idx: 31257\n",
      "maskP [4.024438737815217e-08, 6.941044716768374e-08, 3.6256195962147686e-11]\n",
      "['sign', 'if', 'ikant']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.6563696913932686e-08\n",
      "-- Target Rank:  25273\n",
      "-- Target Entropy:  6.984785556793213\n",
      "--------------------------\n",
      "Target token: ger\n",
      "token_idx: 452\n",
      "--------------------------\n",
      "Target token: inger\n",
      "token_idx: 2099\n",
      "--------------------------\n",
      "Target token: en\n",
      "token_idx: 262\n",
      "maskP [2.3940708615555195e-06, 9.880496918412973e-07, 5.898429549233697e-07]\n",
      "['ger', 'inger', 'en']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.3239878361067288e-06\n",
      "-- Target Rank:  2117\n",
      "-- Target Entropy:  2.3598084449768066\n",
      "--------------------------\n",
      "Target token: Durch\n",
      "token_idx: 3285\n",
      "--------------------------\n",
      "Target token: setzungs\n",
      "token_idx: 21739\n",
      "--------------------------\n",
      "Target token: willen\n",
      "token_idx: 34177\n",
      "maskP [1.8152736629417632e-06, 9.085893704074977e-10, 3.961410754982353e-08]\n",
      "['Durch', 'setzungs', 'willen']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.185987866206647e-07\n",
      "-- Target Rank:  6482\n",
      "-- Target Entropy:  4.978734493255615\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [1.4102917702984996e-05]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.4102917702984996e-05\n",
      "-- Target Rank:  3473\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: psych\n",
      "token_idx: 19240\n",
      "--------------------------\n",
      "Target token: isch\n",
      "token_idx: 347\n",
      "maskP [2.215017502749106e-07, 1.2936357052240055e-07]\n",
      "['psych', 'isch']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.7543266039865557e-07\n",
      "-- Target Rank:  19598\n",
      "-- Target Entropy:  5.974837303161621\n",
      "--------------------------\n",
      "Target token: nicht\n",
      "token_idx: 7272\n",
      "maskP [2.4259602326992535e-08]\n",
      "['nicht']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.4259602326992535e-08\n",
      "-- Target Rank:  8509\n",
      "-- Target Entropy:  4.189533233642578\n",
      "--------------------------\n",
      "Target token: fÃ¼r\n",
      "token_idx: 74\n",
      "maskP [1.3353883332456462e-07]\n",
      "['fÃ¼r']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.3353883332456462e-07\n",
      "-- Target Rank:  5843\n",
      "-- Target Entropy:  3.754251718521118\n",
      "--------------------------\n",
      "Target token: komplex\n",
      "token_idx: 16054\n",
      "--------------------------\n",
      "Target token: e\n",
      "token_idx: 73\n",
      "maskP [3.471163552148937e-07, 4.483342308958527e-06]\n",
      "['komplex', 'e']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.41522933208671e-06\n",
      "-- Target Rank:  4741\n",
      "-- Target Entropy:  4.302783489227295\n",
      "--------------------------\n",
      "Target token: Arbeit\n",
      "token_idx: 13936\n",
      "maskP [4.0617314880364574e-06]\n",
      "['Arbeit']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.0617314880364574e-06\n",
      "-- Target Rank:  4703\n",
      "-- Target Entropy:  5.51590633392334\n",
      "--------------------------\n",
      "Target token: gesch\n",
      "token_idx: 877\n",
      "--------------------------\n",
      "Target token: affen\n",
      "token_idx: 1864\n",
      "maskP [4.1414809857087675e-06, 1.0112951365215395e-08]\n",
      "['gesch', 'affen']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.0757969685369915e-06\n",
      "-- Target Rank:  1801\n",
      "-- Target Entropy:  4.00680685043335\n",
      "--------------------------\n",
      "Target token: haben\n",
      "token_idx: 4199\n",
      "maskP [7.831689799786545e-06]\n",
      "['haben']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.831689799786545e-06\n",
      "-- Target Rank:  5047\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: im\n",
      "token_idx: 487\n",
      "maskP [2.638220621520304e-06]\n",
      "['im']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.638220621520304e-06\n",
      "-- Target Rank:  8218\n",
      "-- Target Entropy:  5.9237775802612305\n",
      "--------------------------\n",
      "Target token: stat\n",
      "token_idx: 2641\n",
      "--------------------------\n",
      "Target token: istischen\n",
      "token_idx: 2894\n",
      "maskP [7.190244843968685e-08, 4.743240467064425e-09]\n",
      "['stat', 'istischen']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.832284445337564e-08\n",
      "-- Target Rank:  18397\n",
      "-- Target Entropy:  4.608479976654053\n",
      "--------------------------\n",
      "Target token: Mittel\n",
      "token_idx: 10393\n",
      "maskP [9.931424074238748e-07]\n",
      "['Mittel']\n",
      "-- Target Probability (mean of probabilities in maskP):  9.931424074238748e-07\n",
      "-- Target Rank:  4017\n",
      "-- Target Entropy:  3.5405046939849854\n",
      "--------------------------\n",
      "Target token: ein\n",
      "token_idx: 272\n",
      "maskP [0.0005106838652864099]\n",
      "['ein']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0005106838652864099\n",
      "-- Target Rank:  248\n",
      "-- Target Entropy:  5.734947204589844\n",
      "--------------------------\n",
      "Target token: kleiner\n",
      "token_idx: 29047\n",
      "--------------------------\n",
      "Target token: es\n",
      "token_idx: 271\n",
      "maskP [2.923903821283602e-06, 1.7267288058064878e-05]\n",
      "['kleiner', 'es']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.009559593967424e-05\n",
      "-- Target Rank:  2532\n",
      "-- Target Entropy:  5.962045669555664\n",
      "--------------------------\n",
      "Target token: Allgemein\n",
      "token_idx: 15581\n",
      "--------------------------\n",
      "Target token: wissen\n",
      "token_idx: 3126\n",
      "maskP [7.545939428865722e-10, 1.0614976275746812e-07]\n",
      "['Allgemein', 'wissen']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.345217835017735e-08\n",
      "-- Target Rank:  14855\n",
      "-- Target Entropy:  4.395839691162109\n",
      "--------------------------\n",
      "Target token: hat\n",
      "token_idx: 8491\n",
      "maskP [1.822675585572142e-05]\n",
      "['hat']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.822675585572142e-05\n",
      "-- Target Rank:  2080\n",
      "-- Target Entropy:  4.973829746246338\n",
      "--------------------------\n",
      "Target token: fast\n",
      "token_idx: 5280\n",
      "maskP [1.6411373593427925e-08]\n",
      "['fast']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.6411373593427925e-08\n",
      "-- Target Rank:  30137\n",
      "-- Target Entropy:  4.812148571014404\n",
      "--------------------------\n",
      "Target token: nur\n",
      "token_idx: 12317\n",
      "maskP [2.7534313176147407e-06]\n",
      "['nur']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.7534313176147407e-06\n",
      "-- Target Rank:  2681\n",
      "-- Target Entropy:  4.575490474700928\n",
      "--------------------------\n",
      "Target token: Nacht\n",
      "token_idx: 18683\n",
      "--------------------------\n",
      "Target token: eile\n",
      "token_idx: 1827\n",
      "maskP [5.7228071170811745e-09, 3.2986904319187715e-09]\n",
      "['Nacht', 'eile']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.510748774499973e-09\n",
      "-- Target Rank:  33082\n",
      "-- Target Entropy:  4.362985610961914\n",
      "--------------------------\n",
      "Target token: fÃ¼r\n",
      "token_idx: 74\n",
      "maskP [3.318907033644791e-07]\n",
      "['fÃ¼r']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.318907033644791e-07\n",
      "-- Target Rank:  2460\n",
      "-- Target Entropy:  2.4276654720306396\n",
      "--------------------------\n",
      "Target token: die\n",
      "token_idx: 2327\n",
      "maskP [2.601173400762491e-05]\n",
      "['die']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.601173400762491e-05\n",
      "-- Target Rank:  910\n",
      "-- Target Entropy:  3.0315587520599365\n",
      "--------------------------\n",
      "Target token: Gesellschaft\n",
      "token_idx: 14026\n",
      "maskP [1.6237707995969686e-06]\n",
      "['Gesellschaft']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.6237707995969686e-06\n",
      "-- Target Rank:  8035\n",
      "-- Target Entropy:  5.397999286651611\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [1.4102917702984996e-05]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.4102917702984996e-05\n",
      "-- Target Rank:  3473\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: im\n",
      "token_idx: 487\n",
      "maskP [2.7128726287628524e-06]\n",
      "['im']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.7128726287628524e-06\n",
      "-- Target Rank:  7144\n",
      "-- Target Entropy:  5.974837303161621\n",
      "--------------------------\n",
      "Target token: Durchschnitt\n",
      "token_idx: 23778\n",
      "maskP [6.874789164612594e-07]\n",
      "['Durchschnitt']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.874789164612594e-07\n",
      "-- Target Rank:  12402\n",
      "-- Target Entropy:  5.6138529777526855\n",
      "--------------------------\n",
      "Target token: d\n",
      "token_idx: 72\n",
      "--------------------------\n",
      "Target token: Ã¼mmer\n",
      "token_idx: 3545\n",
      "maskP [1.544117731100414e-05, 4.302963318991715e-08]\n",
      "['d', 'Ã¼mmer']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.742103472097028e-06\n",
      "-- Target Rank:  1484\n",
      "-- Target Entropy:  5.349737644195557\n",
      "--------------------------\n",
      "Target token: als\n",
      "token_idx: 1239\n",
      "maskP [0.0001698968990240246]\n",
      "['als']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0001698968990240246\n",
      "-- Target Rank:  80\n",
      "-- Target Entropy:  2.020752429962158\n",
      "--------------------------\n",
      "Target token: MÃ¤nner\n",
      "token_idx: 49\n",
      "maskP [1.1725013848717936e-07]\n",
      "['MÃ¤nner']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.1725013848717936e-07\n",
      "-- Target Rank:  12257\n",
      "-- Target Entropy:  3.4793457984924316\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [1.4102917702984996e-05]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.4102917702984996e-05\n",
      "-- Target Rank:  3473\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: M\n",
      "token_idx: 49\n",
      "--------------------------\n",
      "Target token: Ã¤n\n",
      "token_idx: 3545\n",
      "--------------------------\n",
      "Target token: nern\n",
      "token_idx: 4279\n",
      "maskP [2.7607288757280912e-06, 5.919378622820659e-07, 1.6587744511298297e-08]\n",
      "['M', 'Ã¤n', 'nern']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.1230848275071519e-06\n",
      "-- Target Rank:  7091\n",
      "-- Target Entropy:  5.974837303161621\n",
      "--------------------------\n",
      "Target token: geist\n",
      "token_idx: 14935\n",
      "--------------------------\n",
      "Target token: ig\n",
      "token_idx: 371\n",
      "maskP [3.2016259865486063e-06, 1.7056589740604977e-06]\n",
      "['geist', 'ig']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.453642480304552e-06\n",
      "-- Target Rank:  3821\n",
      "-- Target Entropy:  5.306904315948486\n",
      "--------------------------\n",
      "Target token: in\n",
      "token_idx: 269\n",
      "maskP [3.7152585719013587e-07]\n",
      "['in']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.7152585719013587e-07\n",
      "-- Target Rank:  4817\n",
      "-- Target Entropy:  4.2140655517578125\n",
      "--------------------------\n",
      "Target token: ein\n",
      "token_idx: 272\n",
      "--------------------------\n",
      "Target token: igen\n",
      "token_idx: 565\n",
      "maskP [3.501718310872093e-05, 8.79095196637536e-09]\n",
      "['ein', 'igen']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.7512987030343652e-05\n",
      "-- Target Rank:  673\n",
      "-- Target Entropy:  3.8407161235809326\n",
      "--------------------------\n",
      "Target token: Ber\n",
      "token_idx: 2165\n",
      "--------------------------\n",
      "Target token: eichen\n",
      "token_idx: 3588\n",
      "maskP [2.6126807028958865e-07, 2.2428403667618113e-07]\n",
      "['Ber', 'eichen']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.427760534828849e-07\n",
      "-- Target Rank:  11401\n",
      "-- Target Entropy:  4.018017292022705\n",
      "--------------------------\n",
      "Target token: unter\n",
      "token_idx: 1408\n",
      "--------------------------\n",
      "Target token: legen\n",
      "token_idx: 1514\n",
      "maskP [3.654457714219461e-06, 3.106099155658626e-09]\n",
      "['unter', 'legen']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.82878190668756e-06\n",
      "-- Target Rank:  2336\n",
      "-- Target Entropy:  3.7260353565216064\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [1.4102917702984996e-05]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.4102917702984996e-05\n",
      "-- Target Rank:  3473\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: M\n",
      "token_idx: 49\n",
      "--------------------------\n",
      "Target token: inder\n",
      "token_idx: 958\n",
      "--------------------------\n",
      "Target token: leister\n",
      "token_idx: 22120\n",
      "maskP [2.7607288757280912e-06, 3.7332765145947633e-07, 7.366047327650449e-09]\n",
      "['M', 'inder', 'leister']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.0471408581717394e-06\n",
      "-- Target Rank:  7091\n",
      "-- Target Entropy:  5.974837303161621\n",
      "--------------------------\n",
      "Target token: in\n",
      "token_idx: 269\n",
      "maskP [0.002466177800670266]\n",
      "['in']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.002466177800670266\n",
      "-- Target Rank:  28\n",
      "-- Target Entropy:  3.0111446380615234\n",
      "--------------------------\n",
      "Target token: unser\n",
      "token_idx: 42614\n",
      "--------------------------\n",
      "Target token: er\n",
      "token_idx: 261\n",
      "maskP [2.479704562574625e-06, 2.9641746550623793e-06]\n",
      "['unser', 'er']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.721939608818502e-06\n",
      "-- Target Rank:  6846\n",
      "-- Target Entropy:  4.3068389892578125\n",
      "--------------------------\n",
      "Target token: Gesellschaft\n",
      "token_idx: 14026\n",
      "maskP [3.0473487640847452e-05]\n",
      "['Gesellschaft']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.0473487640847452e-05\n",
      "-- Target Rank:  1047\n",
      "-- Target Entropy:  3.3138697147369385\n",
      "--------------------------\n",
      "Target token: kÃ¶nnen\n",
      "token_idx: 79\n",
      "maskP [0.0002068869798677042]\n",
      "['kÃ¶nnen']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0002068869798677042\n",
      "-- Target Rank:  424\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: n\n",
      "token_idx: 82\n",
      "--------------------------\n",
      "Target token: ichts\n",
      "token_idx: 1701\n",
      "maskP [1.9385593077458907e-06, 7.219283304493729e-08]\n",
      "['n', 'ichts']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.005376070395414e-06\n",
      "-- Target Rank:  10255\n",
      "-- Target Entropy:  5.745215892791748\n",
      "--------------------------\n",
      "Target token: und\n",
      "token_idx: 283\n",
      "maskP [3.1595422456121014e-07]\n",
      "['und']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.1595422456121014e-07\n",
      "-- Target Rank:  7044\n",
      "-- Target Entropy:  4.175434589385986\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [9.319031960330904e-06]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  9.319031960330904e-06\n",
      "-- Target Rank:  2408\n",
      "-- Target Entropy:  5.351434707641602\n",
      "--------------------------\n",
      "Target token: zu\n",
      "token_idx: 636\n",
      "maskP [1.6589552842560806e-06]\n",
      "['zu']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.6589552842560806e-06\n",
      "-- Target Rank:  5497\n",
      "-- Target Entropy:  5.661146640777588\n",
      "--------------------------\n",
      "Target token: d\n",
      "token_idx: 72\n",
      "--------------------------\n",
      "Target token: umm\n",
      "token_idx: 4026\n",
      "maskP [3.639517217379762e-06, 2.590459189377725e-07]\n",
      "['d', 'umm']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.949281568158767e-06\n",
      "-- Target Rank:  3859\n",
      "-- Target Entropy:  5.421221733093262\n",
      "--------------------------\n",
      "Target token: ru\n",
      "token_idx: 504\n",
      "--------------------------\n",
      "Target token: inieren\n",
      "token_idx: 34230\n",
      "maskP [8.553460247640032e-06, 1.2318789321952295e-09]\n",
      "['ru', 'inieren']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.277346063286114e-06\n",
      "-- Target Rank:  4787\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: oft\n",
      "token_idx: 24700\n",
      "maskP [9.449256310745113e-08]\n",
      "['oft']\n",
      "-- Target Probability (mean of probabilities in maskP):  9.449256310745113e-08\n",
      "-- Target Rank:  26134\n",
      "-- Target Entropy:  5.536340713500977\n",
      "--------------------------\n",
      "Target token: den\n",
      "token_idx: 324\n",
      "maskP [1.8839089534594677e-05]\n",
      "['den']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.8839089534594677e-05\n",
      "-- Target Rank:  2234\n",
      "-- Target Entropy:  4.826251029968262\n",
      "--------------------------\n",
      "Target token: grÃ¶ÃŁten\n",
      "token_idx: 667\n",
      "maskP [4.526453434294808e-09]\n",
      "['grÃ¶ÃŁten']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.526453434294808e-09\n",
      "-- Target Rank:  32687\n",
      "-- Target Entropy:  6.522536277770996\n",
      "--------------------------\n",
      "Target token: Sp\n",
      "token_idx: 1571\n",
      "--------------------------\n",
      "Target token: aÃŁ\n",
      "token_idx: 69\n",
      "maskP [5.102707518744865e-07, 1.830068541153196e-08]\n",
      "['Sp', 'aÃŁ']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.642857186430092e-07\n",
      "-- Target Rank:  8919\n",
      "-- Target Entropy:  3.858914613723755\n",
      "--------------------------\n",
      "Target token: #\n",
      "token_idx: 7\n",
      "--------------------------\n",
      "Target token: met\n",
      "token_idx: 3183\n",
      "--------------------------\n",
      "Target token: oo\n",
      "token_idx: 5498\n",
      "--------------------------\n",
      "Target token: -\n",
      "token_idx: 17\n",
      "--------------------------\n",
      "Target token: Bewegung\n",
      "token_idx: 17576\n",
      "maskP [5.527759867618443e-07, 1.1221724207644002e-06, 1.6434421468147775e-07, 8.271169645013288e-05, 2.2373737351699674e-07]\n",
      "['#', 'met', 'oo', '-', 'Bewegung']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.6954945289171518e-05\n",
      "-- Target Rank:  2316\n",
      "-- Target Entropy:  8.566091537475586\n",
      "--------------------------\n",
      "Target token: ist\n",
      "token_idx: 510\n",
      "maskP [4.15797985624522e-05]\n",
      "['ist']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.15797985624522e-05\n",
      "-- Target Rank:  1014\n",
      "-- Target Entropy:  4.825689792633057\n",
      "--------------------------\n",
      "Target token: hy\n",
      "token_idx: 5248\n",
      "--------------------------\n",
      "Target token: ster\n",
      "token_idx: 569\n",
      "--------------------------\n",
      "Target token: isch\n",
      "token_idx: 347\n",
      "maskP [4.685098176082647e-08, 1.1321930060148588e-07, 1.374109359630893e-07]\n",
      "['hy', 'ster', 'isch']\n",
      "-- Target Probability (mean of probabilities in maskP):  9.916040610846721e-08\n",
      "-- Target Rank:  13553\n",
      "-- Target Entropy:  4.882268905639648\n",
      "--------------------------\n",
      "Target token: s\n",
      "token_idx: 87\n",
      "--------------------------\n",
      "Target token: oll\n",
      "token_idx: 701\n",
      "--------------------------\n",
      "Target token: ten\n",
      "token_idx: 310\n",
      "maskP [5.3167033911449835e-05, 1.0145470952238611e-07, 3.8750324165448546e-05]\n",
      "['s', 'oll', 'ten']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.067293759547359e-05\n",
      "-- Target Rank:  1307\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: zu\n",
      "token_idx: 636\n",
      "maskP [7.354933131864527e-06]\n",
      "['zu']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.354933131864527e-06\n",
      "-- Target Rank:  4813\n",
      "-- Target Entropy:  5.844089031219482\n",
      "--------------------------\n",
      "Target token: H\n",
      "token_idx: 44\n",
      "--------------------------\n",
      "Target token: ause\n",
      "token_idx: 5071\n",
      "maskP [1.115356008085655e-05, 3.0409730289449044e-09]\n",
      "['H', 'ause']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.578300526942748e-06\n",
      "-- Target Rank:  3923\n",
      "-- Target Entropy:  5.140537738800049\n",
      "--------------------------\n",
      "Target token: bleiben\n",
      "token_idx: 9343\n",
      "maskP [0.011696168221533298]\n",
      "['bleiben']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.011696168221533298\n",
      "-- Target Rank:  6\n",
      "-- Target Entropy:  3.847615957260132\n",
      "--------------------------\n",
      "Target token: und\n",
      "token_idx: 283\n",
      "maskP [5.447235162137076e-05]\n",
      "['und']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.447235162137076e-05\n",
      "-- Target Rank:  154\n",
      "-- Target Entropy:  2.405090093612671\n",
      "--------------------------\n",
      "Target token: sich\n",
      "token_idx: 12592\n",
      "maskP [1.1141091817989945e-05]\n",
      "['sich']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.1141091817989945e-05\n",
      "-- Target Rank:  2850\n",
      "-- Target Entropy:  5.333828449249268\n",
      "--------------------------\n",
      "Target token: um\n",
      "token_idx: 335\n",
      "maskP [1.8449808294462855e-06]\n",
      "['um']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.8449808294462855e-06\n",
      "-- Target Rank:  4387\n",
      "-- Target Entropy:  5.116806507110596\n",
      "--------------------------\n",
      "Target token: das\n",
      "token_idx: 5972\n",
      "maskP [9.043454156199005e-06]\n",
      "['das']\n",
      "-- Target Probability (mean of probabilities in maskP):  9.043454156199005e-06\n",
      "-- Target Rank:  1714\n",
      "-- Target Entropy:  3.764312505722046\n",
      "--------------------------\n",
      "Target token: Kind\n",
      "token_idx: 29273\n",
      "maskP [2.0109152956138132e-06]\n",
      "['Kind']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.0109152956138132e-06\n",
      "-- Target Rank:  4860\n",
      "-- Target Entropy:  3.5391924381256104\n",
      "--------------------------\n",
      "Target token: k\n",
      "token_idx: 79\n",
      "--------------------------\n",
      "Target token: Ã¼mmern\n",
      "token_idx: 3545\n",
      "maskP [3.485458728391677e-05, 3.3894089312980213e-08]\n",
      "['k', 'Ã¼mmern']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.7444240686614876e-05\n",
      "-- Target Rank:  155\n",
      "-- Target Entropy:  0.7465940117835999\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [8.489974788972177e-06]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  8.489974788972177e-06\n",
      "-- Target Rank:  3917\n",
      "-- Target Entropy:  5.148418426513672\n",
      "--------------------------\n",
      "Target token: Ã¼ber\n",
      "token_idx: 3545\n",
      "--------------------------\n",
      "Target token: wiegend\n",
      "token_idx: 5406\n",
      "maskP [1.8144466196190479e-07, 2.7343216402186954e-07]\n",
      "['Ã¼ber', 'wiegend']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.2743841299188716e-07\n",
      "-- Target Rank:  17529\n",
      "-- Target Entropy:  5.996739387512207\n",
      "--------------------------\n",
      "Target token: ange\n",
      "token_idx: 1209\n",
      "--------------------------\n",
      "Target token: trieben\n",
      "token_idx: 14671\n",
      "maskP [7.617370556545211e-08, 8.641156679090045e-10]\n",
      "['ange', 'trieben']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.851891061668056e-08\n",
      "-- Target Rank:  21439\n",
      "-- Target Entropy:  5.436563968658447\n",
      "--------------------------\n",
      "Target token: durch\n",
      "token_idx: 4148\n",
      "maskP [2.1080033548059873e-05]\n",
      "['durch']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.1080033548059873e-05\n",
      "-- Target Rank:  86\n",
      "-- Target Entropy:  1.1199722290039062\n",
      "--------------------------\n",
      "Target token: MÃ¤nner\n",
      "token_idx: 49\n",
      "--------------------------\n",
      "Target token: h\n",
      "token_idx: 76\n",
      "--------------------------\n",
      "Target token: ass\n",
      "token_idx: 630\n",
      "maskP [3.5437523138170945e-07, 6.089698558753298e-07, 1.0664656713288423e-07]\n",
      "['MÃ¤nner', 'h', 'ass']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.566638847966412e-07\n",
      "-- Target Rank:  13093\n",
      "-- Target Entropy:  4.542285919189453\n",
      "--------------------------\n",
      "Target token: altern\n",
      "token_idx: 26758\n",
      "maskP [4.858616193814669e-06]\n",
      "['altern']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.858616193814669e-06\n",
      "-- Target Rank:  6593\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: wie\n",
      "token_idx: 687\n",
      "maskP [7.279465080500813e-06]\n",
      "['wie']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.279465080500813e-06\n",
      "-- Target Rank:  1955\n",
      "-- Target Entropy:  4.679680824279785\n",
      "--------------------------\n",
      "Target token: Milch\n",
      "token_idx: 37619\n",
      "--------------------------\n",
      "Target token: ,\n",
      "token_idx: 16\n",
      "maskP [8.210180091339225e-09, 5.2811214118264616e-05]\n",
      "['Milch', ',']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.6409712149177977e-05\n",
      "-- Target Rank:  645\n",
      "-- Target Entropy:  3.915179491043091\n",
      "--------------------------\n",
      "Target token: MÃ¤nner\n",
      "token_idx: 49\n",
      "maskP [1.2700539627985563e-05]\n",
      "['MÃ¤nner']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.2700539627985563e-05\n",
      "-- Target Rank:  3319\n",
      "-- Target Entropy:  5.907447814941406\n",
      "--------------------------\n",
      "Target token: altern\n",
      "token_idx: 26758\n",
      "maskP [1.7026316072588088e-06]\n",
      "['altern']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.7026316072588088e-06\n",
      "-- Target Rank:  5266\n",
      "-- Target Entropy:  4.149090766906738\n",
      "--------------------------\n",
      "Target token: wie\n",
      "token_idx: 687\n",
      "maskP [0.0011234113480895758]\n",
      "['wie']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0011234113480895758\n",
      "-- Target Rank:  28\n",
      "-- Target Entropy:  1.1471372842788696\n",
      "--------------------------\n",
      "Target token: Wein\n",
      "token_idx: 22425\n",
      "maskP [3.5435539302852703e-06]\n",
      "['Wein']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.5435539302852703e-06\n",
      "-- Target Rank:  2399\n",
      "-- Target Entropy:  4.2712321281433105\n",
      "--------------------------\n",
      "Target token: klass\n",
      "token_idx: 7342\n",
      "--------------------------\n",
      "Target token: ische\n",
      "token_idx: 523\n",
      "maskP [1.1218420326031264e-07, 1.2300132539166952e-06]\n",
      "['klass', 'ische']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.710987285885039e-07\n",
      "-- Target Rank:  20000\n",
      "-- Target Entropy:  8.063133239746094\n",
      "--------------------------\n",
      "Target token: R\n",
      "token_idx: 54\n",
      "--------------------------\n",
      "Target token: ollen\n",
      "token_idx: 6010\n",
      "--------------------------\n",
      "Target token: verteilung\n",
      "token_idx: 14709\n",
      "maskP [2.9382631510088686e-06, 5.3295615032311616e-08, 3.58982887860293e-08]\n",
      "['R', 'ollen', 'verteilung']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.00915235160907e-06\n",
      "-- Target Rank:  13976\n",
      "-- Target Entropy:  8.063177108764648\n",
      "--------------------------\n",
      "Target token: in\n",
      "token_idx: 269\n",
      "maskP [1.525927359580237e-06]\n",
      "['in']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.525927359580237e-06\n",
      "-- Target Rank:  3684\n",
      "-- Target Entropy:  4.266345024108887\n",
      "--------------------------\n",
      "Target token: der\n",
      "token_idx: 320\n",
      "maskP [1.9613858967204578e-05]\n",
      "['der']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.9613858967204578e-05\n",
      "-- Target Rank:  1677\n",
      "-- Target Entropy:  3.407257318496704\n",
      "--------------------------\n",
      "Target token: Ehe\n",
      "token_idx: 33545\n",
      "maskP [3.2214135359254215e-08]\n",
      "['Ehe']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.2214135359254215e-08\n",
      "-- Target Rank:  26303\n",
      "-- Target Entropy:  6.982829570770264\n",
      "--------------------------\n",
      "Target token: ist\n",
      "token_idx: 510\n",
      "maskP [3.725527221831726e-06]\n",
      "['ist']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.725527221831726e-06\n",
      "-- Target Rank:  2630\n",
      "-- Target Entropy:  4.452498912811279\n",
      "--------------------------\n",
      "Target token: zu\n",
      "token_idx: 636\n",
      "maskP [9.095718382923224e-07]\n",
      "['zu']\n",
      "-- Target Probability (mean of probabilities in maskP):  9.095718382923224e-07\n",
      "-- Target Rank:  6542\n",
      "-- Target Entropy:  4.881762504577637\n",
      "--------------------------\n",
      "Target token: be\n",
      "token_idx: 518\n",
      "--------------------------\n",
      "Target token: vor\n",
      "token_idx: 805\n",
      "--------------------------\n",
      "Target token: zu\n",
      "token_idx: 636\n",
      "--------------------------\n",
      "Target token: gen\n",
      "token_idx: 312\n",
      "maskP [6.407484761439264e-06, 6.7872501858801115e-06, 5.159451120562153e-06, 6.732457404723391e-05]\n",
      "['be', 'vor', 'zu', 'gen']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.141969002877886e-05\n",
      "-- Target Rank:  646\n",
      "-- Target Entropy:  4.838583946228027\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [1.4102917702984996e-05]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.4102917702984996e-05\n",
      "-- Target Rank:  3473\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: fÃ¼r\n",
      "token_idx: 74\n",
      "maskP [4.3660270421241876e-06]\n",
      "['fÃ¼r']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.3660270421241876e-06\n",
      "-- Target Rank:  5568\n",
      "-- Target Entropy:  5.974837303161621\n",
      "--------------------------\n",
      "Target token: gew\n",
      "token_idx: 1436\n",
      "--------------------------\n",
      "Target token: isse\n",
      "token_idx: 2932\n",
      "maskP [2.4569440029154066e-06, 1.6413277847959762e-08]\n",
      "['gew', 'isse']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.2366786403816832e-06\n",
      "-- Target Rank:  10327\n",
      "-- Target Entropy:  5.436031341552734\n",
      "--------------------------\n",
      "Target token: Ber\n",
      "token_idx: 2165\n",
      "--------------------------\n",
      "Target token: ufen\n",
      "token_idx: 1627\n",
      "maskP [2.566780494817067e-06, 6.802892915658276e-09]\n",
      "['Ber', 'ufen']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.2867916938663626e-06\n",
      "-- Target Rank:  8766\n",
      "-- Target Entropy:  6.299251079559326\n",
      "--------------------------\n",
      "Target token: nicht\n",
      "token_idx: 7272\n",
      "maskP [5.7311830460093915e-05]\n",
      "['nicht']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.7311830460093915e-05\n",
      "-- Target Rank:  949\n",
      "-- Target Entropy:  5.576683044433594\n",
      "--------------------------\n",
      "Target token: ge\n",
      "token_idx: 281\n",
      "--------------------------\n",
      "Target token: eignet\n",
      "token_idx: 10106\n",
      "maskP [4.2494735680520535e-05, 2.3613453947746166e-07]\n",
      "['ge', 'eignet']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.1365435109998998e-05\n",
      "-- Target Rank:  888\n",
      "-- Target Entropy:  5.049911975860596\n",
      "--------------------------\n",
      "Target token: der\n",
      "token_idx: 320\n",
      "maskP [0.0015312677714973688]\n",
      "['der']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0015312677714973688\n",
      "-- Target Rank:  50\n",
      "-- Target Entropy:  4.115504264831543\n",
      "--------------------------\n",
      "Target token: Gesch\n",
      "token_idx: 5328\n",
      "--------------------------\n",
      "Target token: lechter\n",
      "token_idx: 14704\n",
      "maskP [3.2358866519643925e-06, 1.8303659032881114e-08]\n",
      "['Gesch', 'lechter']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.6270951554986368e-06\n",
      "-- Target Rank:  880\n",
      "-- Target Entropy:  0.8480423092842102\n",
      "--------------------------\n",
      "Target token: ist\n",
      "token_idx: 510\n",
      "maskP [1.218593206431251e-05]\n",
      "['ist']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.218593206431251e-05\n",
      "-- Target Rank:  2258\n",
      "-- Target Entropy:  4.2744460105896\n",
      "--------------------------\n",
      "Target token: eine\n",
      "token_idx: 580\n",
      "maskP [0.0013318692799657583]\n",
      "['eine']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0013318692799657583\n",
      "-- Target Rank:  87\n",
      "-- Target Entropy:  4.674030303955078\n",
      "--------------------------\n",
      "Target token: Ãľber\n",
      "token_idx: 3545\n",
      "--------------------------\n",
      "Target token: be\n",
      "token_idx: 518\n",
      "--------------------------\n",
      "Target token: vort\n",
      "token_idx: 13852\n",
      "--------------------------\n",
      "Target token: eilung\n",
      "token_idx: 5137\n",
      "maskP [3.2175925923638715e-08, 4.312901182856876e-06, 1.2803972992969648e-08, 2.7682627745662103e-08]\n",
      "['Ãľber', 'be', 'vort', 'eilung']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.0963909273797867e-06\n",
      "-- Target Rank:  3955\n",
      "-- Target Entropy:  4.734949111938477\n",
      "--------------------------\n",
      "Target token: von\n",
      "token_idx: 1420\n",
      "maskP [0.000297313992632553]\n",
      "['von']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.000297313992632553\n",
      "-- Target Rank:  118\n",
      "-- Target Entropy:  3.2760462760925293\n",
      "--------------------------\n",
      "Target token: Frauen\n",
      "token_idx: 11678\n",
      "maskP [7.406004442600533e-05]\n",
      "['Frauen']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.406004442600533e-05\n",
      "-- Target Rank:  486\n",
      "-- Target Entropy:  2.57381010055542\n",
      "--------------------------\n",
      "Target token: in\n",
      "token_idx: 269\n",
      "maskP [0.0012834107037633657]\n",
      "['in']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0012834107037633657\n",
      "-- Target Rank:  91\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: fÃ¼hrenden\n",
      "token_idx: 74\n",
      "maskP [3.878858115058392e-05]\n",
      "['fÃ¼hrenden']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.878858115058392e-05\n",
      "-- Target Rank:  1843\n",
      "-- Target Entropy:  5.600177764892578\n",
      "--------------------------\n",
      "Target token: Position\n",
      "token_idx: 23786\n",
      "--------------------------\n",
      "Target token: en\n",
      "token_idx: 262\n",
      "maskP [6.303784903138876e-05, 8.726859164198686e-07]\n",
      "['Position', 'en']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.1955267473904314e-05\n",
      "-- Target Rank:  239\n",
      "-- Target Entropy:  1.461358904838562\n",
      "--------------------------\n",
      "Target token: haben\n",
      "token_idx: 4199\n",
      "maskP [1.4797471521887928e-05]\n",
      "['haben']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.4797471521887928e-05\n",
      "-- Target Rank:  2326\n",
      "-- Target Entropy:  4.686800956726074\n",
      "--------------------------\n",
      "Target token: hÃ¤\n",
      "token_idx: 76\n",
      "--------------------------\n",
      "Target token: ufig\n",
      "token_idx: 3021\n",
      "maskP [4.965125845046714e-05, 8.979489152238784e-09]\n",
      "['hÃ¤', 'ufig']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.483011896980969e-05\n",
      "-- Target Rank:  1049\n",
      "-- Target Entropy:  5.498671531677246\n",
      "--------------------------\n",
      "Target token: kompl\n",
      "token_idx: 28456\n",
      "--------------------------\n",
      "Target token: izierte\n",
      "token_idx: 7066\n",
      "maskP [2.220709518496733e-07, 1.932721716002561e-08]\n",
      "['kompl', 'izierte']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.2069908450484945e-07\n",
      "-- Target Rank:  20465\n",
      "-- Target Entropy:  5.878767967224121\n",
      "--------------------------\n",
      "Target token: PersÃ¶n\n",
      "token_idx: 48263\n",
      "--------------------------\n",
      "Target token: lichkeiten\n",
      "token_idx: 5936\n",
      "maskP [3.316169838729621e-10, 1.018729349766545e-07]\n",
      "['PersÃ¶n', 'lichkeiten']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.1102275980263734e-08\n",
      "-- Target Rank:  16827\n",
      "-- Target Entropy:  5.840826988220215\n",
      "--------------------------\n",
      "Target token: gehÃ¶ren\n",
      "token_idx: 2571\n",
      "maskP [0.00010706575267249718]\n",
      "['gehÃ¶ren']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.00010706575267249718\n",
      "-- Target Rank:  740\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: in\n",
      "token_idx: 269\n",
      "maskP [3.716025730682304e-06]\n",
      "['in']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.716025730682304e-06\n",
      "-- Target Rank:  3361\n",
      "-- Target Entropy:  4.247570991516113\n",
      "--------------------------\n",
      "Target token: die\n",
      "token_idx: 2327\n",
      "maskP [5.496704034158029e-05]\n",
      "['die']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.496704034158029e-05\n",
      "-- Target Rank:  670\n",
      "-- Target Entropy:  4.332465171813965\n",
      "--------------------------\n",
      "Target token: KÃ¼che\n",
      "token_idx: 47\n",
      "maskP [2.0915276763844304e-06]\n",
      "['KÃ¼che']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.0915276763844304e-06\n",
      "-- Target Rank:  11896\n",
      "-- Target Entropy:  7.050624370574951\n",
      "--------------------------\n",
      "Target token: s\n",
      "token_idx: 87\n",
      "--------------------------\n",
      "Target token: oll\n",
      "token_idx: 701\n",
      "--------------------------\n",
      "Target token: ten\n",
      "token_idx: 310\n",
      "maskP [5.3167033911449835e-05, 1.0145470952238611e-07, 3.8750324165448546e-05]\n",
      "['s', 'oll', 'ten']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.067293759547359e-05\n",
      "-- Target Rank:  1307\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: ihre\n",
      "token_idx: 44188\n",
      "maskP [6.556603239005199e-06]\n",
      "['ihre']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.556603239005199e-06\n",
      "-- Target Rank:  5149\n",
      "-- Target Entropy:  5.844089031219482\n",
      "--------------------------\n",
      "Target token: klass\n",
      "token_idx: 7342\n",
      "--------------------------\n",
      "Target token: ische\n",
      "token_idx: 523\n",
      "maskP [2.300688350942437e-07, 9.363311193055779e-08]\n",
      "['klass', 'ische']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.6185097351240074e-07\n",
      "-- Target Rank:  20880\n",
      "-- Target Entropy:  7.191878795623779\n",
      "--------------------------\n",
      "Target token: Gesch\n",
      "token_idx: 5328\n",
      "--------------------------\n",
      "Target token: lechter\n",
      "token_idx: 14704\n",
      "--------------------------\n",
      "Target token: rolle\n",
      "token_idx: 5215\n",
      "maskP [2.4811268417579413e-07, 5.650368506415759e-10, 4.443463197389974e-08]\n",
      "['Gesch', 'lechter', 'rolle']\n",
      "-- Target Probability (mean of probabilities in maskP):  9.770411766677849e-08\n",
      "-- Target Rank:  18666\n",
      "-- Target Entropy:  6.709188461303711\n",
      "--------------------------\n",
      "Target token: aus\n",
      "token_idx: 481\n",
      "--------------------------\n",
      "Target token: Ã¼ben\n",
      "token_idx: 3545\n",
      "maskP [7.794026714691427e-06, 1.0731555732945708e-07]\n",
      "['aus', 'Ã¼ben']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.950671136010442e-06\n",
      "-- Target Rank:  1860\n",
      "-- Target Entropy:  4.895749568939209\n",
      "--------------------------\n",
      "Target token: was\n",
      "token_idx: 2563\n",
      "maskP [3.91185749322176e-05]\n",
      "['was']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.91185749322176e-05\n",
      "-- Target Rank:  1391\n",
      "-- Target Entropy:  5.562985420227051\n",
      "--------------------------\n",
      "Target token: eine\n",
      "token_idx: 580\n",
      "maskP [1.1489289519772683e-08]\n",
      "['eine']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.1489289519772683e-08\n",
      "-- Target Rank:  33471\n",
      "-- Target Entropy:  4.9353742599487305\n",
      "--------------------------\n",
      "Target token: Frau\n",
      "token_idx: 9918\n",
      "maskP [1.554971390760329e-06]\n",
      "['Frau']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.554971390760329e-06\n",
      "-- Target Rank:  15891\n",
      "-- Target Entropy:  7.5555853843688965\n",
      "--------------------------\n",
      "Target token: tun\n",
      "token_idx: 32349\n",
      "maskP [7.947207336655993e-07]\n",
      "['tun']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.947207336655993e-07\n",
      "-- Target Rank:  5222\n",
      "-- Target Entropy:  4.85538387298584\n",
      "--------------------------\n",
      "Target token: m\n",
      "token_idx: 81\n",
      "--------------------------\n",
      "Target token: uss\n",
      "token_idx: 592\n",
      "--------------------------\n",
      "Target token: ,\n",
      "token_idx: 16\n",
      "maskP [1.3135758308635559e-05, 1.1184709336475862e-07, 0.00876571610569954]\n",
      "['m', 'uss', ',']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0029263212370338465\n",
      "-- Target Rank:  11\n",
      "-- Target Entropy:  2.21112322807312\n",
      "--------------------------\n",
      "Target token: ist\n",
      "token_idx: 510\n",
      "maskP [0.00010154780466109514]\n",
      "['ist']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.00010154780466109514\n",
      "-- Target Rank:  246\n",
      "-- Target Entropy:  2.4088499546051025\n",
      "--------------------------\n",
      "Target token: i\n",
      "token_idx: 77\n",
      "--------------------------\n",
      "Target token: hren\n",
      "token_idx: 3031\n",
      "maskP [6.668662990705343e-06, 5.9323571832692323e-08]\n",
      "['i', 'hren']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.3639932812690176e-06\n",
      "-- Target Rank:  3377\n",
      "-- Target Entropy:  5.18226957321167\n",
      "--------------------------\n",
      "Target token: Mann\n",
      "token_idx: 7100\n",
      "maskP [1.0377563739893958e-05]\n",
      "['Mann']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.0377563739893958e-05\n",
      "-- Target Rank:  2180\n",
      "-- Target Entropy:  3.9628007411956787\n",
      "--------------------------\n",
      "Target token: zu\n",
      "token_idx: 636\n",
      "maskP [8.30435601528734e-06]\n",
      "['zu']\n",
      "-- Target Probability (mean of probabilities in maskP):  8.30435601528734e-06\n",
      "-- Target Rank:  1757\n",
      "-- Target Entropy:  4.229884624481201\n",
      "--------------------------\n",
      "Target token: be\n",
      "token_idx: 518\n",
      "--------------------------\n",
      "Target token: fried\n",
      "token_idx: 5911\n",
      "--------------------------\n",
      "Target token: igen\n",
      "token_idx: 565\n",
      "maskP [1.819154135773715e-06, 2.2427470991459586e-09, 1.4823103811067995e-07]\n",
      "['be', 'fried', 'igen']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.56542640327847e-07\n",
      "-- Target Rank:  2233\n",
      "-- Target Entropy:  4.430199146270752\n",
      "--------------------------\n",
      "Target token: machen\n",
      "token_idx: 7843\n",
      "maskP [6.601790119020734e-06]\n",
      "['machen']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.601790119020734e-06\n",
      "-- Target Rank:  5542\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: j\n",
      "token_idx: 78\n",
      "--------------------------\n",
      "Target token: edes\n",
      "token_idx: 6004\n",
      "maskP [1.3258749049782637e-06, 2.1313208975470843e-08]\n",
      "['j', 'edes']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.735940569768673e-07\n",
      "-- Target Rank:  10607\n",
      "-- Target Entropy:  5.540369987487793\n",
      "--------------------------\n",
      "Target token: wirtschaftliche\n",
      "token_idx: 17376\n",
      "maskP [8.394610340189956e-09]\n",
      "['wirtschaftliche']\n",
      "-- Target Probability (mean of probabilities in maskP):  8.394610340189956e-09\n",
      "-- Target Rank:  19051\n",
      "-- Target Entropy:  1.383182168006897\n",
      "--------------------------\n",
      "Target token: Unternehmen\n",
      "token_idx: 10404\n",
      "maskP [2.254893843200989e-06]\n",
      "['Unternehmen']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.254893843200989e-06\n",
      "-- Target Rank:  3630\n",
      "-- Target Entropy:  4.664006233215332\n",
      "--------------------------\n",
      "Target token: stÃ¤r\n",
      "token_idx: 30068\n",
      "--------------------------\n",
      "Target token: ker\n",
      "token_idx: 1179\n",
      "maskP [3.7870755420499336e-08, 6.0541975877015375e-09]\n",
      "['stÃ¤r', 'ker']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.1962476504100437e-08\n",
      "-- Target Rank:  15341\n",
      "-- Target Entropy:  4.5595703125\n",
      "--------------------------\n",
      "Target token: und\n",
      "token_idx: 283\n",
      "maskP [1.4408567949431017e-05]\n",
      "['und']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.4408567949431017e-05\n",
      "-- Target Rank:  2865\n",
      "-- Target Entropy:  5.121635913848877\n",
      "--------------------------\n",
      "Target token: Frauen\n",
      "token_idx: 11678\n",
      "maskP [0.00019128876738250256]\n",
      "['Frauen']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.00019128876738250256\n",
      "-- Target Rank:  224\n",
      "-- Target Entropy:  2.8845956325531006\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [4.241257101966767e-06]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.241257101966767e-06\n",
      "-- Target Rank:  3921\n",
      "-- Target Entropy:  4.675729751586914\n",
      "--------------------------\n",
      "Target token: gleich\n",
      "token_idx: 1464\n",
      "maskP [3.0457544198725373e-05]\n",
      "['gleich']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.0457544198725373e-05\n",
      "-- Target Rank:  1402\n",
      "-- Target Entropy:  5.388428688049316\n",
      "--------------------------\n",
      "Target token: in\n",
      "token_idx: 269\n",
      "--------------------------\n",
      "Target token: telligen\n",
      "token_idx: 8593\n",
      "--------------------------\n",
      "Target token: t\n",
      "token_idx: 88\n",
      "maskP [6.482713160949061e-06, 1.526862902778703e-08, 7.146939537960861e-07]\n",
      "['in', 'telligen', 't']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.404225247924311e-06\n",
      "-- Target Rank:  1671\n",
      "-- Target Entropy:  4.186195373535156\n",
      "--------------------------\n",
      "Target token: kÃ¶nnen\n",
      "token_idx: 79\n",
      "maskP [0.0002068869798677042]\n",
      "['kÃ¶nnen']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0002068869798677042\n",
      "-- Target Rank:  424\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: ohne\n",
      "token_idx: 9810\n",
      "maskP [1.0797035656651133e-06]\n",
      "['ohne']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.0797035656651133e-06\n",
      "-- Target Rank:  13297\n",
      "-- Target Entropy:  5.745215892791748\n",
      "--------------------------\n",
      "Target token: Kinder\n",
      "token_idx: 8977\n",
      "maskP [3.4387085179332644e-07]\n",
      "['Kinder']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.4387085179332644e-07\n",
      "-- Target Rank:  18770\n",
      "-- Target Entropy:  6.563605308532715\n",
      "--------------------------\n",
      "Target token: glÃ¼ck\n",
      "token_idx: 1306\n",
      "--------------------------\n",
      "Target token: lich\n",
      "token_idx: 341\n",
      "maskP [8.519898074155208e-06, 3.6157357499178033e-06]\n",
      "['glÃ¼ck', 'lich']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.0678169120365055e-06\n",
      "-- Target Rank:  3164\n",
      "-- Target Entropy:  5.273921966552734\n",
      "--------------------------\n",
      "Target token: sein\n",
      "token_idx: 5579\n",
      "maskP [4.8899011744651943e-05]\n",
      "['sein']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.8899011744651943e-05\n",
      "-- Target Rank:  106\n",
      "-- Target Entropy:  1.2276252508163452\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [1.4102917702984996e-05]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.4102917702984996e-05\n",
      "-- Target Rank:  3473\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: nicht\n",
      "token_idx: 7272\n",
      "maskP [4.32030037700315e-06]\n",
      "['nicht']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.32030037700315e-06\n",
      "-- Target Rank:  5603\n",
      "-- Target Entropy:  5.974837303161621\n",
      "--------------------------\n",
      "Target token: schw\n",
      "token_idx: 2028\n",
      "--------------------------\n",
      "Target token: ach\n",
      "token_idx: 344\n",
      "maskP [1.0683781965781236e-06, 1.258659523273309e-07]\n",
      "['schw', 'ach']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.971220744527272e-07\n",
      "-- Target Rank:  7840\n",
      "-- Target Entropy:  5.435161113739014\n",
      "--------------------------\n",
      "Target token: und\n",
      "token_idx: 283\n",
      "maskP [6.249639409361407e-05]\n",
      "['und']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.249639409361407e-05\n",
      "-- Target Rank:  183\n",
      "-- Target Entropy:  2.5783591270446777\n",
      "--------------------------\n",
      "Target token: s\n",
      "token_idx: 87\n",
      "--------------------------\n",
      "Target token: oll\n",
      "token_idx: 701\n",
      "--------------------------\n",
      "Target token: ten\n",
      "token_idx: 310\n",
      "maskP [4.3838949750352185e-06, 1.1038303604493649e-08, 1.5251515605996246e-07]\n",
      "['s', 'oll', 'ten']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.5158161448998915e-06\n",
      "-- Target Rank:  4270\n",
      "-- Target Entropy:  5.724864959716797\n",
      "--------------------------\n",
      "Target token: sich\n",
      "token_idx: 12592\n",
      "maskP [1.163505748991156e-05]\n",
      "['sich']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.163505748991156e-05\n",
      "-- Target Rank:  2263\n",
      "-- Target Entropy:  5.18825101852417\n",
      "--------------------------\n",
      "Target token: so\n",
      "token_idx: 1342\n",
      "maskP [8.628344971839397e-07]\n",
      "['so']\n",
      "-- Target Probability (mean of probabilities in maskP):  8.628344971839397e-07\n",
      "-- Target Rank:  5366\n",
      "-- Target Entropy:  5.0798659324646\n",
      "--------------------------\n",
      "Target token: auch\n",
      "token_idx: 4564\n",
      "maskP [1.2940977285325062e-06]\n",
      "['auch']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.2940977285325062e-06\n",
      "-- Target Rank:  4174\n",
      "-- Target Entropy:  4.675177574157715\n",
      "--------------------------\n",
      "Target token: nicht\n",
      "token_idx: 7272\n",
      "maskP [7.008581451373175e-05]\n",
      "['nicht']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.008581451373175e-05\n",
      "-- Target Rank:  662\n",
      "-- Target Entropy:  4.662259101867676\n",
      "--------------------------\n",
      "Target token: fÃ¼hlen\n",
      "token_idx: 74\n",
      "maskP [2.8711936010950012e-06]\n",
      "['fÃ¼hlen']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.8711936010950012e-06\n",
      "-- Target Rank:  4278\n",
      "-- Target Entropy:  5.65384578704834\n",
      "--------------------------\n",
      "Target token: so\n",
      "token_idx: 1342\n",
      "--------------------------\n",
      "Target token: llen\n",
      "token_idx: 492\n",
      "maskP [3.201015715603717e-05, 2.2615779471379938e-07]\n",
      "['so', 'llen']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.6118157475375483e-05\n",
      "-- Target Rank:  1929\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: das\n",
      "token_idx: 5972\n",
      "maskP [4.3170020944671705e-06]\n",
      "['das']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.3170020944671705e-06\n",
      "-- Target Rank:  9748\n",
      "-- Target Entropy:  6.543186664581299\n",
      "--------------------------\n",
      "Target token: gleich\n",
      "token_idx: 1464\n",
      "--------------------------\n",
      "Target token: e\n",
      "token_idx: 73\n",
      "maskP [2.4500754989276174e-06, 1.053981350196409e-06]\n",
      "['gleich', 'e']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.7520284245620132e-06\n",
      "-- Target Rank:  11121\n",
      "-- Target Entropy:  6.823728084564209\n",
      "--------------------------\n",
      "Target token: machen\n",
      "token_idx: 7843\n",
      "maskP [1.6062033409980359e-06]\n",
      "['machen']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.6062033409980359e-06\n",
      "-- Target Rank:  6519\n",
      "-- Target Entropy:  4.798906326293945\n",
      "--------------------------\n",
      "Target token: d\n",
      "token_idx: 72\n",
      "--------------------------\n",
      "Target token: Ã¼rfen\n",
      "token_idx: 3545\n",
      "maskP [2.0522932118183235e-06, 4.512572004955473e-08]\n",
      "['d', 'Ã¼rfen']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.048709465933939e-06\n",
      "-- Target Rank:  621\n",
      "-- Target Entropy:  2.351341962814331\n",
      "--------------------------\n",
      "Target token: wie\n",
      "token_idx: 687\n",
      "maskP [0.0002434443449601531]\n",
      "['wie']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0002434443449601531\n",
      "-- Target Rank:  44\n",
      "-- Target Entropy:  2.2212414741516113\n",
      "--------------------------\n",
      "Target token: MÃ¤nner\n",
      "token_idx: 49\n",
      "maskP [5.478009370563086e-07]\n",
      "['MÃ¤nner']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.478009370563086e-07\n",
      "-- Target Rank:  13955\n",
      "-- Target Entropy:  4.960460186004639\n",
      "--------------------------\n",
      "Target token: Gesch\n",
      "token_idx: 5328\n",
      "--------------------------\n",
      "Target token: lechter\n",
      "token_idx: 14704\n",
      "maskP [1.0490600743651157e-06, 5.748631792812375e-09]\n",
      "['Gesch', 'lechter']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.27404353078964e-07\n",
      "-- Target Rank:  17943\n",
      "-- Target Entropy:  6.9506425857543945\n",
      "--------------------------\n",
      "Target token: s\n",
      "token_idx: 87\n",
      "--------------------------\n",
      "Target token: oll\n",
      "token_idx: 701\n",
      "--------------------------\n",
      "Target token: ten\n",
      "token_idx: 310\n",
      "maskP [0.00012169461842859164, 3.4401801940475707e-07, 4.326971065893304e-06]\n",
      "['s', 'oll', 'ten']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.2121869171296566e-05\n",
      "-- Target Rank:  664\n",
      "-- Target Entropy:  5.565274238586426\n",
      "--------------------------\n",
      "Target token: gleich\n",
      "token_idx: 1464\n",
      "maskP [1.9279737898614258e-05]\n",
      "['gleich']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.9279737898614258e-05\n",
      "-- Target Rank:  2028\n",
      "-- Target Entropy:  5.4840593338012695\n",
      "--------------------------\n",
      "Target token: be\n",
      "token_idx: 518\n",
      "--------------------------\n",
      "Target token: zahlt\n",
      "token_idx: 6928\n",
      "maskP [0.0016089023556560278, 5.490483090397902e-08]\n",
      "['be', 'zahlt']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0008044786302434659\n",
      "-- Target Rank:  34\n",
      "-- Target Entropy:  2.573824405670166\n",
      "--------------------------\n",
      "Target token: werden\n",
      "token_idx: 9190\n",
      "maskP [0.0005534907686524093]\n",
      "['werden']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0005534907686524093\n",
      "-- Target Rank:  9\n",
      "-- Target Entropy:  0.33461707830429077\n",
      "--------------------------\n",
      "Target token: ist\n",
      "token_idx: 510\n",
      "maskP [4.713838279712945e-06]\n",
      "['ist']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.713838279712945e-06\n",
      "-- Target Rank:  3906\n",
      "-- Target Entropy:  4.8548665046691895\n",
      "--------------------------\n",
      "Target token: eine\n",
      "token_idx: 580\n",
      "maskP [2.0582383513101377e-05]\n",
      "['eine']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.0582383513101377e-05\n",
      "-- Target Rank:  1441\n",
      "-- Target Entropy:  4.707686424255371\n",
      "--------------------------\n",
      "Target token: menschen\n",
      "token_idx: 25760\n",
      "--------------------------\n",
      "Target token: rechtliche\n",
      "token_idx: 17354\n",
      "maskP [3.4540096294222167e-07, 6.566492771753474e-08]\n",
      "['menschen', 'rechtliche']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.055329453298782e-07\n",
      "-- Target Rank:  12330\n",
      "-- Target Entropy:  6.047176361083984\n",
      "--------------------------\n",
      "Target token: Frage\n",
      "token_idx: 24864\n",
      "maskP [5.124989570504113e-07]\n",
      "['Frage']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.124989570504113e-07\n",
      "-- Target Rank:  5658\n",
      "-- Target Entropy:  4.679506301879883\n",
      "--------------------------\n",
      "Target token: m\n",
      "token_idx: 81\n",
      "--------------------------\n",
      "Target token: Ã¼ssen\n",
      "token_idx: 3545\n",
      "maskP [9.090622916119173e-05, 8.052055022744753e-07]\n",
      "['m', 'Ã¼ssen']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.5855717331733103e-05\n",
      "-- Target Rank:  551\n",
      "-- Target Entropy:  4.86444091796875\n",
      "--------------------------\n",
      "Target token: im\n",
      "token_idx: 487\n",
      "maskP [2.1616770595755952e-07]\n",
      "['im']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.1616770595755952e-07\n",
      "-- Target Rank:  16953\n",
      "-- Target Entropy:  5.361434459686279\n",
      "--------------------------\n",
      "Target token: gleichen\n",
      "token_idx: 14065\n",
      "maskP [5.353168035071576e-06]\n",
      "['gleichen']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.353168035071576e-06\n",
      "-- Target Rank:  4982\n",
      "-- Target Entropy:  6.129724025726318\n",
      "--------------------------\n",
      "Target token: Um\n",
      "token_idx: 2193\n",
      "--------------------------\n",
      "Target token: fang\n",
      "token_idx: 1587\n",
      "maskP [5.1219114993728e-07, 1.6619587484001386e-08]\n",
      "['Um', 'fang']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.644053687106407e-07\n",
      "-- Target Rank:  8504\n",
      "-- Target Entropy:  4.611981391906738\n",
      "--------------------------\n",
      "Target token: wie\n",
      "token_idx: 687\n",
      "maskP [8.194493602786679e-06]\n",
      "['wie']\n",
      "-- Target Probability (mean of probabilities in maskP):  8.194493602786679e-06\n",
      "-- Target Rank:  2937\n",
      "-- Target Entropy:  5.385591983795166\n",
      "--------------------------\n",
      "Target token: M\n",
      "token_idx: 49\n",
      "--------------------------\n",
      "Target token: Ã¼tter\n",
      "token_idx: 3545\n",
      "maskP [3.341329204431531e-07, 1.2739610255607658e-08]\n",
      "['M', 'Ã¼tter']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.734362653493804e-07\n",
      "-- Target Rank:  4157\n",
      "-- Target Entropy:  2.04034161567688\n",
      "--------------------------\n",
      "Target token: Verantwort\n",
      "token_idx: 30670\n",
      "--------------------------\n",
      "Target token: ung\n",
      "token_idx: 288\n",
      "maskP [3.011192628576964e-09, 6.676174507447286e-06]\n",
      "['Verantwort', 'ung']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.3395928500379313e-06\n",
      "-- Target Rank:  2633\n",
      "-- Target Entropy:  4.829646110534668\n",
      "--------------------------\n",
      "Target token: fÃ¼r\n",
      "token_idx: 74\n",
      "maskP [3.56867360551405e-07]\n",
      "['fÃ¼r']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.56867360551405e-07\n",
      "-- Target Rank:  1847\n",
      "-- Target Entropy:  1.6967241764068604\n",
      "--------------------------\n",
      "Target token: ihre\n",
      "token_idx: 44188\n",
      "maskP [2.4575201678089797e-05]\n",
      "['ihre']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.4575201678089797e-05\n",
      "-- Target Rank:  320\n",
      "-- Target Entropy:  2.1838653087615967\n",
      "--------------------------\n",
      "Target token: Kinder\n",
      "token_idx: 8977\n",
      "maskP [0.00011227431969018653]\n",
      "['Kinder']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.00011227431969018653\n",
      "-- Target Rank:  84\n",
      "-- Target Entropy:  0.7986650466918945\n",
      "--------------------------\n",
      "Target token: Ã¼ber\n",
      "token_idx: 3545\n",
      "--------------------------\n",
      "Target token: nehmen\n",
      "token_idx: 2137\n",
      "maskP [9.426983638149977e-10, 3.008283329108963e-07]\n",
      "['Ã¼ber', 'nehmen']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.5088551563735564e-07\n",
      "-- Target Rank:  1653\n",
      "-- Target Entropy:  0.8209302425384521\n",
      "--------------------------\n",
      "Target token: Gesch\n",
      "token_idx: 5328\n",
      "--------------------------\n",
      "Target token: lechter\n",
      "token_idx: 14704\n",
      "maskP [6.882874004077166e-07, 5.153494964105221e-09]\n",
      "['Gesch', 'lechter']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.467204476859109e-07\n",
      "-- Target Rank:  25360\n",
      "-- Target Entropy:  8.566091537475586\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [1.2503109246608801e-05]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.2503109246608801e-05\n",
      "-- Target Rank:  2013\n",
      "-- Target Entropy:  4.926531791687012\n",
      "--------------------------\n",
      "Target token: nicht\n",
      "token_idx: 7272\n",
      "maskP [6.8708895923919044e-06]\n",
      "['nicht']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.8708895923919044e-06\n",
      "-- Target Rank:  3734\n",
      "-- Target Entropy:  5.809778213500977\n",
      "--------------------------\n",
      "Target token: immer\n",
      "token_idx: 1440\n",
      "maskP [7.828811249055434e-06]\n",
      "['immer']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.828811249055434e-06\n",
      "-- Target Rank:  2958\n",
      "-- Target Entropy:  5.768219470977783\n",
      "--------------------------\n",
      "Target token: gleich\n",
      "token_idx: 1464\n",
      "--------------------------\n",
      "Target token: ,\n",
      "token_idx: 16\n",
      "maskP [0.0001326471974607557, 0.0006702647660858929]\n",
      "['gleich', ',']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0004014559817733243\n",
      "-- Target Rank:  100\n",
      "-- Target Entropy:  3.004626750946045\n",
      "--------------------------\n",
      "Target token: j\n",
      "token_idx: 78\n",
      "--------------------------\n",
      "Target token: edoch\n",
      "token_idx: 12072\n",
      "maskP [1.1831280062324367e-05, 3.584582630722366e-09]\n",
      "['j', 'edoch']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.917432322477545e-06\n",
      "-- Target Rank:  1681\n",
      "-- Target Entropy:  4.31684684753418\n",
      "--------------------------\n",
      "Target token: nicht\n",
      "token_idx: 7272\n",
      "maskP [4.594248366629472e-06]\n",
      "['nicht']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.594248366629472e-06\n",
      "-- Target Rank:  3519\n",
      "-- Target Entropy:  5.050710201263428\n",
      "--------------------------\n",
      "Target token: m\n",
      "token_idx: 81\n",
      "--------------------------\n",
      "Target token: inder\n",
      "token_idx: 958\n",
      "--------------------------\n",
      "Target token: wer\n",
      "token_idx: 548\n",
      "--------------------------\n",
      "Target token: tiger\n",
      "token_idx: 2663\n",
      "maskP [2.2092571327902988e-07, 1.1840106139970885e-07, 5.0130722684116336e-08, 4.870192782391314e-08]\n",
      "['m', 'inder', 'wer', 'tiger']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.0953985629669205e-07\n",
      "-- Target Rank:  8517\n",
      "-- Target Entropy:  3.8708064556121826\n",
      "--------------------------\n",
      "Target token: M\n",
      "token_idx: 49\n",
      "--------------------------\n",
      "Target token: Ã¼tter\n",
      "token_idx: 3545\n",
      "maskP [1.9114077076665126e-05, 9.497252762002972e-09]\n",
      "['M', 'Ã¼tter']\n",
      "-- Target Probability (mean of probabilities in maskP):  9.561787164713564e-06\n",
      "-- Target Rank:  1064\n",
      "-- Target Entropy:  4.326862335205078\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [1.2100063031539321e-05]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.2100063031539321e-05\n",
      "-- Target Rank:  1364\n",
      "-- Target Entropy:  4.1507158279418945\n",
      "--------------------------\n",
      "Target token: H\n",
      "token_idx: 44\n",
      "--------------------------\n",
      "Target token: eld\n",
      "token_idx: 847\n",
      "--------------------------\n",
      "Target token: innen\n",
      "token_idx: 1364\n",
      "maskP [6.109755759098334e-07, 1.2781937730466097e-09, 1.811161382647697e-05]\n",
      "['H', 'eld', 'innen']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.24128919871995e-06\n",
      "-- Target Rank:  1760\n",
      "-- Target Entropy:  5.4689178466796875\n",
      "--------------------------\n",
      "Target token: gibt\n",
      "token_idx: 12489\n",
      "maskP [4.0253245970234275e-05]\n",
      "['gibt']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.0253245970234275e-05\n",
      "-- Target Rank:  809\n",
      "-- Target Entropy:  4.175835609436035\n",
      "--------------------------\n",
      "Target token: Frauen\n",
      "token_idx: 11678\n",
      "--------------------------\n",
      "Target token: berufe\n",
      "token_idx: 42874\n",
      "maskP [1.3714448243717925e-07, 8.027987719039231e-10]\n",
      "['Frauen', 'berufe']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.897364060454159e-08\n",
      "-- Target Rank:  21831\n",
      "-- Target Entropy:  5.575512886047363\n",
      "--------------------------\n",
      "Target token: und\n",
      "token_idx: 283\n",
      "maskP [2.9718012228840962e-05]\n",
      "['und']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.9718012228840962e-05\n",
      "-- Target Rank:  178\n",
      "-- Target Entropy:  1.680458426475525\n",
      "--------------------------\n",
      "Target token: es\n",
      "token_idx: 271\n",
      "maskP [3.474124241620302e-06]\n",
      "['es']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.474124241620302e-06\n",
      "-- Target Rank:  6899\n",
      "-- Target Entropy:  5.706750392913818\n",
      "--------------------------\n",
      "Target token: gibt\n",
      "token_idx: 12489\n",
      "maskP [3.5737404687097296e-05]\n",
      "['gibt']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.5737404687097296e-05\n",
      "-- Target Rank:  147\n",
      "-- Target Entropy:  1.0313572883605957\n",
      "--------------------------\n",
      "Target token: MÃ¤nner\n",
      "token_idx: 49\n",
      "--------------------------\n",
      "Target token: berufe\n",
      "token_idx: 42874\n",
      "maskP [2.3838442757551093e-06, 1.3704104731004918e-06]\n",
      "['MÃ¤nner', 'berufe']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.8771273744278005e-06\n",
      "-- Target Rank:  7381\n",
      "-- Target Entropy:  5.314662456512451\n",
      "--------------------------\n",
      "Target token: fÃ¼hlen\n",
      "token_idx: 74\n",
      "maskP [0.000767977093346417]\n",
      "['fÃ¼hlen']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.000767977093346417\n",
      "-- Target Rank:  97\n",
      "-- Target Entropy:  5.121635913848877\n",
      "--------------------------\n",
      "Target token: sich\n",
      "token_idx: 12592\n",
      "maskP [5.9567832977336366e-06]\n",
      "['sich']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.9567832977336366e-06\n",
      "-- Target Rank:  773\n",
      "-- Target Entropy:  0.8298159241676331\n",
      "--------------------------\n",
      "Target token: von\n",
      "token_idx: 1420\n",
      "maskP [5.971529049020319e-07]\n",
      "['von']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.971529049020319e-07\n",
      "-- Target Rank:  5929\n",
      "-- Target Entropy:  5.4416680335998535\n",
      "--------------------------\n",
      "Target token: Frauen\n",
      "token_idx: 11678\n",
      "maskP [1.8994316519638232e-07]\n",
      "['Frauen']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.8994316519638232e-07\n",
      "-- Target Rank:  21585\n",
      "-- Target Entropy:  5.023889064788818\n",
      "--------------------------\n",
      "Target token: in\n",
      "token_idx: 269\n",
      "maskP [1.0797582945087925e-05]\n",
      "['in']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.0797582945087925e-05\n",
      "-- Target Rank:  1766\n",
      "-- Target Entropy:  5.240754127502441\n",
      "--------------------------\n",
      "Target token: FÃ¼hrung\n",
      "token_idx: 42\n",
      "--------------------------\n",
      "Target token: spositionen\n",
      "token_idx: 43059\n",
      "maskP [4.464920493774116e-06, 4.987475676898612e-08]\n",
      "['FÃ¼hrung', 'spositionen']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.257397625271551e-06\n",
      "-- Target Rank:  6341\n",
      "-- Target Entropy:  5.508897304534912\n",
      "--------------------------\n",
      "Target token: bed\n",
      "token_idx: 2340\n",
      "--------------------------\n",
      "Target token: roht\n",
      "token_idx: 7204\n",
      "maskP [1.1389857945687254e-07, 2.4424096078945468e-09]\n",
      "['bed', 'roht']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.817049453238354e-08\n",
      "-- Target Rank:  7503\n",
      "-- Target Entropy:  5.068798065185547\n",
      "--------------------------\n",
      "Target token: m\n",
      "token_idx: 81\n",
      "--------------------------\n",
      "Target token: uss\n",
      "token_idx: 592\n",
      "maskP [1.8954780216517975e-06, 2.6899598992713436e-07]\n",
      "['m', 'uss']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.082237005789466e-06\n",
      "-- Target Rank:  4479\n",
      "-- Target Entropy:  4.261542797088623\n",
      "--------------------------\n",
      "Target token: Ã¼ber\n",
      "token_idx: 3545\n",
      "--------------------------\n",
      "Target token: all\n",
      "token_idx: 520\n",
      "maskP [7.779920707662313e-08, 7.353247610808467e-08]\n",
      "['Ã¼ber', 'all']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.56658415923539e-08\n",
      "-- Target Rank:  18679\n",
      "-- Target Entropy:  5.494452476501465\n",
      "--------------------------\n",
      "Target token: sein\n",
      "token_idx: 5579\n",
      "maskP [7.621625286446942e-08]\n",
      "['sein']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.621625286446942e-08\n",
      "-- Target Rank:  15819\n",
      "-- Target Entropy:  4.983212471008301\n",
      "--------------------------\n",
      "Target token: und\n",
      "token_idx: 283\n",
      "maskP [1.4408567949431017e-05]\n",
      "['und']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.4408567949431017e-05\n",
      "-- Target Rank:  2865\n",
      "-- Target Entropy:  5.121635913848877\n",
      "--------------------------\n",
      "Target token: Frauen\n",
      "token_idx: 11678\n",
      "maskP [0.00019128876738250256]\n",
      "['Frauen']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.00019128876738250256\n",
      "-- Target Rank:  224\n",
      "-- Target Entropy:  2.8845956325531006\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [4.241257101966767e-06]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.241257101966767e-06\n",
      "-- Target Rank:  3921\n",
      "-- Target Entropy:  4.675729751586914\n",
      "--------------------------\n",
      "Target token: in\n",
      "token_idx: 269\n",
      "maskP [1.9285398593638092e-05]\n",
      "['in']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.9285398593638092e-05\n",
      "-- Target Rank:  1843\n",
      "-- Target Entropy:  5.388428688049316\n",
      "--------------------------\n",
      "Target token: einer\n",
      "token_idx: 2276\n",
      "maskP [5.431848421721952e-06]\n",
      "['einer']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.431848421721952e-06\n",
      "-- Target Rank:  4433\n",
      "-- Target Entropy:  4.822605609893799\n",
      "--------------------------\n",
      "Target token: tradition\n",
      "token_idx: 42714\n",
      "--------------------------\n",
      "Target token: ellen\n",
      "token_idx: 2546\n",
      "maskP [5.82911354740645e-07, 6.402049734788307e-08]\n",
      "['tradition', 'ellen']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.2346592604426405e-07\n",
      "-- Target Rank:  14326\n",
      "-- Target Entropy:  6.911291599273682\n",
      "--------------------------\n",
      "Target token: Familie\n",
      "token_idx: 18422\n",
      "maskP [1.004317709885072e-05]\n",
      "['Familie']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.004317709885072e-05\n",
      "-- Target Rank:  3534\n",
      "-- Target Entropy:  5.702281475067139\n",
      "--------------------------\n",
      "Target token: am\n",
      "token_idx: 343\n",
      "maskP [1.047369664775033e-06]\n",
      "['am']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.047369664775033e-06\n",
      "-- Target Rank:  5442\n",
      "-- Target Entropy:  4.950534820556641\n",
      "--------------------------\n",
      "Target token: glÃ¼ck\n",
      "token_idx: 1306\n",
      "--------------------------\n",
      "Target token: lich\n",
      "token_idx: 341\n",
      "--------------------------\n",
      "Target token: sten\n",
      "token_idx: 448\n",
      "maskP [4.0595298855805595e-07, 1.4467019582298235e-08, 4.863643709995813e-08]\n",
      "['glÃ¼ck', 'lich', 'sten']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.5635214841343745e-07\n",
      "-- Target Rank:  10668\n",
      "-- Target Entropy:  4.9929423332214355\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [1.4102917702984996e-05]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.4102917702984996e-05\n",
      "-- Target Rank:  3473\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: bei\n",
      "token_idx: 1305\n",
      "maskP [2.1732619188696845e-06]\n",
      "['bei']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.1732619188696845e-06\n",
      "-- Target Rank:  7992\n",
      "-- Target Entropy:  5.974837303161621\n",
      "--------------------------\n",
      "Target token: S\n",
      "token_idx: 55\n",
      "--------------------------\n",
      "Target token: orger\n",
      "token_idx: 20126\n",
      "--------------------------\n",
      "Target token: echts\n",
      "token_idx: 26017\n",
      "--------------------------\n",
      "Target token: fragen\n",
      "token_idx: 4909\n",
      "maskP [2.2944650481804274e-06, 8.01631294677918e-09, 8.31919244603796e-09, 9.218818377121352e-06]\n",
      "['S', 'orger', 'echts', 'fragen']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.882404732673649e-06\n",
      "-- Target Rank:  4214\n",
      "-- Target Entropy:  4.750674247741699\n",
      "--------------------------\n",
      "Target token: priv\n",
      "token_idx: 21554\n",
      "--------------------------\n",
      "Target token: ileg\n",
      "token_idx: 15362\n",
      "--------------------------\n",
      "Target token: iert\n",
      "token_idx: 588\n",
      "maskP [3.823925354140556e-08, 1.939830074348947e-09, 3.480448640402756e-08]\n",
      "['priv', 'ileg', 'iert']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.4994523339927355e-08\n",
      "-- Target Rank:  20754\n",
      "-- Target Entropy:  5.706724643707275\n",
      "--------------------------\n",
      "Target token: haben\n",
      "token_idx: 4199\n",
      "maskP [7.831689799786545e-06]\n",
      "['haben']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.831689799786545e-06\n",
      "-- Target Rank:  5047\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: groÃŁe\n",
      "token_idx: 10237\n",
      "maskP [1.859804577009072e-08]\n",
      "['groÃŁe']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.859804577009072e-08\n",
      "-- Target Rank:  34146\n",
      "-- Target Entropy:  5.9237775802612305\n",
      "--------------------------\n",
      "Target token: Vort\n",
      "token_idx: 29101\n",
      "--------------------------\n",
      "Target token: eile\n",
      "token_idx: 1827\n",
      "maskP [1.312308268097695e-05, 6.23812834721349e-10]\n",
      "['Vort', 'eile']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.5618532469058355e-06\n",
      "-- Target Rank:  1968\n",
      "-- Target Entropy:  4.5583577156066895\n",
      "--------------------------\n",
      "Target token: bei\n",
      "token_idx: 1305\n",
      "maskP [3.6318929232947994e-06]\n",
      "['bei']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.6318929232947994e-06\n",
      "-- Target Rank:  1059\n",
      "-- Target Entropy:  2.9640684127807617\n",
      "--------------------------\n",
      "Target token: Gerichts\n",
      "token_idx: 33660\n",
      "--------------------------\n",
      "Target token: entscheidungen\n",
      "token_idx: 30682\n",
      "maskP [6.930147011807719e-10, 3.2669501592863526e-07]\n",
      "['Gerichts', 'entscheidungen']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.6369401531490801e-07\n",
      "-- Target Rank:  17935\n",
      "-- Target Entropy:  4.051307201385498\n",
      "--------------------------\n",
      "Target token: Ã¼ber\n",
      "token_idx: 3545\n",
      "maskP [1.9690206443101488e-07]\n",
      "['Ã¼ber']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.9690206443101488e-07\n",
      "-- Target Rank:  7082\n",
      "-- Target Entropy:  2.545945167541504\n",
      "--------------------------\n",
      "Target token: den\n",
      "token_idx: 324\n",
      "maskP [6.0280344769125804e-05]\n",
      "['den']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.0280344769125804e-05\n",
      "-- Target Rank:  1646\n",
      "-- Target Entropy:  6.300941467285156\n",
      "--------------------------\n",
      "Target token: Ver\n",
      "token_idx: 1068\n",
      "--------------------------\n",
      "Target token: bleib\n",
      "token_idx: 22247\n",
      "maskP [8.459464879706502e-07, 4.620303029057027e-10]\n",
      "['Ver', 'bleib']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.2320425913677795e-07\n",
      "-- Target Rank:  10964\n",
      "-- Target Entropy:  6.036040782928467\n",
      "--------------------------\n",
      "Target token: der\n",
      "token_idx: 320\n",
      "maskP [3.635946995927952e-05]\n",
      "['der']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.635946995927952e-05\n",
      "-- Target Rank:  224\n",
      "-- Target Entropy:  2.5685770511627197\n",
      "--------------------------\n",
      "Target token: eigenen\n",
      "token_idx: 19324\n",
      "maskP [1.6542059029234224e-06]\n",
      "['eigenen']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.6542059029234224e-06\n",
      "-- Target Rank:  10882\n",
      "-- Target Entropy:  6.047636985778809\n",
      "--------------------------\n",
      "Target token: Kinder\n",
      "token_idx: 8977\n",
      "maskP [2.7457652322482318e-05]\n",
      "['Kinder']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.7457652322482318e-05\n",
      "-- Target Rank:  1834\n",
      "-- Target Entropy:  5.579922676086426\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [1.4102917702984996e-05]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.4102917702984996e-05\n",
      "-- Target Rank:  3473\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: im\n",
      "token_idx: 487\n",
      "maskP [2.7128726287628524e-06]\n",
      "['im']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.7128726287628524e-06\n",
      "-- Target Rank:  7144\n",
      "-- Target Entropy:  5.974837303161621\n",
      "--------------------------\n",
      "Target token: Durchschnitt\n",
      "token_idx: 23778\n",
      "maskP [6.874789164612594e-07]\n",
      "['Durchschnitt']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.874789164612594e-07\n",
      "-- Target Rank:  12402\n",
      "-- Target Entropy:  5.6138529777526855\n",
      "--------------------------\n",
      "Target token: schw\n",
      "token_idx: 2028\n",
      "--------------------------\n",
      "Target token: Ã¤cher\n",
      "token_idx: 3545\n",
      "maskP [9.365507480652013e-07, 4.302963318991715e-08]\n",
      "['schw', 'Ã¤cher']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.897901906275592e-07\n",
      "-- Target Rank:  5891\n",
      "-- Target Entropy:  5.349737644195557\n",
      "--------------------------\n",
      "Target token: als\n",
      "token_idx: 1239\n",
      "maskP [2.0002584278699942e-05]\n",
      "['als']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.0002584278699942e-05\n",
      "-- Target Rank:  738\n",
      "-- Target Entropy:  3.565925359725952\n",
      "--------------------------\n",
      "Target token: MÃ¤nner\n",
      "token_idx: 49\n",
      "maskP [2.821468854108389e-07]\n",
      "['MÃ¤nner']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.821468854108389e-07\n",
      "-- Target Rank:  6731\n",
      "-- Target Entropy:  2.785688877105713\n",
      "--------------------------\n",
      "Target token: in\n",
      "token_idx: 269\n",
      "maskP [1.665290074015502e-05]\n",
      "['in']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.665290074015502e-05\n",
      "-- Target Rank:  520\n",
      "-- Target Entropy:  2.471797466278076\n",
      "--------------------------\n",
      "Target token: phys\n",
      "token_idx: 20003\n",
      "--------------------------\n",
      "Target token: ischen\n",
      "token_idx: 419\n",
      "maskP [9.357580665891874e-08, 7.522354650291163e-08]\n",
      "['phys', 'ischen']\n",
      "-- Target Probability (mean of probabilities in maskP):  8.439967658091518e-08\n",
      "-- Target Rank:  18175\n",
      "-- Target Entropy:  4.117394924163818\n",
      "--------------------------\n",
      "Target token: A\n",
      "token_idx: 37\n",
      "--------------------------\n",
      "Target token: sp\n",
      "token_idx: 432\n",
      "--------------------------\n",
      "Target token: ekten\n",
      "token_idx: 4197\n",
      "maskP [1.0424310659118419e-07, 3.737673281989373e-09, 2.171640089976279e-10]\n",
      "['A', 'sp', 'ekten']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.606598129405706e-08\n",
      "-- Target Rank:  11696\n",
      "-- Target Entropy:  4.401853561401367\n",
      "--------------------------\n",
      "Target token: Gen\n",
      "token_idx: 3370\n",
      "--------------------------\n",
      "Target token: der\n",
      "token_idx: 320\n",
      "--------------------------\n",
      "Target token: -\n",
      "token_idx: 17\n",
      "--------------------------\n",
      "Target token: P\n",
      "token_idx: 52\n",
      "--------------------------\n",
      "Target token: ay\n",
      "token_idx: 759\n",
      "--------------------------\n",
      "Target token: -\n",
      "token_idx: 17\n",
      "--------------------------\n",
      "Target token: G\n",
      "token_idx: 43\n",
      "--------------------------\n",
      "Target token: ap\n",
      "token_idx: 651\n",
      "maskP [3.091132043664402e-07, 3.963359631597996e-06, 8.271169645013288e-05, 6.634542842220981e-06, 3.070869638577278e-07, 8.271169645013288e-05, 2.8016224860039074e-06, 1.4253283779908088e-06]\n",
      "['Gen', 'der', '-', 'P', 'ay', '-', 'G', 'ap']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.2608055800787952e-05\n",
      "-- Target Rank:  2316\n",
      "-- Target Entropy:  8.566091537475586\n",
      "--------------------------\n",
      "Target token: ist\n",
      "token_idx: 510\n",
      "maskP [2.1256248146528378e-05]\n",
      "['ist']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.1256248146528378e-05\n",
      "-- Target Rank:  981\n",
      "-- Target Entropy:  2.956205129623413\n",
      "--------------------------\n",
      "Target token: kein\n",
      "token_idx: 28570\n",
      "maskP [1.0677664477043436e-06]\n",
      "['kein']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.0677664477043436e-06\n",
      "-- Target Rank:  4571\n",
      "-- Target Entropy:  4.883272171020508\n",
      "--------------------------\n",
      "Target token: Problem\n",
      "token_idx: 15393\n",
      "maskP [4.988445425624377e-07]\n",
      "['Problem']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.988445425624377e-07\n",
      "-- Target Rank:  11469\n",
      "-- Target Entropy:  6.188199520111084\n",
      "--------------------------\n",
      "Target token: des\n",
      "token_idx: 2632\n",
      "maskP [1.7195509371958906e-06]\n",
      "['des']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.7195509371958906e-06\n",
      "-- Target Rank:  790\n",
      "-- Target Entropy:  2.100468873977661\n",
      "--------------------------\n",
      "Target token: Sex\n",
      "token_idx: 23173\n",
      "--------------------------\n",
      "Target token: ismus\n",
      "token_idx: 2072\n",
      "maskP [1.5635981753803208e-07, 2.6743102807813557e-06]\n",
      "['Sex', 'ismus']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.4153350491596939e-06\n",
      "-- Target Rank:  8938\n",
      "-- Target Entropy:  6.8117780685424805\n",
      "--------------------------\n",
      "Target token: kÃ¶nnen\n",
      "token_idx: 79\n",
      "maskP [0.0002068869798677042]\n",
      "['kÃ¶nnen']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0002068869798677042\n",
      "-- Target Rank:  424\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: sich\n",
      "token_idx: 12592\n",
      "maskP [1.714686914056074e-05]\n",
      "['sich']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.714686914056074e-05\n",
      "-- Target Rank:  2463\n",
      "-- Target Entropy:  5.745215892791748\n",
      "--------------------------\n",
      "Target token: besser\n",
      "token_idx: 2402\n",
      "maskP [3.0216639856917027e-07]\n",
      "['besser']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.0216639856917027e-07\n",
      "-- Target Rank:  13970\n",
      "-- Target Entropy:  5.4003005027771\n",
      "--------------------------\n",
      "Target token: um\n",
      "token_idx: 335\n",
      "maskP [3.7201294844635413e-07]\n",
      "['um']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.7201294844635413e-07\n",
      "-- Target Rank:  7842\n",
      "-- Target Entropy:  4.913818836212158\n",
      "--------------------------\n",
      "Target token: Kinder\n",
      "token_idx: 8977\n",
      "maskP [2.0319650957389968e-06]\n",
      "['Kinder']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.0319650957389968e-06\n",
      "-- Target Rank:  8504\n",
      "-- Target Entropy:  4.561654567718506\n",
      "--------------------------\n",
      "Target token: und\n",
      "token_idx: 283\n",
      "maskP [5.157278792466968e-06]\n",
      "['und']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.157278792466968e-06\n",
      "-- Target Rank:  511\n",
      "-- Target Entropy:  0.8934149742126465\n",
      "--------------------------\n",
      "Target token: Familie\n",
      "token_idx: 18422\n",
      "maskP [1.7100452168961056e-05]\n",
      "['Familie']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.7100452168961056e-05\n",
      "-- Target Rank:  1159\n",
      "-- Target Entropy:  4.331591606140137\n",
      "--------------------------\n",
      "Target token: k\n",
      "token_idx: 79\n",
      "--------------------------\n",
      "Target token: Ã¼mmern\n",
      "token_idx: 3545\n",
      "--------------------------\n",
      "Target token: ,\n",
      "token_idx: 16\n",
      "maskP [8.544438401258958e-07, 1.2218885625525644e-10, 0.0029878520872443914]\n",
      "['k', 'Ã¼mmern', ',']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0009962355510911246\n",
      "-- Target Rank:  2\n",
      "-- Target Entropy:  0.1945684254169464\n",
      "--------------------------\n",
      "Target token: es\n",
      "token_idx: 271\n",
      "maskP [1.4959896361688152e-06]\n",
      "['es']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.4959896361688152e-06\n",
      "-- Target Rank:  7012\n",
      "-- Target Entropy:  4.479317665100098\n",
      "--------------------------\n",
      "Target token: liegt\n",
      "token_idx: 8041\n",
      "maskP [1.585452196195547e-07]\n",
      "['liegt']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.585452196195547e-07\n",
      "-- Target Rank:  5819\n",
      "-- Target Entropy:  3.053774356842041\n",
      "--------------------------\n",
      "Target token: in\n",
      "token_idx: 269\n",
      "maskP [3.0347543997777393e-06]\n",
      "['in']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.0347543997777393e-06\n",
      "-- Target Rank:  1032\n",
      "-- Target Entropy:  3.4050681591033936\n",
      "--------------------------\n",
      "Target token: ihr\n",
      "token_idx: 21180\n",
      "--------------------------\n",
      "Target token: er\n",
      "token_idx: 261\n",
      "maskP [3.245243715355173e-05, 4.042126988679229e-07]\n",
      "['ihr', 'er']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.6428324926209825e-05\n",
      "-- Target Rank:  233\n",
      "-- Target Entropy:  2.3494749069213867\n",
      "--------------------------\n",
      "Target token: Natur\n",
      "token_idx: 15726\n",
      "maskP [9.625937309465371e-06]\n",
      "['Natur']\n",
      "-- Target Probability (mean of probabilities in maskP):  9.625937309465371e-06\n",
      "-- Target Rank:  973\n",
      "-- Target Entropy:  2.7291908264160156\n",
      "--------------------------\n",
      "Target token: Frauen\n",
      "token_idx: 11678\n",
      "--------------------------\n",
      "Target token: quoten\n",
      "token_idx: 17540\n",
      "maskP [2.2516535125305381e-07, 4.373978068628048e-09]\n",
      "['Frauen', 'quoten']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.1476966466084093e-07\n",
      "-- Target Rank:  22576\n",
      "-- Target Entropy:  7.490795612335205\n",
      "maskP []\n",
      "WARNING: maskp is empty list 4.373978068628048e-09\n",
      "[]\n",
      "-- Target Probability (mean of probabilities in maskP):  warning\n",
      "-- Target Rank:  50265\n",
      "-- Target Entropy:  0.0\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [6.98681834609971e-10]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.98681834609971e-10\n",
      "-- Target Rank:  32269\n",
      "-- Target Entropy:  4.151603698730469\n",
      "--------------------------\n",
      "Target token: unn\n",
      "token_idx: 4294\n",
      "--------------------------\n",
      "Target token: Ã¶\n",
      "token_idx: 3545\n",
      "--------------------------\n",
      "Target token: tig\n",
      "token_idx: 550\n",
      "maskP [2.0957111246389104e-07, 8.217099889407109e-09, 2.4076626914393273e-07]\n",
      "['unn', 'Ã¶', 'tig']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.5285149383241028e-07\n",
      "-- Target Rank:  14889\n",
      "-- Target Entropy:  5.32805061340332\n",
      "--------------------------\n",
      "Target token: und\n",
      "token_idx: 283\n",
      "maskP [3.538032615324482e-05]\n",
      "['und']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.538032615324482e-05\n",
      "-- Target Rank:  286\n",
      "-- Target Entropy:  2.477287769317627\n",
      "--------------------------\n",
      "Target token: kon\n",
      "token_idx: 1430\n",
      "--------------------------\n",
      "Target token: tra\n",
      "token_idx: 662\n",
      "--------------------------\n",
      "Target token: produ\n",
      "token_idx: 3254\n",
      "--------------------------\n",
      "Target token: ktiv\n",
      "token_idx: 1169\n",
      "maskP [6.20639696080616e-07, 1.6839359204823268e-06, 2.227247250630171e-06, 5.100198663399169e-08]\n",
      "['kon', 'tra', 'produ', 'ktiv']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.1457062134567764e-06\n",
      "-- Target Rank:  4892\n",
      "-- Target Entropy:  5.81797456741333\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [1.113569214794552e-05]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.113569214794552e-05\n",
      "-- Target Rank:  3438\n",
      "-- Target Entropy:  5.121635913848877\n",
      "--------------------------\n",
      "Target token: un\n",
      "token_idx: 267\n",
      "--------------------------\n",
      "Target token: sozial\n",
      "token_idx: 6728\n",
      "maskP [8.175549623956613e-07, 1.3674707588506863e-07]\n",
      "['un', 'sozial']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.77151019140365e-07\n",
      "-- Target Rank:  13296\n",
      "-- Target Entropy:  6.327621936798096\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [1.113569214794552e-05]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.113569214794552e-05\n",
      "-- Target Rank:  3438\n",
      "-- Target Entropy:  5.121635913848877\n",
      "--------------------------\n",
      "Target token: d\n",
      "token_idx: 72\n",
      "--------------------------\n",
      "Target token: Ã¼mmer\n",
      "token_idx: 3545\n",
      "maskP [9.79535161604872e-06, 3.71286290601347e-07]\n",
      "['d', 'Ã¼mmer']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.083318953325033e-06\n",
      "-- Target Rank:  4106\n",
      "-- Target Entropy:  6.327621936798096\n",
      "--------------------------\n",
      "Target token: als\n",
      "token_idx: 1239\n",
      "maskP [2.4439859771518968e-05]\n",
      "['als']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.4439859771518968e-05\n",
      "-- Target Rank:  120\n",
      "-- Target Entropy:  1.3082375526428223\n",
      "--------------------------\n",
      "Target token: Frauen\n",
      "token_idx: 11678\n",
      "maskP [1.4300333361916273e-07]\n",
      "['Frauen']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.4300333361916273e-07\n",
      "-- Target Rank:  14070\n",
      "-- Target Entropy:  4.429445266723633\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [1.113569214794552e-05]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.113569214794552e-05\n",
      "-- Target Rank:  3438\n",
      "-- Target Entropy:  5.121635913848877\n",
      "--------------------------\n",
      "Target token: un\n",
      "token_idx: 267\n",
      "--------------------------\n",
      "Target token: zu\n",
      "token_idx: 636\n",
      "--------------------------\n",
      "Target token: verlÃ¤ss\n",
      "token_idx: 4791\n",
      "--------------------------\n",
      "Target token: iger\n",
      "token_idx: 851\n",
      "maskP [8.175549623956613e-07, 3.928169462596998e-06, 1.9478133594930114e-07, 2.4342861593140697e-07]\n",
      "['un', 'zu', 'verlÃ¤ss', 'iger']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.2959835942183418e-06\n",
      "-- Target Rank:  6666\n",
      "-- Target Entropy:  6.327621936798096\n",
      "--------------------------\n",
      "Target token: als\n",
      "token_idx: 1239\n",
      "maskP [5.260816124064149e-06]\n",
      "['als']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.260816124064149e-06\n",
      "-- Target Rank:  1871\n",
      "-- Target Entropy:  2.5893194675445557\n",
      "--------------------------\n",
      "Target token: Frauen\n",
      "token_idx: 11678\n",
      "maskP [5.4793254093965515e-06]\n",
      "['Frauen']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.4793254093965515e-06\n",
      "-- Target Rank:  3556\n",
      "-- Target Entropy:  4.080101490020752\n",
      "--------------------------\n",
      "Target token: MÃ¤nner\n",
      "token_idx: 49\n",
      "maskP [3.383420050795394e-07]\n",
      "['MÃ¤nner']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.383420050795394e-07\n",
      "-- Target Rank:  26471\n",
      "-- Target Entropy:  7.546823501586914\n",
      "maskP []\n",
      "WARNING: maskp is empty list 3.383420050795394e-07\n",
      "[]\n",
      "-- Target Probability (mean of probabilities in maskP):  warning\n",
      "-- Target Rank:  50265\n",
      "-- Target Entropy:  0.0\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [7.126290668679758e-10]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.126290668679758e-10\n",
      "-- Target Rank:  17986\n",
      "-- Target Entropy:  2.1264774799346924\n",
      "--------------------------\n",
      "Target token: Mach\n",
      "token_idx: 9539\n",
      "--------------------------\n",
      "Target token: os\n",
      "token_idx: 476\n",
      "maskP [6.496455817739388e-09, 2.058547352135065e-06]\n",
      "['Mach', 'os']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.0325219039764022e-06\n",
      "-- Target Rank:  9771\n",
      "-- Target Entropy:  6.600179672241211\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [1.113569214794552e-05]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.113569214794552e-05\n",
      "-- Target Rank:  3438\n",
      "-- Target Entropy:  5.121635913848877\n",
      "--------------------------\n",
      "Target token: nicht\n",
      "token_idx: 7272\n",
      "maskP [3.3912060644070152e-06]\n",
      "['nicht']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.3912060644070152e-06\n",
      "-- Target Rank:  7212\n",
      "-- Target Entropy:  6.327621936798096\n",
      "--------------------------\n",
      "Target token: die\n",
      "token_idx: 2327\n",
      "maskP [2.007478178711608e-05]\n",
      "['die']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.007478178711608e-05\n",
      "-- Target Rank:  1879\n",
      "-- Target Entropy:  5.6347222328186035\n",
      "--------------------------\n",
      "Target token: hell\n",
      "token_idx: 32021\n",
      "--------------------------\n",
      "Target token: sten\n",
      "token_idx: 448\n",
      "maskP [2.526317643969378e-08, 5.342405415831308e-07]\n",
      "['hell', 'sten']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.797518590114123e-07\n",
      "-- Target Rank:  10771\n",
      "-- Target Entropy:  4.234888076782227\n",
      "--------------------------\n",
      "Target token: Mann\n",
      "token_idx: 7100\n",
      "maskP [3.9983792703424115e-06]\n",
      "['Mann']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.9983792703424115e-06\n",
      "-- Target Rank:  14856\n",
      "-- Target Entropy:  8.252379417419434\n",
      "--------------------------\n",
      "Target token: ver\n",
      "token_idx: 446\n",
      "--------------------------\n",
      "Target token: pr\n",
      "token_idx: 987\n",
      "--------------------------\n",
      "Target token: asst\n",
      "token_idx: 1913\n",
      "maskP [4.910203642793931e-06, 2.8634943305405614e-07, 2.1832139651678517e-08]\n",
      "['ver', 'pr', 'asst']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.7394617384998885e-06\n",
      "-- Target Rank:  2048\n",
      "-- Target Entropy:  4.577455997467041\n",
      "--------------------------\n",
      "Target token: das\n",
      "token_idx: 5972\n",
      "maskP [7.049495707178721e-07]\n",
      "['das']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.049495707178721e-07\n",
      "-- Target Rank:  9441\n",
      "-- Target Entropy:  5.555641174316406\n",
      "--------------------------\n",
      "Target token: Geld\n",
      "token_idx: 21094\n",
      "maskP [8.296269697893877e-06]\n",
      "['Geld']\n",
      "-- Target Probability (mean of probabilities in maskP):  8.296269697893877e-06\n",
      "-- Target Rank:  2422\n",
      "-- Target Entropy:  3.3239285945892334\n",
      "--------------------------\n",
      "Target token: gehÃ¶ren\n",
      "token_idx: 2571\n",
      "maskP [0.00010227308666799217]\n",
      "['gehÃ¶ren']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.00010227308666799217\n",
      "-- Target Rank:  566\n",
      "-- Target Entropy:  5.121635913848877\n",
      "--------------------------\n",
      "Target token: auf\n",
      "token_idx: 587\n",
      "maskP [3.5727518934436375e-06]\n",
      "['auf']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.5727518934436375e-06\n",
      "-- Target Rank:  2763\n",
      "-- Target Entropy:  3.936779499053955\n",
      "--------------------------\n",
      "Target token: den\n",
      "token_idx: 324\n",
      "maskP [2.1584877686109394e-05]\n",
      "['den']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.1584877686109394e-05\n",
      "-- Target Rank:  1577\n",
      "-- Target Entropy:  4.425355911254883\n",
      "--------------------------\n",
      "Target token: Bau\n",
      "token_idx: 11000\n",
      "maskP [1.2888307310277014e-07]\n",
      "['Bau']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.2888307310277014e-07\n",
      "-- Target Rank:  19239\n",
      "-- Target Entropy:  6.664018154144287\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [1.113569214794552e-05]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.113569214794552e-05\n",
      "-- Target Rank:  3438\n",
      "-- Target Entropy:  5.121635913848877\n",
      "--------------------------\n",
      "Target token: bei\n",
      "token_idx: 1305\n",
      "maskP [1.1866711702168686e-06]\n",
      "['bei']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.1866711702168686e-06\n",
      "-- Target Rank:  11516\n",
      "-- Target Entropy:  6.327621936798096\n",
      "--------------------------\n",
      "Target token: Stellen\n",
      "token_idx: 23858\n",
      "--------------------------\n",
      "Target token: ver\n",
      "token_idx: 446\n",
      "--------------------------\n",
      "Target token: gaben\n",
      "token_idx: 1539\n",
      "maskP [1.4922344249157504e-08, 1.1474413668111083e-06, 1.0721192666096613e-05]\n",
      "['Stellen', 'ver', 'gaben']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.961185459052293e-06\n",
      "-- Target Rank:  3771\n",
      "-- Target Entropy:  4.7515177726745605\n",
      "--------------------------\n",
      "Target token: priv\n",
      "token_idx: 21554\n",
      "--------------------------\n",
      "Target token: ileg\n",
      "token_idx: 15362\n",
      "--------------------------\n",
      "Target token: iert\n",
      "token_idx: 588\n",
      "maskP [4.452870072668702e-08, 1.1704967661785304e-08, 6.861785095679807e-08]\n",
      "['priv', 'ileg', 'iert']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.161717311509013e-08\n",
      "-- Target Rank:  19656\n",
      "-- Target Entropy:  5.4483842849731445\n",
      "--------------------------\n",
      "Target token: verb\n",
      "token_idx: 1872\n",
      "--------------------------\n",
      "Target token: ingen\n",
      "token_idx: 1245\n",
      "maskP [7.624942099937471e-06, 8.460930075671058e-06]\n",
      "['verb', 'ingen']\n",
      "-- Target Probability (mean of probabilities in maskP):  8.042936087804264e-06\n",
      "-- Target Rank:  4174\n",
      "-- Target Entropy:  5.121635913848877\n",
      "--------------------------\n",
      "Target token: wen\n",
      "token_idx: 4540\n",
      "--------------------------\n",
      "Target token: ig\n",
      "token_idx: 371\n",
      "maskP [4.027172195719686e-08, 5.1244523291416044e-08]\n",
      "['wen', 'ig']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.575812262430645e-08\n",
      "-- Target Rank:  27431\n",
      "-- Target Entropy:  5.668195724487305\n",
      "--------------------------\n",
      "Target token: Zeit\n",
      "token_idx: 6485\n",
      "maskP [9.332296940556262e-06]\n",
      "['Zeit']\n",
      "-- Target Probability (mean of probabilities in maskP):  9.332296940556262e-06\n",
      "-- Target Rank:  3413\n",
      "-- Target Entropy:  5.293584823608398\n",
      "--------------------------\n",
      "Target token: mit\n",
      "token_idx: 774\n",
      "maskP [7.285050287464401e-06]\n",
      "['mit']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.285050287464401e-06\n",
      "-- Target Rank:  508\n",
      "-- Target Entropy:  3.0110137462615967\n",
      "--------------------------\n",
      "Target token: i\n",
      "token_idx: 77\n",
      "--------------------------\n",
      "Target token: hren\n",
      "token_idx: 3031\n",
      "maskP [3.7221152524580248e-06, 1.1130244814694379e-07]\n",
      "['i', 'hren']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.9167088503024843e-06\n",
      "-- Target Rank:  8277\n",
      "-- Target Entropy:  4.906895160675049\n",
      "--------------------------\n",
      "Target token: Kin\n",
      "token_idx: 21687\n",
      "--------------------------\n",
      "Target token: dern\n",
      "token_idx: 676\n",
      "maskP [9.078349307856115e-07, 3.332622000584706e-08]\n",
      "['Kin', 'dern']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.705805753957293e-07\n",
      "-- Target Rank:  12082\n",
      "-- Target Entropy:  6.435502529144287\n",
      "--------------------------\n",
      "Target token: MÃ¤nner\n",
      "token_idx: 49\n",
      "maskP [3.383420050795394e-07]\n",
      "['MÃ¤nner']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.383420050795394e-07\n",
      "-- Target Rank:  26471\n",
      "-- Target Entropy:  7.546823501586914\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [2.0174926248728298e-05]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.0174926248728298e-05\n",
      "-- Target Rank:  1527\n",
      "-- Target Entropy:  4.996337890625\n",
      "--------------------------\n",
      "Target token: aus\n",
      "token_idx: 481\n",
      "--------------------------\n",
      "Target token: gewachsen\n",
      "token_idx: 32583\n",
      "--------------------------\n",
      "Target token: e\n",
      "token_idx: 73\n",
      "maskP [9.823115760809742e-07, 1.1058627791271647e-07, 1.8269653082825243e-05]\n",
      "['aus', 'gewachsen', 'e']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.454183645606311e-06\n",
      "-- Target Rank:  2527\n",
      "-- Target Entropy:  6.131466388702393\n",
      "--------------------------\n",
      "Target token: Kinder\n",
      "token_idx: 8977\n",
      "maskP [1.1241967712294354e-07]\n",
      "['Kinder']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.1241967712294354e-07\n",
      "-- Target Rank:  19563\n",
      "-- Target Entropy:  6.875598430633545\n",
      "--------------------------\n",
      "Target token: haben\n",
      "token_idx: 4199\n",
      "maskP [8.21897799596627e-07]\n",
      "['haben']\n",
      "-- Target Probability (mean of probabilities in maskP):  8.21897799596627e-07\n",
      "-- Target Rank:  29189\n",
      "-- Target Entropy:  6.896925449371338\n",
      "--------------------------\n",
      "Target token: einen\n",
      "token_idx: 946\n",
      "maskP [2.556357685534749e-06]\n",
      "['einen']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.556357685534749e-06\n",
      "-- Target Rank:  9154\n",
      "-- Target Entropy:  5.656333923339844\n",
      "--------------------------\n",
      "Target token: sign\n",
      "token_idx: 29597\n",
      "--------------------------\n",
      "Target token: if\n",
      "token_idx: 1038\n",
      "--------------------------\n",
      "Target token: ikant\n",
      "token_idx: 31257\n",
      "maskP [1.4171369855375815e-08, 9.36667277073866e-08, 2.7815688641297243e-10]\n",
      "['sign', 'if', 'ikant']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.603875148305846e-08\n",
      "-- Target Rank:  26584\n",
      "-- Target Entropy:  7.367587089538574\n",
      "--------------------------\n",
      "Target token: ger\n",
      "token_idx: 452\n",
      "--------------------------\n",
      "Target token: inger\n",
      "token_idx: 2099\n",
      "--------------------------\n",
      "Target token: en\n",
      "token_idx: 262\n",
      "maskP [1.950003706951975e-06, 1.5679720490879845e-06, 3.3255059861403424e-06]\n",
      "['ger', 'inger', 'en']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.2811605807267674e-06\n",
      "-- Target Rank:  3576\n",
      "-- Target Entropy:  4.149514198303223\n",
      "--------------------------\n",
      "Target token: Durch\n",
      "token_idx: 3285\n",
      "--------------------------\n",
      "Target token: setzungs\n",
      "token_idx: 21739\n",
      "--------------------------\n",
      "Target token: willen\n",
      "token_idx: 34177\n",
      "maskP [8.685656780471618e-07, 6.2788938492985835e-09, 1.4843869466929505e-09]\n",
      "['Durch', 'setzungs', 'willen']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.921096529477178e-07\n",
      "-- Target Rank:  10844\n",
      "-- Target Entropy:  6.258306503295898\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [4.994048595108325e-06]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.994048595108325e-06\n",
      "-- Target Rank:  7129\n",
      "-- Target Entropy:  6.296268939971924\n",
      "--------------------------\n",
      "Target token: psych\n",
      "token_idx: 19240\n",
      "--------------------------\n",
      "Target token: isch\n",
      "token_idx: 347\n",
      "maskP [4.320085622566694e-07, 1.840171535150148e-07]\n",
      "['psych', 'isch']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.080128578858421e-07\n",
      "-- Target Rank:  17353\n",
      "-- Target Entropy:  6.436309814453125\n",
      "--------------------------\n",
      "Target token: nicht\n",
      "token_idx: 7272\n",
      "maskP [1.1526776866332966e-08]\n",
      "['nicht']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.1526776866332966e-08\n",
      "-- Target Rank:  8750\n",
      "-- Target Entropy:  3.659461259841919\n",
      "--------------------------\n",
      "Target token: fÃ¼r\n",
      "token_idx: 74\n",
      "maskP [1.5765699856729043e-07]\n",
      "['fÃ¼r']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.5765699856729043e-07\n",
      "-- Target Rank:  5044\n",
      "-- Target Entropy:  3.8654518127441406\n",
      "--------------------------\n",
      "Target token: komplex\n",
      "token_idx: 16054\n",
      "--------------------------\n",
      "Target token: e\n",
      "token_idx: 73\n",
      "maskP [3.0396034844670794e-07, 8.621422239230014e-06]\n",
      "['komplex', 'e']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.462691293838361e-06\n",
      "-- Target Rank:  2190\n",
      "-- Target Entropy:  3.968801736831665\n",
      "--------------------------\n",
      "Target token: Arbeit\n",
      "token_idx: 13936\n",
      "maskP [1.1958534287259681e-06]\n",
      "['Arbeit']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.1958534287259681e-06\n",
      "-- Target Rank:  7588\n",
      "-- Target Entropy:  5.762393474578857\n",
      "--------------------------\n",
      "Target token: gesch\n",
      "token_idx: 877\n",
      "--------------------------\n",
      "Target token: affen\n",
      "token_idx: 1864\n",
      "maskP [3.3131316286016954e-06, 1.8455960315577613e-08]\n",
      "['gesch', 'affen']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.6657937944586365e-06\n",
      "-- Target Rank:  1785\n",
      "-- Target Entropy:  3.6509463787078857\n",
      "--------------------------\n",
      "Target token: haben\n",
      "token_idx: 4199\n",
      "maskP [1.9426937797106802e-05]\n",
      "['haben']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.9426937797106802e-05\n",
      "-- Target Rank:  3098\n",
      "-- Target Entropy:  6.296268939971924\n",
      "--------------------------\n",
      "Target token: im\n",
      "token_idx: 487\n",
      "maskP [7.852920020923193e-07]\n",
      "['im']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.852920020923193e-07\n",
      "-- Target Rank:  13643\n",
      "-- Target Entropy:  5.9342241287231445\n",
      "--------------------------\n",
      "Target token: stat\n",
      "token_idx: 2641\n",
      "--------------------------\n",
      "Target token: istischen\n",
      "token_idx: 2894\n",
      "maskP [5.412199044485533e-08, 4.098141204167405e-08]\n",
      "['stat', 'istischen']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.755170124326469e-08\n",
      "-- Target Rank:  22207\n",
      "-- Target Entropy:  5.858941555023193\n",
      "--------------------------\n",
      "Target token: Mittel\n",
      "token_idx: 10393\n",
      "maskP [1.8783466657623649e-06]\n",
      "['Mittel']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.8783466657623649e-06\n",
      "-- Target Rank:  3845\n",
      "-- Target Entropy:  3.6698086261749268\n",
      "--------------------------\n",
      "Target token: ein\n",
      "token_idx: 272\n",
      "maskP [0.00027650431729853153]\n",
      "['ein']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.00027650431729853153\n",
      "-- Target Rank:  343\n",
      "-- Target Entropy:  5.567345142364502\n",
      "--------------------------\n",
      "Target token: kleiner\n",
      "token_idx: 29047\n",
      "--------------------------\n",
      "Target token: es\n",
      "token_idx: 271\n",
      "maskP [3.169499223076855e-06, 5.612692348222481e-06]\n",
      "['kleiner', 'es']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.391095785649668e-06\n",
      "-- Target Rank:  4740\n",
      "-- Target Entropy:  5.967565059661865\n",
      "--------------------------\n",
      "Target token: Allgemein\n",
      "token_idx: 15581\n",
      "--------------------------\n",
      "Target token: wissen\n",
      "token_idx: 3126\n",
      "maskP [6.971589971982439e-10, 1.0245424419963456e-07]\n",
      "['Allgemein', 'wissen']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.15757015984164e-08\n",
      "-- Target Rank:  16513\n",
      "-- Target Entropy:  4.758600234985352\n",
      "--------------------------\n",
      "Target token: hat\n",
      "token_idx: 8491\n",
      "maskP [1.2475507901399396e-05]\n",
      "['hat']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.2475507901399396e-05\n",
      "-- Target Rank:  2681\n",
      "-- Target Entropy:  4.8592939376831055\n",
      "--------------------------\n",
      "Target token: fast\n",
      "token_idx: 5280\n",
      "maskP [3.41149011262587e-08]\n",
      "['fast']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.41149011262587e-08\n",
      "-- Target Rank:  28004\n",
      "-- Target Entropy:  5.318484306335449\n",
      "--------------------------\n",
      "Target token: nur\n",
      "token_idx: 12317\n",
      "maskP [1.0020301033364376e-06]\n",
      "['nur']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.0020301033364376e-06\n",
      "-- Target Rank:  6185\n",
      "-- Target Entropy:  4.364145278930664\n",
      "--------------------------\n",
      "Target token: Nacht\n",
      "token_idx: 18683\n",
      "--------------------------\n",
      "Target token: eile\n",
      "token_idx: 1827\n",
      "maskP [9.117710142447777e-09, 9.771060405228127e-09]\n",
      "['Nacht', 'eile']\n",
      "-- Target Probability (mean of probabilities in maskP):  9.444385273837952e-09\n",
      "-- Target Rank:  33605\n",
      "-- Target Entropy:  5.27000617980957\n",
      "--------------------------\n",
      "Target token: fÃ¼r\n",
      "token_idx: 74\n",
      "maskP [2.4510339358130295e-07]\n",
      "['fÃ¼r']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.4510339358130295e-07\n",
      "-- Target Rank:  2701\n",
      "-- Target Entropy:  2.412348985671997\n",
      "--------------------------\n",
      "Target token: die\n",
      "token_idx: 2327\n",
      "maskP [3.30207149090711e-05]\n",
      "['die']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.30207149090711e-05\n",
      "-- Target Rank:  949\n",
      "-- Target Entropy:  3.6865296363830566\n",
      "--------------------------\n",
      "Target token: Gesellschaft\n",
      "token_idx: 14026\n",
      "maskP [4.166309281572467e-06]\n",
      "['Gesellschaft']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.166309281572467e-06\n",
      "-- Target Rank:  8116\n",
      "-- Target Entropy:  6.750095367431641\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [1.7133075971287326e-06]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.7133075971287326e-06\n",
      "-- Target Rank:  8653\n",
      "-- Target Entropy:  5.05638313293457\n",
      "--------------------------\n",
      "Target token: im\n",
      "token_idx: 487\n",
      "maskP [4.4459363834903343e-07]\n",
      "['im']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.4459363834903343e-07\n",
      "-- Target Rank:  13985\n",
      "-- Target Entropy:  6.135077953338623\n",
      "--------------------------\n",
      "Target token: Durchschnitt\n",
      "token_idx: 23778\n",
      "maskP [5.764546244790836e-07]\n",
      "['Durchschnitt']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.764546244790836e-07\n",
      "-- Target Rank:  12608\n",
      "-- Target Entropy:  5.9251532554626465\n",
      "--------------------------\n",
      "Target token: d\n",
      "token_idx: 72\n",
      "--------------------------\n",
      "Target token: Ã¼mmer\n",
      "token_idx: 3545\n",
      "maskP [7.86887903814204e-06, 1.4363553901830528e-08]\n",
      "['d', 'Ã¼mmer']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.9416212960219354e-06\n",
      "-- Target Rank:  2239\n",
      "-- Target Entropy:  5.0618062019348145\n",
      "--------------------------\n",
      "Target token: als\n",
      "token_idx: 1239\n",
      "maskP [0.00029050675220787525]\n",
      "['als']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.00029050675220787525\n",
      "-- Target Rank:  45\n",
      "-- Target Entropy:  1.8431602716445923\n",
      "--------------------------\n",
      "Target token: O\n",
      "token_idx: 51\n",
      "--------------------------\n",
      "Target token: ktop\n",
      "token_idx: 23890\n",
      "--------------------------\n",
      "Target token: usse\n",
      "token_idx: 10408\n",
      "maskP [3.165023372275755e-07, 5.568234318076293e-09, 1.3438252288722197e-08]\n",
      "['O', 'ktop', 'usse']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.11836274611458e-07\n",
      "-- Target Rank:  11521\n",
      "-- Target Entropy:  4.766998767852783\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [4.202533716579637e-07]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.202533716579637e-07\n",
      "-- Target Rank:  15948\n",
      "-- Target Entropy:  5.720414638519287\n",
      "--------------------------\n",
      "Target token: Menschen\n",
      "token_idx: 14527\n",
      "maskP [8.465207770314009e-07]\n",
      "['Menschen']\n",
      "-- Target Probability (mean of probabilities in maskP):  8.465207770314009e-07\n",
      "-- Target Rank:  10258\n",
      "-- Target Entropy:  5.863741874694824\n",
      "--------------------------\n",
      "Target token: geist\n",
      "token_idx: 14935\n",
      "--------------------------\n",
      "Target token: ig\n",
      "token_idx: 371\n",
      "maskP [5.36580500920536e-06, 4.935970565611569e-08]\n",
      "['geist', 'ig']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.707582357430738e-06\n",
      "-- Target Rank:  1310\n",
      "-- Target Entropy:  2.641598701477051\n",
      "--------------------------\n",
      "Target token: in\n",
      "token_idx: 269\n",
      "maskP [3.5030987532991276e-07]\n",
      "['in']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.5030987532991276e-07\n",
      "-- Target Rank:  7468\n",
      "-- Target Entropy:  4.793551921844482\n",
      "--------------------------\n",
      "Target token: ein\n",
      "token_idx: 272\n",
      "--------------------------\n",
      "Target token: igen\n",
      "token_idx: 565\n",
      "maskP [9.359439718537033e-05, 2.581096794074256e-07]\n",
      "['ein', 'igen']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.6926253432388876e-05\n",
      "-- Target Rank:  519\n",
      "-- Target Entropy:  4.372959613800049\n",
      "--------------------------\n",
      "Target token: Ber\n",
      "token_idx: 2165\n",
      "--------------------------\n",
      "Target token: eichen\n",
      "token_idx: 3588\n",
      "maskP [6.181058864740407e-08, 1.0207729417288647e-07]\n",
      "['Ber', 'eichen']\n",
      "-- Target Probability (mean of probabilities in maskP):  8.194394141014527e-08\n",
      "-- Target Rank:  19758\n",
      "-- Target Entropy:  5.23136568069458\n",
      "--------------------------\n",
      "Target token: unter\n",
      "token_idx: 1408\n",
      "--------------------------\n",
      "Target token: legen\n",
      "token_idx: 1514\n",
      "maskP [2.1116129573783837e-06, 2.887759142922164e-09]\n",
      "['unter', 'legen']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.057250358260653e-06\n",
      "-- Target Rank:  5781\n",
      "-- Target Entropy:  5.557783603668213\n",
      "maskP []\n",
      "WARNING: maskp is empty list 2.887759142922164e-09\n",
      "[]\n",
      "-- Target Probability (mean of probabilities in maskP):  warning\n",
      "-- Target Rank:  50265\n",
      "-- Target Entropy:  0.0\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [4.2536743571908175e-10]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.2536743571908175e-10\n",
      "-- Target Rank:  37268\n",
      "-- Target Entropy:  3.440415859222412\n",
      "--------------------------\n",
      "Target token: M\n",
      "token_idx: 49\n",
      "--------------------------\n",
      "Target token: inder\n",
      "token_idx: 958\n",
      "--------------------------\n",
      "Target token: leister\n",
      "token_idx: 22120\n",
      "maskP [6.436682724597631e-07, 3.0858808486300404e-07, 1.4258243652420788e-07]\n",
      "['M', 'inder', 'leister']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.649462646156583e-07\n",
      "-- Target Rank:  12137\n",
      "-- Target Entropy:  5.279454708099365\n",
      "--------------------------\n",
      "Target token: in\n",
      "token_idx: 269\n",
      "maskP [0.00032141152769327164]\n",
      "['in']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.00032141152769327164\n",
      "-- Target Rank:  75\n",
      "-- Target Entropy:  2.958615779876709\n",
      "--------------------------\n",
      "Target token: unser\n",
      "token_idx: 42614\n",
      "--------------------------\n",
      "Target token: en\n",
      "token_idx: 262\n",
      "maskP [4.5537274218077073e-07, 3.3165395052492386e-07]\n",
      "['unser', 'en']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.935133463528473e-07\n",
      "-- Target Rank:  14156\n",
      "-- Target Entropy:  3.630183696746826\n",
      "--------------------------\n",
      "Target token: K\n",
      "token_idx: 47\n",
      "--------------------------\n",
      "Target token: nei\n",
      "token_idx: 3551\n",
      "--------------------------\n",
      "Target token: pen\n",
      "token_idx: 2494\n",
      "maskP [1.2629858474610955e-06, 1.2544091099186971e-08, 2.228493656275532e-08]\n",
      "['K', 'nei', 'pen']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.3260495837434593e-07\n",
      "-- Target Rank:  8664\n",
      "-- Target Entropy:  5.1096906661987305\n",
      "--------------------------\n",
      "Target token: kÃ¶nnen\n",
      "token_idx: 79\n",
      "maskP [1.1040647223126143e-05]\n",
      "['kÃ¶nnen']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.1040647223126143e-05\n",
      "-- Target Rank:  2449\n",
      "-- Target Entropy:  4.5513715744018555\n",
      "--------------------------\n",
      "Target token: n\n",
      "token_idx: 82\n",
      "--------------------------\n",
      "Target token: ichts\n",
      "token_idx: 1701\n",
      "maskP [2.5464992177148815e-06, 3.9700847054291444e-08]\n",
      "['n', 'ichts']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.2931000323845865e-06\n",
      "-- Target Rank:  8467\n",
      "-- Target Entropy:  5.628582954406738\n",
      "--------------------------\n",
      "Target token: und\n",
      "token_idx: 283\n",
      "maskP [2.9355621222748596e-07]\n",
      "['und']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.9355621222748596e-07\n",
      "-- Target Rank:  7508\n",
      "-- Target Entropy:  4.511490821838379\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [1.0917135114141274e-05]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.0917135114141274e-05\n",
      "-- Target Rank:  2121\n",
      "-- Target Entropy:  5.187047481536865\n",
      "--------------------------\n",
      "Target token: zu\n",
      "token_idx: 636\n",
      "maskP [1.598145900061354e-06]\n",
      "['zu']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.598145900061354e-06\n",
      "-- Target Rank:  6987\n",
      "-- Target Entropy:  5.7975754737854\n",
      "--------------------------\n",
      "Target token: d\n",
      "token_idx: 72\n",
      "--------------------------\n",
      "Target token: umm\n",
      "token_idx: 4026\n",
      "maskP [2.1837747681274777e-06, 2.786565289625287e-07]\n",
      "['d', 'umm']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.2312156485450032e-06\n",
      "-- Target Rank:  5043\n",
      "-- Target Entropy:  5.609494686126709\n",
      "--------------------------\n",
      "Target token: ru\n",
      "token_idx: 504\n",
      "--------------------------\n",
      "Target token: iniert\n",
      "token_idx: 21210\n",
      "maskP [5.200021178097813e-07, 2.434803434425703e-07]\n",
      "['ru', 'iniert']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.817412306261758e-07\n",
      "-- Target Rank:  15493\n",
      "-- Target Entropy:  5.279760837554932\n",
      "--------------------------\n",
      "Target token: oft\n",
      "token_idx: 24700\n",
      "maskP [2.867173520826327e-08]\n",
      "['oft']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.867173520826327e-08\n",
      "-- Target Rank:  27396\n",
      "-- Target Entropy:  3.4377262592315674\n",
      "--------------------------\n",
      "Target token: den\n",
      "token_idx: 324\n",
      "maskP [3.9606493373867124e-05]\n",
      "['den']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.9606493373867124e-05\n",
      "-- Target Rank:  1198\n",
      "-- Target Entropy:  4.515782833099365\n",
      "--------------------------\n",
      "Target token: grÃ¶ÃŁten\n",
      "token_idx: 667\n",
      "maskP [7.34273486457937e-09]\n",
      "['grÃ¶ÃŁten']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.34273486457937e-09\n",
      "-- Target Rank:  31178\n",
      "-- Target Entropy:  6.790289878845215\n",
      "--------------------------\n",
      "Target token: Sp\n",
      "token_idx: 1571\n",
      "--------------------------\n",
      "Target token: aÃŁ\n",
      "token_idx: 69\n",
      "maskP [2.2694206336382194e-07, 4.745726656096849e-08]\n",
      "['Sp', 'aÃŁ']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.3719966496239522e-07\n",
      "-- Target Rank:  13063\n",
      "-- Target Entropy:  2.9927518367767334\n",
      "--------------------------\n",
      "Target token: #\n",
      "token_idx: 7\n",
      "--------------------------\n",
      "Target token: kein\n",
      "token_idx: 28570\n",
      "--------------------------\n",
      "Target token: urlaub\n",
      "token_idx: 13740\n",
      "--------------------------\n",
      "Target token: -\n",
      "token_idx: 17\n",
      "--------------------------\n",
      "Target token: Bewegung\n",
      "token_idx: 17576\n",
      "maskP [5.527759867618443e-07, 4.225749083985875e-09, 1.3826868539013049e-08, 8.271169645013288e-05, 2.2373737351699674e-07]\n",
      "['#', 'kein', 'urlaub', '-', 'Bewegung']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.6701252485606944e-05\n",
      "-- Target Rank:  2316\n",
      "-- Target Entropy:  8.566091537475586\n",
      "--------------------------\n",
      "Target token: ist\n",
      "token_idx: 510\n",
      "maskP [0.00034741044510155916]\n",
      "['ist']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.00034741044510155916\n",
      "-- Target Rank:  286\n",
      "-- Target Entropy:  5.283660888671875\n",
      "--------------------------\n",
      "Target token: hy\n",
      "token_idx: 5248\n",
      "--------------------------\n",
      "Target token: ster\n",
      "token_idx: 569\n",
      "--------------------------\n",
      "Target token: isch\n",
      "token_idx: 347\n",
      "maskP [1.815332772991951e-08, 1.7409810482149624e-07, 2.2049744075047784e-07]\n",
      "['hy', 'ster', 'isch']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.3758295776729787e-07\n",
      "-- Target Rank:  13498\n",
      "-- Target Entropy:  5.148623943328857\n",
      "--------------------------\n",
      "Target token: s\n",
      "token_idx: 87\n",
      "--------------------------\n",
      "Target token: oll\n",
      "token_idx: 701\n",
      "--------------------------\n",
      "Target token: ten\n",
      "token_idx: 310\n",
      "maskP [0.007145000156015158, 1.0546595774485468e-07, 3.494258407954476e-06]\n",
      "['s', 'oll', 'ten']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.002382866626793619\n",
      "-- Target Rank:  19\n",
      "-- Target Entropy:  4.363998889923096\n",
      "--------------------------\n",
      "Target token: zu\n",
      "token_idx: 636\n",
      "maskP [4.968638677382842e-06]\n",
      "['zu']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.968638677382842e-06\n",
      "-- Target Rank:  4820\n",
      "-- Target Entropy:  5.404351711273193\n",
      "--------------------------\n",
      "Target token: H\n",
      "token_idx: 44\n",
      "--------------------------\n",
      "Target token: ause\n",
      "token_idx: 5071\n",
      "maskP [4.4040416469215415e-06, 8.119374617088226e-10]\n",
      "['H', 'ause']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.202426792191625e-06\n",
      "-- Target Rank:  3766\n",
      "-- Target Entropy:  3.354259490966797\n",
      "--------------------------\n",
      "Target token: bleiben\n",
      "token_idx: 9343\n",
      "maskP [0.005258566699922085]\n",
      "['bleiben']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.005258566699922085\n",
      "-- Target Rank:  6\n",
      "-- Target Entropy:  2.0305426120758057\n",
      "--------------------------\n",
      "Target token: und\n",
      "token_idx: 283\n",
      "maskP [2.122176010743715e-05]\n",
      "['und']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.122176010743715e-05\n",
      "-- Target Rank:  184\n",
      "-- Target Entropy:  1.9946036338806152\n",
      "--------------------------\n",
      "Target token: sich\n",
      "token_idx: 12592\n",
      "maskP [2.964513669212465e-06]\n",
      "['sich']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.964513669212465e-06\n",
      "-- Target Rank:  5682\n",
      "-- Target Entropy:  5.144406795501709\n",
      "--------------------------\n",
      "Target token: um\n",
      "token_idx: 335\n",
      "maskP [2.8523099899757653e-06]\n",
      "['um']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.8523099899757653e-06\n",
      "-- Target Rank:  2860\n",
      "-- Target Entropy:  4.131677627563477\n",
      "--------------------------\n",
      "Target token: das\n",
      "token_idx: 5972\n",
      "maskP [5.411702659330331e-06]\n",
      "['das']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.411702659330331e-06\n",
      "-- Target Rank:  1619\n",
      "-- Target Entropy:  2.8872225284576416\n",
      "--------------------------\n",
      "Target token: Kind\n",
      "token_idx: 29273\n",
      "maskP [1.709180764919438e-06]\n",
      "['Kind']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.709180764919438e-06\n",
      "-- Target Rank:  1838\n",
      "-- Target Entropy:  1.380998134613037\n",
      "--------------------------\n",
      "Target token: k\n",
      "token_idx: 79\n",
      "--------------------------\n",
      "Target token: Ã¼mmern\n",
      "token_idx: 3545\n",
      "maskP [1.8954357074107975e-05, 1.4646044377286671e-08]\n",
      "['k', 'Ã¼mmern']\n",
      "-- Target Probability (mean of probabilities in maskP):  9.48450155924263e-06\n",
      "-- Target Rank:  157\n",
      "-- Target Entropy:  0.5035662055015564\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [3.6255589748179773e-06]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.6255589748179773e-06\n",
      "-- Target Rank:  4714\n",
      "-- Target Entropy:  5.446863174438477\n",
      "--------------------------\n",
      "Target token: Ã¼ber\n",
      "token_idx: 3545\n",
      "--------------------------\n",
      "Target token: wiegend\n",
      "token_idx: 5406\n",
      "maskP [2.2661069465357286e-07, 2.5475998199908645e-07]\n",
      "['Ã¼ber', 'wiegend']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.4068533832632966e-07\n",
      "-- Target Rank:  12667\n",
      "-- Target Entropy:  4.6362738609313965\n",
      "--------------------------\n",
      "Target token: ange\n",
      "token_idx: 1209\n",
      "--------------------------\n",
      "Target token: trieben\n",
      "token_idx: 14671\n",
      "maskP [1.7178139444240514e-07, 6.255582163383622e-10]\n",
      "['ange', 'trieben']\n",
      "-- Target Probability (mean of probabilities in maskP):  8.620347632937175e-08\n",
      "-- Target Rank:  20065\n",
      "-- Target Entropy:  5.770594120025635\n",
      "--------------------------\n",
      "Target token: durch\n",
      "token_idx: 4148\n",
      "maskP [5.813081588712521e-05]\n",
      "['durch']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.813081588712521e-05\n",
      "-- Target Rank:  81\n",
      "-- Target Entropy:  1.858262300491333\n",
      "--------------------------\n",
      "Target token: Neu\n",
      "token_idx: 4406\n",
      "--------------------------\n",
      "Target token: gier\n",
      "token_idx: 11433\n",
      "--------------------------\n",
      "Target token: de\n",
      "token_idx: 313\n",
      "maskP [1.3773336249300883e-08, 2.5500973777070612e-08, 8.691980042385694e-07]\n",
      "['Neu', 'gier', 'de']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.028241047549803e-07\n",
      "-- Target Rank:  15325\n",
      "-- Target Entropy:  5.498490333557129\n",
      "--------------------------\n",
      "Target token: altern\n",
      "token_idx: 26758\n",
      "maskP [8.863157319183301e-09]\n",
      "['altern']\n",
      "-- Target Probability (mean of probabilities in maskP):  8.863157319183301e-09\n",
      "-- Target Rank:  41646\n",
      "-- Target Entropy:  5.622288227081299\n",
      "--------------------------\n",
      "Target token: wie\n",
      "token_idx: 687\n",
      "maskP [3.4076245469805144e-07]\n",
      "['wie']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.4076245469805144e-07\n",
      "-- Target Rank:  2733\n",
      "-- Target Entropy:  1.778936505317688\n",
      "--------------------------\n",
      "Target token: Milch\n",
      "token_idx: 37619\n",
      "--------------------------\n",
      "Target token: ,\n",
      "token_idx: 16\n",
      "maskP [1.240736793306496e-07, 0.000835016428027302]\n",
      "['Milch', ',']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.00041757025085331634\n",
      "-- Target Rank:  110\n",
      "-- Target Entropy:  5.711405277252197\n",
      "--------------------------\n",
      "Target token: Programm\n",
      "token_idx: 8273\n",
      "--------------------------\n",
      "Target token: ierer\n",
      "token_idx: 10009\n",
      "maskP [2.958573119826724e-08, 2.711367130814324e-09]\n",
      "['Programm', 'ierer']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.6148549164540782e-08\n",
      "-- Target Rank:  26542\n",
      "-- Target Entropy:  4.912980079650879\n",
      "--------------------------\n",
      "Target token: altern\n",
      "token_idx: 26758\n",
      "maskP [3.002529638251872e-06]\n",
      "['altern']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.002529638251872e-06\n",
      "-- Target Rank:  5429\n",
      "-- Target Entropy:  3.395850419998169\n",
      "--------------------------\n",
      "Target token: wie\n",
      "token_idx: 687\n",
      "maskP [0.001170689589343965]\n",
      "['wie']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.001170689589343965\n",
      "-- Target Rank:  44\n",
      "-- Target Entropy:  2.2923169136047363\n",
      "--------------------------\n",
      "Target token: Wein\n",
      "token_idx: 22425\n",
      "maskP [6.564474830383915e-08]\n",
      "['Wein']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.564474830383915e-08\n",
      "-- Target Rank:  26637\n",
      "-- Target Entropy:  7.0741777420043945\n",
      "--------------------------\n",
      "Target token: ges\n",
      "token_idx: 626\n",
      "--------------------------\n",
      "Target token: undes\n",
      "token_idx: 1107\n",
      "maskP [0.0001651511702220887, 1.929132167788339e-06]\n",
      "['ges', 'undes']\n",
      "-- Target Probability (mean of probabilities in maskP):  8.354015119493852e-05\n",
      "-- Target Rank:  1109\n",
      "-- Target Entropy:  8.252483367919922\n",
      "--------------------------\n",
      "Target token: Sex\n",
      "token_idx: 23173\n",
      "--------------------------\n",
      "Target token: u\n",
      "token_idx: 89\n",
      "--------------------------\n",
      "Target token: alle\n",
      "token_idx: 2390\n",
      "--------------------------\n",
      "Target token: ben\n",
      "token_idx: 366\n",
      "maskP [5.33493285104214e-08, 7.14402403900749e-08, 1.3325864023361333e-10, 3.5946103871253854e-09]\n",
      "['Sex', 'u', 'alle', 'ben']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.2129359481963826e-08\n",
      "-- Target Rank:  18733\n",
      "-- Target Entropy:  5.294729232788086\n",
      "--------------------------\n",
      "Target token: in\n",
      "token_idx: 269\n",
      "maskP [5.5245418479898944e-06]\n",
      "['in']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.5245418479898944e-06\n",
      "-- Target Rank:  1789\n",
      "-- Target Entropy:  3.8583128452301025\n",
      "--------------------------\n",
      "Target token: der\n",
      "token_idx: 320\n",
      "maskP [3.8817976019345224e-05]\n",
      "['der']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.8817976019345224e-05\n",
      "-- Target Rank:  1744\n",
      "-- Target Entropy:  5.417837619781494\n",
      "--------------------------\n",
      "Target token: Ehe\n",
      "token_idx: 33545\n",
      "maskP [4.1293512254014786e-07]\n",
      "['Ehe']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.1293512254014786e-07\n",
      "-- Target Rank:  13134\n",
      "-- Target Entropy:  5.669896125793457\n",
      "--------------------------\n",
      "Target token: ist\n",
      "token_idx: 510\n",
      "maskP [4.228091256663902e-06]\n",
      "['ist']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.228091256663902e-06\n",
      "-- Target Rank:  2215\n",
      "-- Target Entropy:  3.712773084640503\n",
      "--------------------------\n",
      "Target token: zu\n",
      "token_idx: 636\n",
      "maskP [5.323198024598241e-07]\n",
      "['zu']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.323198024598241e-07\n",
      "-- Target Rank:  6549\n",
      "-- Target Entropy:  4.984340190887451\n",
      "--------------------------\n",
      "Target token: be\n",
      "token_idx: 518\n",
      "--------------------------\n",
      "Target token: vor\n",
      "token_idx: 805\n",
      "--------------------------\n",
      "Target token: zu\n",
      "token_idx: 636\n",
      "--------------------------\n",
      "Target token: gen\n",
      "token_idx: 312\n",
      "maskP [1.2792396773875225e-05, 3.5768234738497995e-06, 7.075474513840163e-06, 0.0002591846860013902]\n",
      "['be', 'vor', 'zu', 'gen']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.065734519073885e-05\n",
      "-- Target Rank:  221\n",
      "-- Target Entropy:  4.139522552490234\n",
      "maskP []\n",
      "WARNING: maskp is empty list 0.0002591846860013902\n",
      "[]\n",
      "-- Target Probability (mean of probabilities in maskP):  warning\n",
      "-- Target Rank:  50265\n",
      "-- Target Entropy:  0.0\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [4.736541714400744e-10]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.736541714400744e-10\n",
      "-- Target Rank:  40077\n",
      "-- Target Entropy:  4.042445659637451\n",
      "--------------------------\n",
      "Target token: fÃ¼r\n",
      "token_idx: 74\n",
      "maskP [2.2877622996020364e-06]\n",
      "['fÃ¼r']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.2877622996020364e-06\n",
      "-- Target Rank:  11309\n",
      "-- Target Entropy:  6.344681739807129\n",
      "--------------------------\n",
      "Target token: best\n",
      "token_idx: 3190\n",
      "--------------------------\n",
      "Target token: immte\n",
      "token_idx: 19833\n",
      "maskP [1.4034593505130033e-06, 1.3837411927397625e-07]\n",
      "['best', 'immte']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.709167348934898e-07\n",
      "-- Target Rank:  13404\n",
      "-- Target Entropy:  5.266529083251953\n",
      "--------------------------\n",
      "Target token: Ber\n",
      "token_idx: 2165\n",
      "--------------------------\n",
      "Target token: ufe\n",
      "token_idx: 2761\n",
      "maskP [1.5997848095139489e-06, 1.8056143247235923e-08]\n",
      "['Ber', 'ufe']\n",
      "-- Target Probability (mean of probabilities in maskP):  8.089204763805924e-07\n",
      "-- Target Rank:  11476\n",
      "-- Target Entropy:  6.922850608825684\n",
      "--------------------------\n",
      "Target token: nicht\n",
      "token_idx: 7272\n",
      "maskP [9.943701115844306e-06]\n",
      "['nicht']\n",
      "-- Target Probability (mean of probabilities in maskP):  9.943701115844306e-06\n",
      "-- Target Rank:  2322\n",
      "-- Target Entropy:  5.0519118309021\n",
      "--------------------------\n",
      "Target token: ge\n",
      "token_idx: 281\n",
      "--------------------------\n",
      "Target token: eignet\n",
      "token_idx: 10106\n",
      "maskP [0.00013206887524574995, 3.286573075911292e-07]\n",
      "['ge', 'eignet']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.619876627667054e-05\n",
      "-- Target Rank:  383\n",
      "-- Target Entropy:  4.285037994384766\n",
      "--------------------------\n",
      "Target token: der\n",
      "token_idx: 320\n",
      "maskP [0.0015312677714973688]\n",
      "['der']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0015312677714973688\n",
      "-- Target Rank:  50\n",
      "-- Target Entropy:  4.115504264831543\n",
      "--------------------------\n",
      "Target token: Gesch\n",
      "token_idx: 5328\n",
      "--------------------------\n",
      "Target token: lechter\n",
      "token_idx: 14704\n",
      "maskP [3.2358866519643925e-06, 1.8303659032881114e-08]\n",
      "['Gesch', 'lechter']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.6270951554986368e-06\n",
      "-- Target Rank:  880\n",
      "-- Target Entropy:  0.8480423092842102\n",
      "--------------------------\n",
      "Target token: findet\n",
      "token_idx: 12440\n",
      "maskP [4.37940707342932e-06]\n",
      "['findet']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.37940707342932e-06\n",
      "-- Target Rank:  4333\n",
      "-- Target Entropy:  4.2744460105896\n",
      "--------------------------\n",
      "Target token: zunehmen\n",
      "token_idx: 5696\n",
      "--------------------------\n",
      "Target token: d\n",
      "token_idx: 72\n",
      "maskP [3.2313021165464306e-06, 2.537353429943323e-05]\n",
      "['zunehmen', 'd']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.4302418207989831e-05\n",
      "-- Target Rank:  829\n",
      "-- Target Entropy:  4.113677024841309\n",
      "--------------------------\n",
      "Target token: hÃ¤uf\n",
      "token_idx: 76\n",
      "--------------------------\n",
      "Target token: iger\n",
      "token_idx: 851\n",
      "maskP [7.674733751628082e-06, 3.830787065339791e-08]\n",
      "['hÃ¤uf', 'iger']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.85652081114074e-06\n",
      "-- Target Rank:  1332\n",
      "-- Target Entropy:  3.719705581665039\n",
      "--------------------------\n",
      "Target token: statt\n",
      "token_idx: 3244\n",
      "maskP [0.0007648789905942976]\n",
      "['statt']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0007648789905942976\n",
      "-- Target Rank:  34\n",
      "-- Target Entropy:  2.1036674976348877\n",
      "--------------------------\n",
      "Target token: in\n",
      "token_idx: 269\n",
      "maskP [0.00020662668976001441]\n",
      "['in']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.00020662668976001441\n",
      "-- Target Rank:  426\n",
      "-- Target Entropy:  6.071537494659424\n",
      "--------------------------\n",
      "Target token: fÃ¼hrenden\n",
      "token_idx: 74\n",
      "maskP [2.679622957657557e-05]\n",
      "['fÃ¼hrenden']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.679622957657557e-05\n",
      "-- Target Rank:  1980\n",
      "-- Target Entropy:  5.274400234222412\n",
      "--------------------------\n",
      "Target token: Position\n",
      "token_idx: 23786\n",
      "--------------------------\n",
      "Target token: en\n",
      "token_idx: 262\n",
      "maskP [1.2721422535832971e-05, 1.310427364842326e-06]\n",
      "['Position', 'en']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.015924950337649e-06\n",
      "-- Target Rank:  1558\n",
      "-- Target Entropy:  2.7704529762268066\n",
      "--------------------------\n",
      "Target token: haben\n",
      "token_idx: 4199\n",
      "maskP [2.9176489988458343e-06]\n",
      "['haben']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.9176489988458343e-06\n",
      "-- Target Rank:  6148\n",
      "-- Target Entropy:  5.215683460235596\n",
      "--------------------------\n",
      "Target token: hÃ¤\n",
      "token_idx: 76\n",
      "--------------------------\n",
      "Target token: ufig\n",
      "token_idx: 3021\n",
      "maskP [2.5310901037300937e-05, 1.7800936280565338e-09]\n",
      "['hÃ¤', 'ufig']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.2656340565464497e-05\n",
      "-- Target Rank:  1821\n",
      "-- Target Entropy:  5.619873523712158\n",
      "--------------------------\n",
      "Target token: kompl\n",
      "token_idx: 28456\n",
      "--------------------------\n",
      "Target token: izierte\n",
      "token_idx: 7066\n",
      "maskP [2.4025169409469527e-07, 2.772788931793002e-08]\n",
      "['kompl', 'izierte']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.3398979170631264e-07\n",
      "-- Target Rank:  20995\n",
      "-- Target Entropy:  6.105802059173584\n",
      "--------------------------\n",
      "Target token: Termin\n",
      "token_idx: 27152\n",
      "--------------------------\n",
      "Target token: plÃ¤ne\n",
      "token_idx: 691\n",
      "maskP [1.003506877594873e-08, 2.0487917140599166e-07]\n",
      "['Termin', 'plÃ¤ne']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.0745712009097019e-07\n",
      "-- Target Rank:  15613\n",
      "-- Target Entropy:  6.092094421386719\n",
      "--------------------------\n",
      "Target token: gehÃ¶ren\n",
      "token_idx: 2571\n",
      "maskP [5.142229611010407e-07]\n",
      "['gehÃ¶ren']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.142229611010407e-07\n",
      "-- Target Rank:  11044\n",
      "-- Target Entropy:  4.1739044189453125\n",
      "--------------------------\n",
      "Target token: in\n",
      "token_idx: 269\n",
      "maskP [6.223276614036877e-07]\n",
      "['in']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.223276614036877e-07\n",
      "-- Target Rank:  9324\n",
      "-- Target Entropy:  4.3775434494018555\n",
      "--------------------------\n",
      "Target token: die\n",
      "token_idx: 2327\n",
      "maskP [1.3347602362046018e-05]\n",
      "['die']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.3347602362046018e-05\n",
      "-- Target Rank:  2003\n",
      "-- Target Entropy:  3.917527198791504\n",
      "--------------------------\n",
      "Target token: KÃ¼che\n",
      "token_idx: 47\n",
      "maskP [2.3225118184200255e-06]\n",
      "['KÃ¼che']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.3225118184200255e-06\n",
      "-- Target Rank:  9231\n",
      "-- Target Entropy:  6.292064189910889\n",
      "--------------------------\n",
      "Target token: s\n",
      "token_idx: 87\n",
      "--------------------------\n",
      "Target token: oll\n",
      "token_idx: 701\n",
      "--------------------------\n",
      "Target token: ten\n",
      "token_idx: 310\n",
      "maskP [1.285101376424791e-07, 7.266753073054133e-06, 0.00012707275163847953]\n",
      "['s', 'oll', 'ten']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.482267161639205e-05\n",
      "-- Target Rank:  687\n",
      "-- Target Entropy:  5.979811668395996\n",
      "--------------------------\n",
      "Target token: ihre\n",
      "token_idx: 44188\n",
      "maskP [8.97347490536049e-07]\n",
      "['ihre']\n",
      "-- Target Probability (mean of probabilities in maskP):  8.97347490536049e-07\n",
      "-- Target Rank:  9271\n",
      "-- Target Entropy:  5.656896114349365\n",
      "--------------------------\n",
      "Target token: klass\n",
      "token_idx: 7342\n",
      "--------------------------\n",
      "Target token: ische\n",
      "token_idx: 523\n",
      "maskP [3.184386798693595e-08, 6.175173439260107e-08]\n",
      "['klass', 'ische']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.6797801189768506e-08\n",
      "-- Target Rank:  20340\n",
      "-- Target Entropy:  4.783398151397705\n",
      "--------------------------\n",
      "Target token: Gl\n",
      "token_idx: 7423\n",
      "--------------------------\n",
      "Target token: ucken\n",
      "token_idx: 29237\n",
      "--------------------------\n",
      "Target token: rolle\n",
      "token_idx: 5215\n",
      "maskP [3.627502564995666e-08, 8.077457813726596e-09, 8.962033781756418e-09]\n",
      "['Gl', 'ucken', 'rolle']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.7771505748479893e-08\n",
      "-- Target Rank:  22855\n",
      "-- Target Entropy:  6.290283203125\n",
      "--------------------------\n",
      "Target token: aus\n",
      "token_idx: 481\n",
      "--------------------------\n",
      "Target token: Ã¼ben\n",
      "token_idx: 3545\n",
      "maskP [1.9236445041315164e-06, 2.6579275669291746e-08]\n",
      "['aus', 'Ã¼ben']\n",
      "-- Target Probability (mean of probabilities in maskP):  9.75111889900404e-07\n",
      "-- Target Rank:  3744\n",
      "-- Target Entropy:  5.107473373413086\n",
      "--------------------------\n",
      "Target token: was\n",
      "token_idx: 2563\n",
      "maskP [3.91185749322176e-05]\n",
      "['was']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.91185749322176e-05\n",
      "-- Target Rank:  1391\n",
      "-- Target Entropy:  5.562985420227051\n",
      "--------------------------\n",
      "Target token: ein\n",
      "token_idx: 272\n",
      "maskP [6.299894153016794e-07]\n",
      "['ein']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.299894153016794e-07\n",
      "-- Target Rank:  14102\n",
      "-- Target Entropy:  4.9353742599487305\n",
      "--------------------------\n",
      "Target token: Film\n",
      "token_idx: 10939\n",
      "maskP [1.47993171140115e-06]\n",
      "['Film']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.47993171140115e-06\n",
      "-- Target Rank:  15348\n",
      "-- Target Entropy:  7.366436004638672\n",
      "--------------------------\n",
      "Target token: tun\n",
      "token_idx: 32349\n",
      "maskP [1.5558505765511654e-05]\n",
      "['tun']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.5558505765511654e-05\n",
      "-- Target Rank:  1171\n",
      "-- Target Entropy:  3.485114336013794\n",
      "--------------------------\n",
      "Target token: m\n",
      "token_idx: 81\n",
      "--------------------------\n",
      "Target token: uss\n",
      "token_idx: 592\n",
      "--------------------------\n",
      "Target token: ,\n",
      "token_idx: 16\n",
      "maskP [7.419032044708729e-05, 3.3410583455406595e-07, 0.016666974872350693]\n",
      "['m', 'uss', ',']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.005580499766210778\n",
      "-- Target Rank:  8\n",
      "-- Target Entropy:  2.5888876914978027\n",
      "--------------------------\n",
      "Target token: ist\n",
      "token_idx: 510\n",
      "maskP [5.588410931522958e-05]\n",
      "['ist']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.588410931522958e-05\n",
      "-- Target Rank:  312\n",
      "-- Target Entropy:  2.0964016914367676\n",
      "--------------------------\n",
      "Target token: seine\n",
      "token_idx: 50044\n",
      "maskP [2.9699083370360313e-07]\n",
      "['seine']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.9699083370360313e-07\n",
      "-- Target Rank:  15584\n",
      "-- Target Entropy:  5.380878448486328\n",
      "--------------------------\n",
      "Target token: Zu\n",
      "token_idx: 2416\n",
      "--------------------------\n",
      "Target token: schauer\n",
      "token_idx: 20994\n",
      "maskP [3.8280956005110056e-07, 2.0533645894715846e-09]\n",
      "['Zu', 'schauer']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.9243146232028607e-07\n",
      "-- Target Rank:  14992\n",
      "-- Target Entropy:  6.340991020202637\n",
      "--------------------------\n",
      "Target token: zu\n",
      "token_idx: 636\n",
      "maskP [7.72022976889275e-05]\n",
      "['zu']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.72022976889275e-05\n",
      "-- Target Rank:  630\n",
      "-- Target Entropy:  4.304470539093018\n",
      "--------------------------\n",
      "Target token: be\n",
      "token_idx: 518\n",
      "--------------------------\n",
      "Target token: fried\n",
      "token_idx: 5911\n",
      "--------------------------\n",
      "Target token: igen\n",
      "token_idx: 565\n",
      "maskP [5.50012628082186e-05, 2.1293025120883158e-09, 5.42051168395119e-07]\n",
      "['be', 'fried', 'igen']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.85151477597086e-05\n",
      "-- Target Rank:  764\n",
      "-- Target Entropy:  5.269656181335449\n",
      "--------------------------\n",
      "Target token: haben\n",
      "token_idx: 4199\n",
      "maskP [7.831689799786545e-06]\n",
      "['haben']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.831689799786545e-06\n",
      "-- Target Rank:  5047\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: einen\n",
      "token_idx: 946\n",
      "maskP [5.625740868708817e-06]\n",
      "['einen']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.625740868708817e-06\n",
      "-- Target Rank:  5263\n",
      "-- Target Entropy:  5.9237775802612305\n",
      "--------------------------\n",
      "Target token: sign\n",
      "token_idx: 29597\n",
      "--------------------------\n",
      "Target token: if\n",
      "token_idx: 1038\n",
      "--------------------------\n",
      "Target token: ikant\n",
      "token_idx: 31257\n",
      "maskP [4.024438737815217e-08, 6.941044716768374e-08, 3.6256195962147686e-11]\n",
      "['sign', 'if', 'ikant']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.6563696913932686e-08\n",
      "-- Target Rank:  25273\n",
      "-- Target Entropy:  6.984785556793213\n",
      "--------------------------\n",
      "Target token: hÃ¶\n",
      "token_idx: 76\n",
      "--------------------------\n",
      "Target token: re\n",
      "token_idx: 359\n",
      "maskP [1.660000776837478e-07, 3.290593610927317e-07]\n",
      "['hÃ¶', 're']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.4752971938823976e-07\n",
      "-- Target Rank:  4973\n",
      "-- Target Entropy:  2.3598084449768066\n",
      "--------------------------\n",
      "Target token: Sch\n",
      "token_idx: 896\n",
      "--------------------------\n",
      "Target token: mer\n",
      "token_idx: 505\n",
      "--------------------------\n",
      "Target token: zt\n",
      "token_idx: 1131\n",
      "--------------------------\n",
      "Target token: oleranz\n",
      "token_idx: 18979\n",
      "maskP [2.229086385341361e-05, 4.0273062040796503e-07, 7.280390263986192e-07, 6.198617938935058e-07]\n",
      "['Sch', 'mer', 'zt', 'oleranz']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.010373823528425e-06\n",
      "-- Target Rank:  2615\n",
      "-- Target Entropy:  5.790609836578369\n",
      "maskP []\n",
      "WARNING: maskp is empty list 6.198617938935058e-07\n",
      "[]\n",
      "-- Target Probability (mean of probabilities in maskP):  warning\n",
      "-- Target Rank:  50265\n",
      "-- Target Entropy:  0.0\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [1.4102917702984996e-05]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.4102917702984996e-05\n",
      "-- Target Rank:  3473\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: psych\n",
      "token_idx: 19240\n",
      "--------------------------\n",
      "Target token: isch\n",
      "token_idx: 347\n",
      "maskP [2.215017502749106e-07, 1.2936357052240055e-07]\n",
      "['psych', 'isch']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.7543266039865557e-07\n",
      "-- Target Rank:  19598\n",
      "-- Target Entropy:  5.974837303161621\n",
      "--------------------------\n",
      "Target token: fÃ¼r\n",
      "token_idx: 74\n",
      "maskP [5.843085570944595e-09]\n",
      "['fÃ¼r']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.843085570944595e-09\n",
      "-- Target Rank:  12519\n",
      "-- Target Entropy:  4.189533233642578\n",
      "--------------------------\n",
      "Target token: komplex\n",
      "token_idx: 16054\n",
      "--------------------------\n",
      "Target token: e\n",
      "token_idx: 73\n",
      "maskP [1.019890873976692e-06, 1.2306133612582926e-05]\n",
      "['komplex', 'e']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.663012243279809e-06\n",
      "-- Target Rank:  3277\n",
      "-- Target Entropy:  5.038015842437744\n",
      "--------------------------\n",
      "Target token: Arbeit\n",
      "token_idx: 13936\n",
      "maskP [6.906867383804638e-06]\n",
      "['Arbeit']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.906867383804638e-06\n",
      "-- Target Rank:  3621\n",
      "-- Target Entropy:  5.5151214599609375\n",
      "--------------------------\n",
      "Target token: gesch\n",
      "token_idx: 877\n",
      "--------------------------\n",
      "Target token: affen\n",
      "token_idx: 1864\n",
      "maskP [3.858624950225931e-06, 2.6110132722578783e-08]\n",
      "['gesch', 'affen']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.9423675414742547e-06\n",
      "-- Target Rank:  2447\n",
      "-- Target Entropy:  4.770198822021484\n",
      "--------------------------\n",
      "Target token: haben\n",
      "token_idx: 4199\n",
      "maskP [7.831689799786545e-06]\n",
      "['haben']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.831689799786545e-06\n",
      "-- Target Rank:  5047\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: im\n",
      "token_idx: 487\n",
      "maskP [2.638220621520304e-06]\n",
      "['im']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.638220621520304e-06\n",
      "-- Target Rank:  8218\n",
      "-- Target Entropy:  5.9237775802612305\n",
      "--------------------------\n",
      "Target token: stat\n",
      "token_idx: 2641\n",
      "--------------------------\n",
      "Target token: istischen\n",
      "token_idx: 2894\n",
      "maskP [7.190244843968685e-08, 4.743240467064425e-09]\n",
      "['stat', 'istischen']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.832284445337564e-08\n",
      "-- Target Rank:  18397\n",
      "-- Target Entropy:  4.608479976654053\n",
      "--------------------------\n",
      "Target token: Mittel\n",
      "token_idx: 10393\n",
      "maskP [9.931424074238748e-07]\n",
      "['Mittel']\n",
      "-- Target Probability (mean of probabilities in maskP):  9.931424074238748e-07\n",
      "-- Target Rank:  4017\n",
      "-- Target Entropy:  3.5405046939849854\n",
      "--------------------------\n",
      "Target token: in\n",
      "token_idx: 269\n",
      "maskP [7.759033178444952e-05]\n",
      "['in']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.759033178444952e-05\n",
      "-- Target Rank:  773\n",
      "-- Target Entropy:  5.734947204589844\n",
      "--------------------------\n",
      "Target token: einen\n",
      "token_idx: 946\n",
      "maskP [2.9336063107621158e-06]\n",
      "['einen']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.9336063107621158e-06\n",
      "-- Target Rank:  3873\n",
      "-- Target Entropy:  3.9385721683502197\n",
      "--------------------------\n",
      "Target token: grÃ¶ÃŁ\n",
      "token_idx: 667\n",
      "--------------------------\n",
      "Target token: eren\n",
      "token_idx: 1073\n",
      "maskP [4.5975025386724155e-07, 2.2044441720936447e-05]\n",
      "['grÃ¶ÃŁ', 'eren']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.1252095987401844e-05\n",
      "-- Target Rank:  3500\n",
      "-- Target Entropy:  6.973424911499023\n",
      "--------------------------\n",
      "Target token: Wort\n",
      "token_idx: 38161\n",
      "--------------------------\n",
      "Target token: schatz\n",
      "token_idx: 23119\n",
      "maskP [2.3785553082689148e-08, 3.652020552635804e-08]\n",
      "['Wort', 'schatz']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.0152879304523594e-08\n",
      "-- Target Rank:  20370\n",
      "-- Target Entropy:  4.704582691192627\n",
      "--------------------------\n",
      "Target token: hat\n",
      "token_idx: 8491\n",
      "maskP [1.822675585572142e-05]\n",
      "['hat']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.822675585572142e-05\n",
      "-- Target Rank:  2080\n",
      "-- Target Entropy:  4.973829746246338\n",
      "--------------------------\n",
      "Target token: fast\n",
      "token_idx: 5280\n",
      "maskP [1.6411373593427925e-08]\n",
      "['fast']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.6411373593427925e-08\n",
      "-- Target Rank:  30137\n",
      "-- Target Entropy:  4.812148571014404\n",
      "--------------------------\n",
      "Target token: nur\n",
      "token_idx: 12317\n",
      "maskP [2.7534313176147407e-06]\n",
      "['nur']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.7534313176147407e-06\n",
      "-- Target Rank:  2681\n",
      "-- Target Entropy:  4.575490474700928\n",
      "--------------------------\n",
      "Target token: Vort\n",
      "token_idx: 29101\n",
      "--------------------------\n",
      "Target token: eile\n",
      "token_idx: 1827\n",
      "maskP [4.3097324464724807e-07, 3.2986904319187715e-09]\n",
      "['Vort', 'eile']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.1713596753958342e-07\n",
      "-- Target Rank:  12051\n",
      "-- Target Entropy:  4.362985610961914\n",
      "--------------------------\n",
      "Target token: fÃ¼r\n",
      "token_idx: 74\n",
      "maskP [7.007906219769211e-07]\n",
      "['fÃ¼r']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.007906219769211e-07\n",
      "-- Target Rank:  2474\n",
      "-- Target Entropy:  2.474022388458252\n",
      "--------------------------\n",
      "Target token: die\n",
      "token_idx: 2327\n",
      "maskP [3.45160806318745e-05]\n",
      "['die']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.45160806318745e-05\n",
      "-- Target Rank:  759\n",
      "-- Target Entropy:  2.932575225830078\n",
      "--------------------------\n",
      "Target token: Gesellschaft\n",
      "token_idx: 14026\n",
      "maskP [1.4266386187955504e-06]\n",
      "['Gesellschaft']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.4266386187955504e-06\n",
      "-- Target Rank:  8171\n",
      "-- Target Entropy:  5.029886722564697\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [1.4102917702984996e-05]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.4102917702984996e-05\n",
      "-- Target Rank:  3473\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: im\n",
      "token_idx: 487\n",
      "maskP [2.7128726287628524e-06]\n",
      "['im']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.7128726287628524e-06\n",
      "-- Target Rank:  7144\n",
      "-- Target Entropy:  5.974837303161621\n",
      "--------------------------\n",
      "Target token: Durchschnitt\n",
      "token_idx: 23778\n",
      "maskP [6.874789164612594e-07]\n",
      "['Durchschnitt']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.874789164612594e-07\n",
      "-- Target Rank:  12402\n",
      "-- Target Entropy:  5.6138529777526855\n",
      "--------------------------\n",
      "Target token: sozial\n",
      "token_idx: 6728\n",
      "--------------------------\n",
      "Target token: er\n",
      "token_idx: 261\n",
      "maskP [9.297061296820175e-06, 1.2140185390308034e-05]\n",
      "['sozial', 'er']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.0718623343564104e-05\n",
      "-- Target Rank:  1673\n",
      "-- Target Entropy:  5.349737644195557\n",
      "--------------------------\n",
      "Target token: als\n",
      "token_idx: 1239\n",
      "maskP [5.914442226639949e-06]\n",
      "['als']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.914442226639949e-06\n",
      "-- Target Rank:  2437\n",
      "-- Target Entropy:  3.779818058013916\n",
      "--------------------------\n",
      "Target token: MÃ¤nner\n",
      "token_idx: 49\n",
      "maskP [1.1958778713960783e-06]\n",
      "['MÃ¤nner']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.1958778713960783e-06\n",
      "-- Target Rank:  3839\n",
      "-- Target Entropy:  3.183478832244873\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [1.4102917702984996e-05]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.4102917702984996e-05\n",
      "-- Target Rank:  3473\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: M\n",
      "token_idx: 49\n",
      "--------------------------\n",
      "Target token: Ã¤n\n",
      "token_idx: 3545\n",
      "--------------------------\n",
      "Target token: nern\n",
      "token_idx: 4279\n",
      "maskP [2.7607288757280912e-06, 5.919378622820659e-07, 1.6587744511298297e-08]\n",
      "['M', 'Ã¤n', 'nern']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.1230848275071519e-06\n",
      "-- Target Rank:  7091\n",
      "-- Target Entropy:  5.974837303161621\n",
      "--------------------------\n",
      "Target token: im\n",
      "token_idx: 487\n",
      "maskP [4.340690793469548e-06]\n",
      "['im']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.340690793469548e-06\n",
      "-- Target Rank:  3285\n",
      "-- Target Entropy:  5.306904315948486\n",
      "--------------------------\n",
      "Target token: Erinner\n",
      "token_idx: 23123\n",
      "--------------------------\n",
      "Target token: ungsver\n",
      "token_idx: 10975\n",
      "--------------------------\n",
      "Target token: mÃ¶gen\n",
      "token_idx: 81\n",
      "maskP [4.1830299640777113e-11, 5.557272743317299e-06, 6.469213076343294e-06]\n",
      "['Erinner', 'ungsver', 'mÃ¶gen']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.008842549986745e-06\n",
      "-- Target Rank:  2956\n",
      "-- Target Entropy:  4.421422004699707\n",
      "--------------------------\n",
      "Target token: Ã¼ber\n",
      "token_idx: 3545\n",
      "--------------------------\n",
      "Target token: legen\n",
      "token_idx: 1514\n",
      "maskP [1.3016152422551386e-07, 2.2733284144038635e-09]\n",
      "['Ã¼ber', 'legen']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.621742631995886e-08\n",
      "-- Target Rank:  11860\n",
      "-- Target Entropy:  5.12861442565918\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [1.4102917702984996e-05]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.4102917702984996e-05\n",
      "-- Target Rank:  3473\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: S\n",
      "token_idx: 55\n",
      "--------------------------\n",
      "Target token: Ã¤ulen\n",
      "token_idx: 3545\n",
      "maskP [4.53017293011726e-07, 5.919378622820659e-07]\n",
      "['S', 'Ã¤ulen']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.22477577646896e-07\n",
      "-- Target Rank:  14107\n",
      "-- Target Entropy:  5.974837303161621\n",
      "--------------------------\n",
      "Target token: in\n",
      "token_idx: 269\n",
      "maskP [8.917517334339209e-06]\n",
      "['in']\n",
      "-- Target Probability (mean of probabilities in maskP):  8.917517334339209e-06\n",
      "-- Target Rank:  1176\n",
      "-- Target Entropy:  3.11257004737854\n",
      "--------------------------\n",
      "Target token: unser\n",
      "token_idx: 42614\n",
      "--------------------------\n",
      "Target token: er\n",
      "token_idx: 261\n",
      "maskP [7.539430043834727e-06, 2.9090480779814243e-07]\n",
      "['unser', 'er']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.915167425816435e-06\n",
      "-- Target Rank:  3228\n",
      "-- Target Entropy:  3.6828272342681885\n",
      "--------------------------\n",
      "Target token: Gesellschaft\n",
      "token_idx: 14026\n",
      "maskP [2.3859030989115126e-05]\n",
      "['Gesellschaft']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.3859030989115126e-05\n",
      "-- Target Rank:  1120\n",
      "-- Target Entropy:  3.0337631702423096\n",
      "--------------------------\n",
      "Target token: kÃ¶nnen\n",
      "token_idx: 79\n",
      "maskP [0.0002068869798677042]\n",
      "['kÃ¶nnen']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0002068869798677042\n",
      "-- Target Rank:  424\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: alles\n",
      "token_idx: 31486\n",
      "maskP [2.8435428589546063e-07]\n",
      "['alles']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.8435428589546063e-07\n",
      "-- Target Rank:  20936\n",
      "-- Target Entropy:  5.745215892791748\n",
      "--------------------------\n",
      "Target token: und\n",
      "token_idx: 283\n",
      "maskP [1.0075007139676018e-07]\n",
      "['und']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.0075007139676018e-07\n",
      "-- Target Rank:  10846\n",
      "-- Target Entropy:  4.829560279846191\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [7.241234243338113e-07]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.241234243338113e-07\n",
      "-- Target Rank:  9362\n",
      "-- Target Entropy:  4.771591663360596\n",
      "--------------------------\n",
      "Target token: sehr\n",
      "token_idx: 12626\n",
      "maskP [4.7668154365965165e-06]\n",
      "['sehr']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.7668154365965165e-06\n",
      "-- Target Rank:  3648\n",
      "-- Target Entropy:  5.73152494430542\n",
      "--------------------------\n",
      "Target token: kre\n",
      "token_idx: 13627\n",
      "--------------------------\n",
      "Target token: ativ\n",
      "token_idx: 1655\n",
      "maskP [2.571487982550025e-07, 3.690684202695138e-09]\n",
      "['kre', 'ativ']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.304197412288488e-07\n",
      "-- Target Rank:  7654\n",
      "-- Target Entropy:  5.578278064727783\n",
      "--------------------------\n",
      "Target token: schaffen\n",
      "token_idx: 7603\n",
      "maskP [2.1555795683525503e-05]\n",
      "['schaffen']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.1555795683525503e-05\n",
      "-- Target Rank:  2554\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: oft\n",
      "token_idx: 24700\n",
      "maskP [6.710201461146426e-08]\n",
      "['oft']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.710201461146426e-08\n",
      "-- Target Rank:  27137\n",
      "-- Target Entropy:  4.954009532928467\n",
      "--------------------------\n",
      "Target token: den\n",
      "token_idx: 324\n",
      "maskP [2.2611242457060143e-05]\n",
      "['den']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.2611242457060143e-05\n",
      "-- Target Rank:  2280\n",
      "-- Target Entropy:  5.752803325653076\n",
      "--------------------------\n",
      "Target token: grÃ¶ÃŁten\n",
      "token_idx: 667\n",
      "maskP [1.8242786836708547e-08]\n",
      "['grÃ¶ÃŁten']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.8242786836708547e-08\n",
      "-- Target Rank:  23931\n",
      "-- Target Entropy:  5.451928615570068\n",
      "--------------------------\n",
      "Target token: Sp\n",
      "token_idx: 1571\n",
      "--------------------------\n",
      "Target token: aÃŁ\n",
      "token_idx: 69\n",
      "maskP [7.290769303835987e-07, 2.3501673496184594e-08]\n",
      "['Sp', 'aÃŁ']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.7628930193989163e-07\n",
      "-- Target Rank:  8112\n",
      "-- Target Entropy:  5.539865016937256\n",
      "--------------------------\n",
      "Target token: #\n",
      "token_idx: 7\n",
      "--------------------------\n",
      "Target token: met\n",
      "token_idx: 3183\n",
      "--------------------------\n",
      "Target token: oo\n",
      "token_idx: 5498\n",
      "--------------------------\n",
      "Target token: -\n",
      "token_idx: 17\n",
      "--------------------------\n",
      "Target token: Bewegung\n",
      "token_idx: 17576\n",
      "maskP [5.527759867618443e-07, 1.1221724207644002e-06, 1.6434421468147775e-07, 8.271169645013288e-05, 2.2373737351699674e-07]\n",
      "['#', 'met', 'oo', '-', 'Bewegung']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.6954945289171518e-05\n",
      "-- Target Rank:  2316\n",
      "-- Target Entropy:  8.566091537475586\n",
      "--------------------------\n",
      "Target token: ist\n",
      "token_idx: 510\n",
      "maskP [4.15797985624522e-05]\n",
      "['ist']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.15797985624522e-05\n",
      "-- Target Rank:  1014\n",
      "-- Target Entropy:  4.825689792633057\n",
      "--------------------------\n",
      "Target token: wirk\n",
      "token_idx: 2895\n",
      "--------------------------\n",
      "Target token: mÃ¤chtig\n",
      "token_idx: 81\n",
      "maskP [1.8928001566109742e-07, 6.123473781372013e-07]\n",
      "['wirk', 'mÃ¤chtig']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.0081369689914936e-07\n",
      "-- Target Rank:  7705\n",
      "-- Target Entropy:  4.882268905639648\n",
      "--------------------------\n",
      "Target token: s\n",
      "token_idx: 87\n",
      "--------------------------\n",
      "Target token: oll\n",
      "token_idx: 701\n",
      "--------------------------\n",
      "Target token: ten\n",
      "token_idx: 310\n",
      "maskP [5.3167033911449835e-05, 1.0145470952238611e-07, 3.8750324165448546e-05]\n",
      "['s', 'oll', 'ten']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.067293759547359e-05\n",
      "-- Target Rank:  1307\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: nicht\n",
      "token_idx: 7272\n",
      "maskP [4.026684837299399e-05]\n",
      "['nicht']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.026684837299399e-05\n",
      "-- Target Rank:  1445\n",
      "-- Target Entropy:  5.844089031219482\n",
      "--------------------------\n",
      "Target token: zu\n",
      "token_idx: 636\n",
      "maskP [1.3740539543505292e-05]\n",
      "['zu']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.3740539543505292e-05\n",
      "-- Target Rank:  2685\n",
      "-- Target Entropy:  5.546171188354492\n",
      "--------------------------\n",
      "Target token: H\n",
      "token_idx: 44\n",
      "--------------------------\n",
      "Target token: ause\n",
      "token_idx: 5071\n",
      "maskP [9.622851393942256e-06, 6.4541363364867266e-09]\n",
      "['H', 'ause']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.814652765139371e-06\n",
      "-- Target Rank:  4071\n",
      "-- Target Entropy:  5.778377056121826\n",
      "--------------------------\n",
      "Target token: bleiben\n",
      "token_idx: 9343\n",
      "maskP [0.0030260873027145863]\n",
      "['bleiben']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0030260873027145863\n",
      "-- Target Rank:  31\n",
      "-- Target Entropy:  3.425262928009033\n",
      "--------------------------\n",
      "Target token: und\n",
      "token_idx: 283\n",
      "maskP [2.4453333026031032e-05]\n",
      "['und']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.4453333026031032e-05\n",
      "-- Target Rank:  216\n",
      "-- Target Entropy:  2.219727039337158\n",
      "--------------------------\n",
      "Target token: sich\n",
      "token_idx: 12592\n",
      "maskP [1.0769183973025065e-05]\n",
      "['sich']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.0769183973025065e-05\n",
      "-- Target Rank:  3212\n",
      "-- Target Entropy:  5.5299906730651855\n",
      "--------------------------\n",
      "Target token: um\n",
      "token_idx: 335\n",
      "maskP [2.4229368591477396e-06]\n",
      "['um']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.4229368591477396e-06\n",
      "-- Target Rank:  4788\n",
      "-- Target Entropy:  5.4484782218933105\n",
      "--------------------------\n",
      "Target token: ihre\n",
      "token_idx: 44188\n",
      "maskP [0.00014160673890728503]\n",
      "['ihre']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.00014160673890728503\n",
      "-- Target Rank:  283\n",
      "-- Target Entropy:  4.257272243499756\n",
      "--------------------------\n",
      "Target token: Karriere\n",
      "token_idx: 36797\n",
      "maskP [7.188889128428855e-08]\n",
      "['Karriere']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.188889128428855e-08\n",
      "-- Target Rank:  18107\n",
      "-- Target Entropy:  3.878344774246216\n",
      "--------------------------\n",
      "Target token: k\n",
      "token_idx: 79\n",
      "--------------------------\n",
      "Target token: Ã¼mmern\n",
      "token_idx: 3545\n",
      "maskP [1.566850369272288e-05, 7.346081787318326e-08]\n",
      "['k', 'Ã¼mmern']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.870982255298031e-06\n",
      "-- Target Rank:  470\n",
      "-- Target Entropy:  2.3494699001312256\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [8.489974788972177e-06]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  8.489974788972177e-06\n",
      "-- Target Rank:  3917\n",
      "-- Target Entropy:  5.148418426513672\n",
      "--------------------------\n",
      "Target token: Ã¼ber\n",
      "token_idx: 3545\n",
      "--------------------------\n",
      "Target token: wiegend\n",
      "token_idx: 5406\n",
      "maskP [1.8144466196190479e-07, 2.7343216402186954e-07]\n",
      "['Ã¼ber', 'wiegend']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.2743841299188716e-07\n",
      "-- Target Rank:  17529\n",
      "-- Target Entropy:  5.996739387512207\n",
      "--------------------------\n",
      "Target token: ange\n",
      "token_idx: 1209\n",
      "--------------------------\n",
      "Target token: trieben\n",
      "token_idx: 14671\n",
      "maskP [7.617370556545211e-08, 8.641156679090045e-10]\n",
      "['ange', 'trieben']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.851891061668056e-08\n",
      "-- Target Rank:  21439\n",
      "-- Target Entropy:  5.436563968658447\n",
      "--------------------------\n",
      "Target token: durch\n",
      "token_idx: 4148\n",
      "maskP [2.1080033548059873e-05]\n",
      "['durch']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.1080033548059873e-05\n",
      "-- Target Rank:  86\n",
      "-- Target Entropy:  1.1199722290039062\n",
      "--------------------------\n",
      "Target token: Ger\n",
      "token_idx: 4144\n",
      "--------------------------\n",
      "Target token: ech\n",
      "token_idx: 556\n",
      "--------------------------\n",
      "Target token: tigkeits\n",
      "token_idx: 20011\n",
      "--------------------------\n",
      "Target token: wÃ¼nsche\n",
      "token_idx: 91\n",
      "maskP [1.3124600961589294e-08, 3.6699496774872387e-08, 1.1868713789553453e-09, 1.1471361176518258e-06]\n",
      "['Ger', 'ech', 'tigkeits', 'wÃ¼nsche']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.995367716918107e-07\n",
      "-- Target Rank:  10517\n",
      "-- Target Entropy:  4.542285919189453\n",
      "maskP []\n",
      "WARNING: maskp is empty list 1.1471361176518258e-06\n",
      "[]\n",
      "-- Target Probability (mean of probabilities in maskP):  warning\n",
      "-- Target Rank:  50265\n",
      "-- Target Entropy:  0.0\n",
      "--------------------------\n",
      "Target token: altern\n",
      "token_idx: 26758\n",
      "maskP [2.041726787638254e-10]\n",
      "['altern']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.041726787638254e-10\n",
      "-- Target Rank:  14378\n",
      "-- Target Entropy:  1.8776817321777344\n",
      "--------------------------\n",
      "Target token: wie\n",
      "token_idx: 687\n",
      "maskP [2.6179970973316813e-06]\n",
      "['wie']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.6179970973316813e-06\n",
      "-- Target Rank:  2957\n",
      "-- Target Entropy:  3.2266733646392822\n",
      "--------------------------\n",
      "Target token: Milch\n",
      "token_idx: 37619\n",
      "--------------------------\n",
      "Target token: ,\n",
      "token_idx: 16\n",
      "maskP [6.615358927319903e-08, 4.06066574214492e-05]\n",
      "['Milch', ',']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.03364055053612e-05\n",
      "-- Target Rank:  1479\n",
      "-- Target Entropy:  5.496448516845703\n",
      "--------------------------\n",
      "Target token: Frauen\n",
      "token_idx: 11678\n",
      "maskP [2.1112701631409436e-07]\n",
      "['Frauen']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.1112701631409436e-07\n",
      "-- Target Rank:  23180\n",
      "-- Target Entropy:  6.587625980377197\n",
      "--------------------------\n",
      "Target token: altern\n",
      "token_idx: 26758\n",
      "maskP [2.368637069594115e-05]\n",
      "['altern']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.368637069594115e-05\n",
      "-- Target Rank:  2022\n",
      "-- Target Entropy:  5.857842445373535\n",
      "--------------------------\n",
      "Target token: wie\n",
      "token_idx: 687\n",
      "maskP [0.0002461853146087378]\n",
      "['wie']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0002461853146087378\n",
      "-- Target Rank:  127\n",
      "-- Target Entropy:  2.4546148777008057\n",
      "--------------------------\n",
      "Target token: Wein\n",
      "token_idx: 22425\n",
      "maskP [6.765327725588577e-06]\n",
      "['Wein']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.765327725588577e-06\n",
      "-- Target Rank:  3702\n",
      "-- Target Entropy:  5.780807971954346\n",
      "--------------------------\n",
      "Target token: moderne\n",
      "token_idx: 48147\n",
      "maskP [1.0851469767203525e-07]\n",
      "['moderne']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.0851469767203525e-07\n",
      "-- Target Rank:  31625\n",
      "-- Target Entropy:  8.063133239746094\n",
      "--------------------------\n",
      "Target token: R\n",
      "token_idx: 54\n",
      "--------------------------\n",
      "Target token: ollen\n",
      "token_idx: 6010\n",
      "--------------------------\n",
      "Target token: verteilung\n",
      "token_idx: 14709\n",
      "maskP [2.5004599137901096e-06, 1.9882374857616014e-08, 1.0540580319684523e-07]\n",
      "['R', 'ollen', 'verteilung']\n",
      "-- Target Probability (mean of probabilities in maskP):  8.752493639481903e-07\n",
      "-- Target Rank:  11761\n",
      "-- Target Entropy:  6.932570457458496\n",
      "--------------------------\n",
      "Target token: in\n",
      "token_idx: 269\n",
      "maskP [1.6720990743124275e-06]\n",
      "['in']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.6720990743124275e-06\n",
      "-- Target Rank:  3896\n",
      "-- Target Entropy:  4.51539421081543\n",
      "--------------------------\n",
      "Target token: der\n",
      "token_idx: 320\n",
      "maskP [3.688284050440416e-05]\n",
      "['der']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.688284050440416e-05\n",
      "-- Target Rank:  1007\n",
      "-- Target Entropy:  3.252065896987915\n",
      "--------------------------\n",
      "Target token: Ehe\n",
      "token_idx: 33545\n",
      "maskP [2.5369129019736647e-08]\n",
      "['Ehe']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.5369129019736647e-08\n",
      "-- Target Rank:  27323\n",
      "-- Target Entropy:  7.033496379852295\n",
      "--------------------------\n",
      "Target token: ist\n",
      "token_idx: 510\n",
      "maskP [1.6668782336637378e-06]\n",
      "['ist']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.6668782336637378e-06\n",
      "-- Target Rank:  4182\n",
      "-- Target Entropy:  4.609010219573975\n",
      "--------------------------\n",
      "Target token: zu\n",
      "token_idx: 636\n",
      "maskP [3.708400413415802e-07]\n",
      "['zu']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.708400413415802e-07\n",
      "-- Target Rank:  9505\n",
      "-- Target Entropy:  5.382641792297363\n",
      "--------------------------\n",
      "Target token: be\n",
      "token_idx: 518\n",
      "--------------------------\n",
      "Target token: vor\n",
      "token_idx: 805\n",
      "--------------------------\n",
      "Target token: zu\n",
      "token_idx: 636\n",
      "--------------------------\n",
      "Target token: gen\n",
      "token_idx: 312\n",
      "maskP [1.743600114423316e-05, 5.118295575812226e-06, 4.420096956891939e-06, 5.229710950516164e-05]\n",
      "['be', 'vor', 'zu', 'gen']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.9817875795524742e-05\n",
      "-- Target Rank:  700\n",
      "-- Target Entropy:  4.7177414894104\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [1.4102917702984996e-05]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.4102917702984996e-05\n",
      "-- Target Rank:  3473\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: fÃ¼r\n",
      "token_idx: 74\n",
      "maskP [4.3660270421241876e-06]\n",
      "['fÃ¼r']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.3660270421241876e-06\n",
      "-- Target Rank:  5568\n",
      "-- Target Entropy:  5.974837303161621\n",
      "--------------------------\n",
      "Target token: alle\n",
      "token_idx: 2390\n",
      "maskP [7.368565547949402e-06]\n",
      "['alle']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.368565547949402e-06\n",
      "-- Target Rank:  5387\n",
      "-- Target Entropy:  5.436031341552734\n",
      "--------------------------\n",
      "Target token: Ber\n",
      "token_idx: 2165\n",
      "--------------------------\n",
      "Target token: ufe\n",
      "token_idx: 2761\n",
      "maskP [4.6443069834367634e-08, 7.406987378999474e-08]\n",
      "['Ber', 'ufe']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.025647181218119e-08\n",
      "-- Target Rank:  24085\n",
      "-- Target Entropy:  5.88626766204834\n",
      "--------------------------\n",
      "Target token: gut\n",
      "token_idx: 4663\n",
      "maskP [1.9892745228844433e-07]\n",
      "['gut']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.9892745228844433e-07\n",
      "-- Target Rank:  13142\n",
      "-- Target Entropy:  4.723236560821533\n",
      "--------------------------\n",
      "Target token: ge\n",
      "token_idx: 281\n",
      "--------------------------\n",
      "Target token: eignet\n",
      "token_idx: 10106\n",
      "maskP [7.736186489637475e-06, 1.8976265891978983e-08]\n",
      "['ge', 'eignet']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.877581377764727e-06\n",
      "-- Target Rank:  699\n",
      "-- Target Entropy:  2.8702266216278076\n",
      "--------------------------\n",
      "Target token: der\n",
      "token_idx: 320\n",
      "maskP [0.0015312677714973688]\n",
      "['der']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0015312677714973688\n",
      "-- Target Rank:  50\n",
      "-- Target Entropy:  4.115504264831543\n",
      "--------------------------\n",
      "Target token: Gesch\n",
      "token_idx: 5328\n",
      "--------------------------\n",
      "Target token: lechter\n",
      "token_idx: 14704\n",
      "maskP [3.2358866519643925e-06, 1.8303659032881114e-08]\n",
      "['Gesch', 'lechter']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.6270951554986368e-06\n",
      "-- Target Rank:  880\n",
      "-- Target Entropy:  0.8480423092842102\n",
      "--------------------------\n",
      "Target token: ist\n",
      "token_idx: 510\n",
      "maskP [1.218593206431251e-05]\n",
      "['ist']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.218593206431251e-05\n",
      "-- Target Rank:  2258\n",
      "-- Target Entropy:  4.2744460105896\n",
      "--------------------------\n",
      "Target token: ein\n",
      "token_idx: 272\n",
      "maskP [0.0005760818021371961]\n",
      "['ein']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0005760818021371961\n",
      "-- Target Rank:  155\n",
      "-- Target Entropy:  4.674030303955078\n",
      "--------------------------\n",
      "Target token: Traum\n",
      "token_idx: 36011\n",
      "maskP [8.88833042722581e-08]\n",
      "['Traum']\n",
      "-- Target Probability (mean of probabilities in maskP):  8.88833042722581e-08\n",
      "-- Target Rank:  18039\n",
      "-- Target Entropy:  5.827844619750977\n",
      "--------------------------\n",
      "Target token: der\n",
      "token_idx: 320\n",
      "maskP [2.6969701139023528e-05]\n",
      "['der']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.6969701139023528e-05\n",
      "-- Target Rank:  377\n",
      "-- Target Entropy:  2.9689009189605713\n",
      "--------------------------\n",
      "Target token: Gesellschaft\n",
      "token_idx: 14026\n",
      "maskP [2.2957212308938324e-07]\n",
      "['Gesellschaft']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.2957212308938324e-07\n",
      "-- Target Rank:  16106\n",
      "-- Target Entropy:  5.784955978393555\n",
      "--------------------------\n",
      "Target token: in\n",
      "token_idx: 269\n",
      "maskP [0.0012834107037633657]\n",
      "['in']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0012834107037633657\n",
      "-- Target Rank:  91\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: fÃ¼hrenden\n",
      "token_idx: 74\n",
      "maskP [3.878858115058392e-05]\n",
      "['fÃ¼hrenden']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.878858115058392e-05\n",
      "-- Target Rank:  1843\n",
      "-- Target Entropy:  5.600177764892578\n",
      "--------------------------\n",
      "Target token: Position\n",
      "token_idx: 23786\n",
      "--------------------------\n",
      "Target token: en\n",
      "token_idx: 262\n",
      "maskP [6.303784903138876e-05, 8.726859164198686e-07]\n",
      "['Position', 'en']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.1955267473904314e-05\n",
      "-- Target Rank:  239\n",
      "-- Target Entropy:  1.461358904838562\n",
      "--------------------------\n",
      "Target token: haben\n",
      "token_idx: 4199\n",
      "maskP [1.4797471521887928e-05]\n",
      "['haben']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.4797471521887928e-05\n",
      "-- Target Rank:  2326\n",
      "-- Target Entropy:  4.686800956726074\n",
      "--------------------------\n",
      "Target token: hÃ¤\n",
      "token_idx: 76\n",
      "--------------------------\n",
      "Target token: ufig\n",
      "token_idx: 3021\n",
      "maskP [4.965125845046714e-05, 8.979489152238784e-09]\n",
      "['hÃ¤', 'ufig']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.483011896980969e-05\n",
      "-- Target Rank:  1049\n",
      "-- Target Entropy:  5.498671531677246\n",
      "--------------------------\n",
      "Target token: starke\n",
      "token_idx: 31562\n",
      "maskP [4.814769454242196e-06]\n",
      "['starke']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.814769454242196e-06\n",
      "-- Target Rank:  6178\n",
      "-- Target Entropy:  5.878767967224121\n",
      "--------------------------\n",
      "Target token: PersÃ¶n\n",
      "token_idx: 48263\n",
      "--------------------------\n",
      "Target token: lichkeiten\n",
      "token_idx: 5936\n",
      "maskP [2.3968602103074943e-10, 1.4401310144407375e-09]\n",
      "['PersÃ¶n', 'lichkeiten']\n",
      "-- Target Probability (mean of probabilities in maskP):  8.399085177357435e-10\n",
      "-- Target Rank:  34666\n",
      "-- Target Entropy:  5.853662490844727\n",
      "--------------------------\n",
      "Target token: gehÃ¶ren\n",
      "token_idx: 2571\n",
      "maskP [0.00010706575267249718]\n",
      "['gehÃ¶ren']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.00010706575267249718\n",
      "-- Target Rank:  740\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: in\n",
      "token_idx: 269\n",
      "maskP [3.716025730682304e-06]\n",
      "['in']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.716025730682304e-06\n",
      "-- Target Rank:  3361\n",
      "-- Target Entropy:  4.247570991516113\n",
      "--------------------------\n",
      "Target token: die\n",
      "token_idx: 2327\n",
      "maskP [5.496704034158029e-05]\n",
      "['die']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.496704034158029e-05\n",
      "-- Target Rank:  670\n",
      "-- Target Entropy:  4.332465171813965\n",
      "--------------------------\n",
      "Target token: Regierung\n",
      "token_idx: 15827\n",
      "maskP [4.150935950519852e-08]\n",
      "['Regierung']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.150935950519852e-08\n",
      "-- Target Rank:  28319\n",
      "-- Target Entropy:  7.050624370574951\n",
      "--------------------------\n",
      "Target token: s\n",
      "token_idx: 87\n",
      "--------------------------\n",
      "Target token: oll\n",
      "token_idx: 701\n",
      "--------------------------\n",
      "Target token: ten\n",
      "token_idx: 310\n",
      "maskP [5.3167033911449835e-05, 1.0145470952238611e-07, 3.8750324165448546e-05]\n",
      "['s', 'oll', 'ten']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.067293759547359e-05\n",
      "-- Target Rank:  1307\n",
      "-- Target Entropy:  5.7409138679504395\n",
      "--------------------------\n",
      "Target token: i\n",
      "token_idx: 77\n",
      "--------------------------\n",
      "Target token: hren\n",
      "token_idx: 3031\n",
      "maskP [6.680028263872373e-07, 8.411004159825097e-08]\n",
      "['i', 'hren']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.7605643399274413e-07\n",
      "-- Target Rank:  15508\n",
      "-- Target Entropy:  5.844089031219482\n",
      "--------------------------\n",
      "Target token: Traum\n",
      "token_idx: 36011\n",
      "--------------------------\n",
      "Target token: beruf\n",
      "token_idx: 12798\n",
      "maskP [2.1354069303924916e-06, 3.017386006831657e-06]\n",
      "['Traum', 'beruf']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.5763964686120744e-06\n",
      "-- Target Rank:  8053\n",
      "-- Target Entropy:  6.471027374267578\n",
      "--------------------------\n",
      "Target token: aus\n",
      "token_idx: 481\n",
      "--------------------------\n",
      "Target token: Ã¼ben\n",
      "token_idx: 3545\n",
      "maskP [1.0192177796852775e-05, 5.571969552420342e-09]\n",
      "['aus', 'Ã¼ben']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.098874883202598e-06\n",
      "-- Target Rank:  2102\n",
      "-- Target Entropy:  4.754831314086914\n",
      "--------------------------\n",
      "Target token: was\n",
      "token_idx: 2563\n",
      "maskP [3.91185749322176e-05]\n",
      "['was']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.91185749322176e-05\n",
      "-- Target Rank:  1391\n",
      "-- Target Entropy:  5.562985420227051\n",
      "--------------------------\n",
      "Target token: eine\n",
      "token_idx: 580\n",
      "maskP [1.1489289519772683e-08]\n",
      "['eine']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.1489289519772683e-08\n",
      "-- Target Rank:  33471\n",
      "-- Target Entropy:  4.9353742599487305\n",
      "--------------------------\n",
      "Target token: Frau\n",
      "token_idx: 9918\n",
      "maskP [1.554971390760329e-06]\n",
      "['Frau']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.554971390760329e-06\n",
      "-- Target Rank:  15891\n",
      "-- Target Entropy:  7.5555853843688965\n",
      "--------------------------\n",
      "Target token: tun\n",
      "token_idx: 32349\n",
      "maskP [7.947207336655993e-07]\n",
      "['tun']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.947207336655993e-07\n",
      "-- Target Rank:  5222\n",
      "-- Target Entropy:  4.85538387298584\n",
      "--------------------------\n",
      "Target token: m\n",
      "token_idx: 81\n",
      "--------------------------\n",
      "Target token: uss\n",
      "token_idx: 592\n",
      "--------------------------\n",
      "Target token: ,\n",
      "token_idx: 16\n",
      "maskP [1.3135758308635559e-05, 1.1184709336475862e-07, 0.00876571610569954]\n",
      "['m', 'uss', ',']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0029263212370338465\n",
      "-- Target Rank:  11\n",
      "-- Target Entropy:  2.21112322807312\n",
      "--------------------------\n",
      "Target token: ist\n",
      "token_idx: 510\n",
      "maskP [0.00010154780466109514]\n",
      "['ist']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.00010154780466109514\n",
      "-- Target Rank:  246\n",
      "-- Target Entropy:  2.4088499546051025\n",
      "--------------------------\n",
      "Target token: ihre\n",
      "token_idx: 44188\n",
      "maskP [1.5577485328321927e-06]\n",
      "['ihre']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.5577485328321927e-06\n",
      "-- Target Rank:  7433\n",
      "-- Target Entropy:  5.18226957321167\n",
      "--------------------------\n",
      "Target token: W\n",
      "token_idx: 59\n",
      "--------------------------\n",
      "Target token: Ã¼n\n",
      "token_idx: 3545\n",
      "--------------------------\n",
      "Target token: sche\n",
      "token_idx: 893\n",
      "maskP [1.2569755654112669e-06, 3.8014469794234174e-08, 2.670594234643886e-08]\n",
      "['W', 'Ã¼n', 'sche']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.405653258506466e-07\n",
      "-- Target Rank:  10293\n",
      "-- Target Entropy:  6.32054328918457\n",
      "--------------------------\n",
      "Target token: zu\n",
      "token_idx: 636\n",
      "maskP [4.027442628284916e-05]\n",
      "['zu']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.027442628284916e-05\n",
      "-- Target Rank:  616\n",
      "-- Target Entropy:  3.216317892074585\n",
      "--------------------------\n",
      "Target token: be\n",
      "token_idx: 518\n",
      "--------------------------\n",
      "Target token: fried\n",
      "token_idx: 5911\n",
      "--------------------------\n",
      "Target token: igen\n",
      "token_idx: 565\n",
      "maskP [1.4738997151653166e-06, 1.9989329302916303e-08, 2.259047349184584e-08]\n",
      "['be', 'fried', 'igen']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.054931726533596e-07\n",
      "-- Target Rank:  1632\n",
      "-- Target Entropy:  1.7098113298416138\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [1.113569214794552e-05]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.113569214794552e-05\n",
      "-- Target Rank:  3438\n",
      "-- Target Entropy:  5.121635913848877\n",
      "--------------------------\n",
      "Target token: im\n",
      "token_idx: 487\n",
      "maskP [1.0252950914946268e-06]\n",
      "['im']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.0252950914946268e-06\n",
      "-- Target Rank:  12206\n",
      "-- Target Entropy:  6.327621936798096\n",
      "--------------------------\n",
      "Target token: Schnitt\n",
      "token_idx: 28853\n",
      "maskP [5.544456271877607e-08]\n",
      "['Schnitt']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.544456271877607e-08\n",
      "-- Target Rank:  24495\n",
      "-- Target Entropy:  6.176450729370117\n",
      "--------------------------\n",
      "Target token: bi\n",
      "token_idx: 3940\n",
      "--------------------------\n",
      "Target token: ologisch\n",
      "token_idx: 9932\n",
      "maskP [9.409579604380269e-08, 6.1103508919302385e-09]\n",
      "['bi', 'ologisch']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.0103073467866466e-08\n",
      "-- Target Rank:  14085\n",
      "-- Target Entropy:  5.50021505355835\n",
      "--------------------------\n",
      "Target token: in\n",
      "token_idx: 269\n",
      "--------------------------\n",
      "Target token: telligen\n",
      "token_idx: 8593\n",
      "--------------------------\n",
      "Target token: ter\n",
      "token_idx: 314\n",
      "maskP [1.421696288161911e-05, 9.804868028595592e-09, 4.890902118859231e-07]\n",
      "['in', 'telligen', 'ter']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.9052859871778765e-06\n",
      "-- Target Rank:  1516\n",
      "-- Target Entropy:  5.008700847625732\n",
      "--------------------------\n",
      "Target token: F\n",
      "token_idx: 42\n",
      "--------------------------\n",
      "Target token: emin\n",
      "token_idx: 5432\n",
      "--------------------------\n",
      "Target token: istinnen\n",
      "token_idx: 45661\n",
      "maskP [4.73470936412923e-06, 5.058425927018106e-07, 9.268192258105046e-08]\n",
      "['F', 'emin', 'istinnen']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.777744626470697e-06\n",
      "-- Target Rank:  10808\n",
      "-- Target Entropy:  7.546823501586914\n",
      "--------------------------\n",
      "Target token: sind\n",
      "token_idx: 25513\n",
      "maskP [7.13920690031955e-06]\n",
      "['sind']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.13920690031955e-06\n",
      "-- Target Rank:  2503\n",
      "-- Target Entropy:  5.027660369873047\n",
      "--------------------------\n",
      "Target token: Hel\n",
      "token_idx: 8917\n",
      "--------------------------\n",
      "Target token: den\n",
      "token_idx: 324\n",
      "maskP [3.062752682581049e-07, 3.4575127756397706e-06]\n",
      "['Hel', 'den']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.8818940219489377e-06\n",
      "-- Target Rank:  6131\n",
      "-- Target Entropy:  6.184911727905273\n",
      "--------------------------\n",
      "Target token: und\n",
      "token_idx: 283\n",
      "maskP [0.0001188469905173406]\n",
      "['und']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0001188469905173406\n",
      "-- Target Rank:  974\n",
      "-- Target Entropy:  6.83012056350708\n",
      "--------------------------\n",
      "Target token: zu\n",
      "token_idx: 636\n",
      "maskP [5.066930498287547e-06]\n",
      "['zu']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.066930498287547e-06\n",
      "-- Target Rank:  325\n",
      "-- Target Entropy:  0.5443810224533081\n",
      "--------------------------\n",
      "Target token: eine\n",
      "token_idx: 580\n",
      "maskP [6.157127359074366e-07]\n",
      "['eine']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.157127359074366e-07\n",
      "-- Target Rank:  8959\n",
      "-- Target Entropy:  6.304701328277588\n",
      "--------------------------\n",
      "Target token: er\n",
      "token_idx: 261\n",
      "--------------------------\n",
      "Target token: zieher\n",
      "token_idx: 13873\n",
      "--------------------------\n",
      "Target token: ische\n",
      "token_idx: 523\n",
      "maskP [1.390558736602543e-06, 2.212958705172241e-09, 7.470317768820678e-07]\n",
      "['er', 'zieher', 'ische']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.13267824063261e-07\n",
      "-- Target Rank:  12419\n",
      "-- Target Entropy:  6.818264961242676\n",
      "--------------------------\n",
      "Target token: O\n",
      "token_idx: 51\n",
      "--------------------------\n",
      "Target token: hr\n",
      "token_idx: 302\n",
      "--------------------------\n",
      "Target token: f\n",
      "token_idx: 74\n",
      "--------------------------\n",
      "Target token: eige\n",
      "token_idx: 6793\n",
      "maskP [1.0277740329911467e-06, 8.467176115800612e-08, 3.00219539894897e-07, 1.0694804070121577e-10]\n",
      "['O', 'hr', 'f', 'eige']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.5319307052118776e-07\n",
      "-- Target Rank:  5761\n",
      "-- Target Entropy:  4.730504512786865\n",
      "--------------------------\n",
      "Target token: hat\n",
      "token_idx: 8491\n",
      "maskP [6.838382304863444e-09]\n",
      "['hat']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.838382304863444e-09\n",
      "-- Target Rank:  19622\n",
      "-- Target Entropy:  3.796225070953369\n",
      "--------------------------\n",
      "Target token: noch\n",
      "token_idx: 23060\n",
      "maskP [9.246441550203599e-07]\n",
      "['noch']\n",
      "-- Target Probability (mean of probabilities in maskP):  9.246441550203599e-07\n",
      "-- Target Rank:  8954\n",
      "-- Target Entropy:  4.6533050537109375\n",
      "--------------------------\n",
      "Target token: nie\n",
      "token_idx: 12049\n",
      "--------------------------\n",
      "Target token: mand\n",
      "token_idx: 3872\n",
      "maskP [7.17778107173217e-07, 2.984835134611785e-08]\n",
      "['nie', 'mand']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.738132292596674e-07\n",
      "-- Target Rank:  5734\n",
      "-- Target Entropy:  3.3978464603424072\n",
      "--------------------------\n",
      "Target token: gesch\n",
      "token_idx: 877\n",
      "--------------------------\n",
      "Target token: adet\n",
      "token_idx: 16467\n",
      "--------------------------\n",
      "Target token: ,\n",
      "token_idx: 16\n",
      "maskP [5.338045525604684e-07, 3.199913251039632e-11, 0.003405342111364007]\n",
      "['gesch', 'adet', ',']\n",
      "-- Target Probability (mean of probabilities in maskP):  0.0011352919826385667\n",
      "-- Target Rank:  30\n",
      "-- Target Entropy:  3.912403106689453\n",
      "--------------------------\n",
      "Target token: auch\n",
      "token_idx: 4564\n",
      "maskP [5.022525783715537e-06]\n",
      "['auch']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.022525783715537e-06\n",
      "-- Target Rank:  2559\n",
      "-- Target Entropy:  4.696900367736816\n",
      "--------------------------\n",
      "Target token: nicht\n",
      "token_idx: 7272\n",
      "maskP [2.8303531507845037e-05]\n",
      "['nicht']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.8303531507845037e-05\n",
      "-- Target Rank:  516\n",
      "-- Target Entropy:  2.889519453048706\n",
      "--------------------------\n",
      "Target token: M\n",
      "token_idx: 49\n",
      "--------------------------\n",
      "Target token: ick\n",
      "token_idx: 598\n",
      "--------------------------\n",
      "Target token: ey\n",
      "token_idx: 1903\n",
      "maskP [6.163981680629149e-08, 7.435067317373978e-08, 1.2262322712786045e-08]\n",
      "['M', 'ick', 'ey']\n",
      "-- Target Probability (mean of probabilities in maskP):  4.9417604230939105e-08\n",
      "-- Target Rank:  21174\n",
      "-- Target Entropy:  4.948810577392578\n",
      "--------------------------\n",
      "Target token: Mo\n",
      "token_idx: 6832\n",
      "--------------------------\n",
      "Target token: use\n",
      "token_idx: 2691\n",
      "maskP [7.0751002567703836e-06, 1.3405521137599408e-10]\n",
      "['Mo', 'use']\n",
      "-- Target Probability (mean of probabilities in maskP):  3.5376171559908798e-06\n",
      "-- Target Rank:  2440\n",
      "-- Target Entropy:  4.043788433074951\n",
      "--------------------------\n",
      "Target token: akt\n",
      "token_idx: 2301\n",
      "--------------------------\n",
      "Target token: uelle\n",
      "token_idx: 2358\n",
      "maskP [1.2939662155986298e-05, 2.662000326836278e-07]\n",
      "['akt', 'uelle']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.602931094334963e-06\n",
      "-- Target Rank:  8332\n",
      "-- Target Entropy:  8.252379417419434\n",
      "--------------------------\n",
      "Target token: D\n",
      "token_idx: 40\n",
      "--------------------------\n",
      "Target token: rang\n",
      "token_idx: 4302\n",
      "maskP [1.2862300025062723e-07, 9.864533190295788e-09]\n",
      "['D', 'rang']\n",
      "-- Target Probability (mean of probabilities in maskP):  6.924376672046151e-08\n",
      "-- Target Rank:  22246\n",
      "-- Target Entropy:  7.080994129180908\n",
      "--------------------------\n",
      "Target token: zur\n",
      "token_idx: 5230\n",
      "maskP [7.602123332617339e-06]\n",
      "['zur']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.602123332617339e-06\n",
      "-- Target Rank:  1594\n",
      "-- Target Entropy:  2.9606897830963135\n",
      "--------------------------\n",
      "Target token: Em\n",
      "token_idx: 7577\n",
      "--------------------------\n",
      "Target token: anzip\n",
      "token_idx: 35836\n",
      "--------------------------\n",
      "Target token: ation\n",
      "token_idx: 457\n",
      "maskP [4.5266961024026386e-07, 1.1814179146085735e-07, 2.497134232726239e-07]\n",
      "['Em', 'anzip', 'ation']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.7350827499124836e-07\n",
      "-- Target Rank:  15611\n",
      "-- Target Entropy:  7.016139507293701\n",
      "--------------------------\n",
      "Target token: schlÃ¤gt\n",
      "token_idx: 642\n",
      "maskP [1.5949022724726092e-07]\n",
      "['schlÃ¤gt']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.5949022724726092e-07\n",
      "-- Target Rank:  10851\n",
      "-- Target Entropy:  4.64223575592041\n",
      "--------------------------\n",
      "Target token: teil\n",
      "token_idx: 814\n",
      "--------------------------\n",
      "Target token: weise\n",
      "token_idx: 1031\n",
      "maskP [5.468327568536324e-09, 3.125547607396584e-07]\n",
      "['teil', 'weise']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.5901154415409735e-07\n",
      "-- Target Rank:  7930\n",
      "-- Target Entropy:  3.521960735321045\n",
      "--------------------------\n",
      "Target token: um\n",
      "token_idx: 335\n",
      "maskP [1.1153027116961312e-05]\n",
      "['um']\n",
      "-- Target Probability (mean of probabilities in maskP):  1.1153027116961312e-05\n",
      "-- Target Rank:  1482\n",
      "-- Target Entropy:  3.9714314937591553\n",
      "--------------------------\n",
      "Target token: in\n",
      "token_idx: 269\n",
      "maskP [2.962539156214916e-06]\n",
      "['in']\n",
      "-- Target Probability (mean of probabilities in maskP):  2.962539156214916e-06\n",
      "-- Target Rank:  539\n",
      "-- Target Entropy:  1.7674888372421265\n",
      "--------------------------\n",
      "Target token: eine\n",
      "token_idx: 580\n",
      "maskP [7.809237104083877e-06]\n",
      "['eine']\n",
      "-- Target Probability (mean of probabilities in maskP):  7.809237104083877e-06\n",
      "-- Target Rank:  4836\n",
      "-- Target Entropy:  4.868663311004639\n",
      "--------------------------\n",
      "Target token: R\n",
      "token_idx: 54\n",
      "--------------------------\n",
      "Target token: achs\n",
      "token_idx: 11478\n",
      "--------------------------\n",
      "Target token: ucht\n",
      "token_idx: 1037\n",
      "maskP [1.4783638562221313e-06, 3.34285643610599e-09, 1.6251823353741202e-07]\n",
      "['R', 'achs', 'ucht']\n",
      "-- Target Probability (mean of probabilities in maskP):  5.480749820652164e-07\n",
      "-- Target Rank:  10705\n",
      "-- Target Entropy:  7.1875996589660645\n",
      "[7.831689799786545e-06, 5.625740868708817e-06, 3.6563696913932686e-08, 1.3239878361067288e-06, 6.185987866206647e-07, 1.4102917702984996e-05, 1.7543266039865557e-07, 2.4259602326992535e-08, 1.3353883332456462e-07, 2.41522933208671e-06, 4.0617314880364574e-06, 2.0757969685369915e-06, 7.831689799786545e-06, 2.638220621520304e-06, 3.832284445337564e-08, 9.931424074238748e-07, 0.0005106838652864099, 1.009559593967424e-05, 5.345217835017735e-08, 1.822675585572142e-05, 1.6411373593427925e-08, 2.7534313176147407e-06, 4.510748774499973e-09, 3.318907033644791e-07, 2.601173400762491e-05, 1.6237707995969686e-06, 1.4102917702984996e-05, 2.7128726287628524e-06, 6.874789164612594e-07, 7.742103472097028e-06, 0.0001698968990240246, 1.1725013848717936e-07, 1.4102917702984996e-05, 1.1230848275071519e-06, 2.453642480304552e-06, 3.7152585719013587e-07, 1.7512987030343652e-05, 2.427760534828849e-07, 1.82878190668756e-06, 1.4102917702984996e-05, 1.0471408581717394e-06, 0.002466177800670266, 2.721939608818502e-06, 3.0473487640847452e-05, 0.0002068869798677042, 1.005376070395414e-06, 3.1595422456121014e-07, 9.319031960330904e-06, 1.6589552842560806e-06, 1.949281568158767e-06, 4.277346063286114e-06, 9.449256310745113e-08, 1.8839089534594677e-05, 4.526453434294808e-09, 2.642857186430092e-07, 1.6954945289171518e-05, 4.15797985624522e-05, 9.916040610846721e-08, 3.067293759547359e-05, 7.354933131864527e-06, 5.578300526942748e-06, 0.011696168221533298, 5.447235162137076e-05, 1.1141091817989945e-05, 1.8449808294462855e-06, 9.043454156199005e-06, 2.0109152956138132e-06, 1.7444240686614876e-05, 8.489974788972177e-06, 2.2743841299188716e-07, 3.851891061668056e-08, 2.1080033548059873e-05, 3.566638847966412e-07, 4.858616193814669e-06, 7.279465080500813e-06, 2.6409712149177977e-05, 1.2700539627985563e-05, 1.7026316072588088e-06, 0.0011234113480895758, 3.5435539302852703e-06, 6.710987285885039e-07, 1.00915235160907e-06, 1.525927359580237e-06, 1.9613858967204578e-05, 3.2214135359254215e-08, 3.725527221831726e-06, 9.095718382923224e-07, 2.141969002877886e-05, 1.4102917702984996e-05, 4.3660270421241876e-06, 1.2366786403816832e-06, 1.2867916938663626e-06, 5.7311830460093915e-05, 2.1365435109998998e-05, 0.0015312677714973688, 1.6270951554986368e-06, 1.218593206431251e-05, 0.0013318692799657583, 1.0963909273797867e-06, 0.000297313992632553, 7.406004442600533e-05, 0.0012834107037633657, 3.878858115058392e-05, 3.1955267473904314e-05, 1.4797471521887928e-05, 2.483011896980969e-05, 1.2069908450484945e-07, 5.1102275980263734e-08, 0.00010706575267249718, 3.716025730682304e-06, 5.496704034158029e-05, 2.0915276763844304e-06, 3.067293759547359e-05, 6.556603239005199e-06, 1.6185097351240074e-07, 9.770411766677849e-08, 3.950671136010442e-06, 3.91185749322176e-05, 1.1489289519772683e-08, 1.554971390760329e-06, 7.947207336655993e-07, 0.0029263212370338465, 0.00010154780466109514, 3.3639932812690176e-06, 1.0377563739893958e-05, 8.30435601528734e-06, 6.56542640327847e-07, 6.601790119020734e-06, 6.735940569768673e-07, 8.394610340189956e-09, 2.254893843200989e-06, 2.1962476504100437e-08, 1.4408567949431017e-05, 0.00019128876738250256, 4.241257101966767e-06, 3.0457544198725373e-05, 2.404225247924311e-06, 0.0002068869798677042, 1.0797035656651133e-06, 3.4387085179332644e-07, 6.0678169120365055e-06, 4.8899011744651943e-05, 1.4102917702984996e-05, 4.32030037700315e-06, 5.971220744527272e-07, 6.249639409361407e-05, 1.5158161448998915e-06, 1.163505748991156e-05, 8.628344971839397e-07, 1.2940977285325062e-06, 7.008581451373175e-05, 2.8711936010950012e-06, 1.6118157475375483e-05, 4.3170020944671705e-06, 1.7520284245620132e-06, 1.6062033409980359e-06, 1.048709465933939e-06, 0.0002434443449601531, 5.478009370563086e-07, 5.27404353078964e-07, 4.2121869171296566e-05, 1.9279737898614258e-05, 0.0008044786302434659, 0.0005534907686524093, 4.713838279712945e-06, 2.0582383513101377e-05, 2.055329453298782e-07, 5.124989570504113e-07, 4.5855717331733103e-05, 2.1616770595755952e-07, 5.353168035071576e-06, 2.644053687106407e-07, 8.194493602786679e-06, 1.734362653493804e-07, 3.3395928500379313e-06, 3.56867360551405e-07, 2.4575201678089797e-05, 0.00011227431969018653, 1.5088551563735564e-07, 3.467204476859109e-07, 1.2503109246608801e-05, 6.8708895923919044e-06, 7.828811249055434e-06, 0.0004014559817733243, 5.917432322477545e-06, 4.594248366629472e-06, 1.0953985629669205e-07, 9.561787164713564e-06, 1.2100063031539321e-05, 6.24128919871995e-06, 4.0253245970234275e-05, 6.897364060454159e-08, 2.9718012228840962e-05, 3.474124241620302e-06, 3.5737404687097296e-05, 1.8771273744278005e-06, 0.000767977093346417, 5.9567832977336366e-06, 5.971529049020319e-07, 1.8994316519638232e-07, 1.0797582945087925e-05, 2.257397625271551e-06, 5.817049453238354e-08, 1.082237005789466e-06, 7.56658415923539e-08, 7.621625286446942e-08, 1.4408567949431017e-05, 0.00019128876738250256, 4.241257101966767e-06, 1.9285398593638092e-05, 5.431848421721952e-06, 3.2346592604426405e-07, 1.004317709885072e-05, 1.047369664775033e-06, 1.5635214841343745e-07, 1.4102917702984996e-05, 2.1732619188696845e-06, 2.882404732673649e-06, 2.4994523339927355e-08, 7.831689799786545e-06, 1.859804577009072e-08, 6.5618532469058355e-06, 3.6318929232947994e-06, 1.6369401531490801e-07, 1.9690206443101488e-07, 6.0280344769125804e-05, 4.2320425913677795e-07, 3.635946995927952e-05, 1.6542059029234224e-06, 2.7457652322482318e-05, 1.4102917702984996e-05, 2.7128726287628524e-06, 6.874789164612594e-07, 4.897901906275592e-07, 2.0002584278699942e-05, 2.821468854108389e-07, 1.665290074015502e-05, 8.439967658091518e-08, 3.606598129405706e-08, 2.2608055800787952e-05, 2.1256248146528378e-05, 1.0677664477043436e-06, 4.988445425624377e-07, 1.7195509371958906e-06, 1.4153350491596939e-06, 0.0002068869798677042, 1.714686914056074e-05, 3.0216639856917027e-07, 3.7201294844635413e-07, 2.0319650957389968e-06, 5.157278792466968e-06, 1.7100452168961056e-05, 0.0009962355510911246, 1.4959896361688152e-06, 1.585452196195547e-07, 3.0347543997777393e-06, 1.6428324926209825e-05, 9.625937309465371e-06, 1.1476966466084093e-07, 'warning', 6.98681834609971e-10, 1.5285149383241028e-07, 3.538032615324482e-05, 1.1457062134567764e-06, 1.113569214794552e-05, 4.77151019140365e-07, 1.113569214794552e-05, 5.083318953325033e-06, 2.4439859771518968e-05, 1.4300333361916273e-07, 1.113569214794552e-05, 1.2959835942183418e-06, 5.260816124064149e-06, 5.4793254093965515e-06, 3.383420050795394e-07, 'warning', 7.126290668679758e-10, 1.0325219039764022e-06, 1.113569214794552e-05, 3.3912060644070152e-06, 2.007478178711608e-05, 2.797518590114123e-07, 3.9983792703424115e-06, 1.7394617384998885e-06, 7.049495707178721e-07, 8.296269697893877e-06, 0.00010227308666799217, 3.5727518934436375e-06, 2.1584877686109394e-05, 1.2888307310277014e-07, 1.113569214794552e-05, 1.1866711702168686e-06, 3.961185459052293e-06, 4.161717311509013e-08, 8.042936087804264e-06, 4.575812262430645e-08, 9.332296940556262e-06, 7.285050287464401e-06, 1.9167088503024843e-06, 4.705805753957293e-07, 3.383420050795394e-07, 2.0174926248728298e-05, 6.454183645606311e-06, 1.1241967712294354e-07, 8.21897799596627e-07, 2.556357685534749e-06, 3.603875148305846e-08, 2.2811605807267674e-06, 2.921096529477178e-07, 4.994048595108325e-06, 3.080128578858421e-07, 1.1526776866332966e-08, 1.5765699856729043e-07, 4.462691293838361e-06, 1.1958534287259681e-06, 1.6657937944586365e-06, 1.9426937797106802e-05, 7.852920020923193e-07, 4.755170124326469e-08, 1.8783466657623649e-06, 0.00027650431729853153, 4.391095785649668e-06, 5.15757015984164e-08, 1.2475507901399396e-05, 3.41149011262587e-08, 1.0020301033364376e-06, 9.444385273837952e-09, 2.4510339358130295e-07, 3.30207149090711e-05, 4.166309281572467e-06, 1.7133075971287326e-06, 4.4459363834903343e-07, 5.764546244790836e-07, 3.9416212960219354e-06, 0.00029050675220787525, 1.11836274611458e-07, 4.202533716579637e-07, 8.465207770314009e-07, 2.707582357430738e-06, 3.5030987532991276e-07, 4.6926253432388876e-05, 8.194394141014527e-08, 1.057250358260653e-06, 'warning', 4.2536743571908175e-10, 3.649462646156583e-07, 0.00032141152769327164, 3.935133463528473e-07, 4.3260495837434593e-07, 1.1040647223126143e-05, 1.2931000323845865e-06, 2.9355621222748596e-07, 1.0917135114141274e-05, 1.598145900061354e-06, 1.2312156485450032e-06, 3.817412306261758e-07, 2.867173520826327e-08, 3.9606493373867124e-05, 7.34273486457937e-09, 1.3719966496239522e-07, 1.6701252485606944e-05, 0.00034741044510155916, 1.3758295776729787e-07, 0.002382866626793619, 4.968638677382842e-06, 2.202426792191625e-06, 0.005258566699922085, 2.122176010743715e-05, 2.964513669212465e-06, 2.8523099899757653e-06, 5.411702659330331e-06, 1.709180764919438e-06, 9.48450155924263e-06, 3.6255589748179773e-06, 2.4068533832632966e-07, 8.620347632937175e-08, 5.813081588712521e-05, 3.028241047549803e-07, 8.863157319183301e-09, 3.4076245469805144e-07, 0.00041757025085331634, 1.6148549164540782e-08, 3.002529638251872e-06, 0.001170689589343965, 6.564474830383915e-08, 8.354015119493852e-05, 3.2129359481963826e-08, 5.5245418479898944e-06, 3.8817976019345224e-05, 4.1293512254014786e-07, 4.228091256663902e-06, 5.323198024598241e-07, 7.065734519073885e-05, 'warning', 4.736541714400744e-10, 2.2877622996020364e-06, 7.709167348934898e-07, 8.089204763805924e-07, 9.943701115844306e-06, 6.619876627667054e-05, 0.0015312677714973688, 1.6270951554986368e-06, 4.37940707342932e-06, 1.4302418207989831e-05, 3.85652081114074e-06, 0.0007648789905942976, 0.00020662668976001441, 2.679622957657557e-05, 7.015924950337649e-06, 2.9176489988458343e-06, 1.2656340565464497e-05, 1.3398979170631264e-07, 1.0745712009097019e-07, 5.142229611010407e-07, 6.223276614036877e-07, 1.3347602362046018e-05, 2.3225118184200255e-06, 4.482267161639205e-05, 8.97347490536049e-07, 4.6797801189768506e-08, 1.7771505748479893e-08, 9.75111889900404e-07, 3.91185749322176e-05, 6.299894153016794e-07, 1.47993171140115e-06, 1.5558505765511654e-05, 0.005580499766210778, 5.588410931522958e-05, 2.9699083370360313e-07, 1.9243146232028607e-07, 7.72022976889275e-05, 1.85151477597086e-05, 7.831689799786545e-06, 5.625740868708817e-06, 3.6563696913932686e-08, 2.4752971938823976e-07, 6.010373823528425e-06, 'warning', 1.4102917702984996e-05, 1.7543266039865557e-07, 5.843085570944595e-09, 6.663012243279809e-06, 6.906867383804638e-06, 1.9423675414742547e-06, 7.831689799786545e-06, 2.638220621520304e-06, 3.832284445337564e-08, 9.931424074238748e-07, 7.759033178444952e-05, 2.9336063107621158e-06, 1.1252095987401844e-05, 3.0152879304523594e-08, 1.822675585572142e-05, 1.6411373593427925e-08, 2.7534313176147407e-06, 2.1713596753958342e-07, 7.007906219769211e-07, 3.45160806318745e-05, 1.4266386187955504e-06, 1.4102917702984996e-05, 2.7128726287628524e-06, 6.874789164612594e-07, 1.0718623343564104e-05, 5.914442226639949e-06, 1.1958778713960783e-06, 1.4102917702984996e-05, 1.1230848275071519e-06, 4.340690793469548e-06, 4.008842549986745e-06, 6.621742631995886e-08, 1.4102917702984996e-05, 5.22477577646896e-07, 8.917517334339209e-06, 3.915167425816435e-06, 2.3859030989115126e-05, 0.0002068869798677042, 2.8435428589546063e-07, 1.0075007139676018e-07, 7.241234243338113e-07, 4.7668154365965165e-06, 1.304197412288488e-07, 2.1555795683525503e-05, 6.710201461146426e-08, 2.2611242457060143e-05, 1.8242786836708547e-08, 3.7628930193989163e-07, 1.6954945289171518e-05, 4.15797985624522e-05, 4.0081369689914936e-07, 3.067293759547359e-05, 4.026684837299399e-05, 1.3740539543505292e-05, 4.814652765139371e-06, 0.0030260873027145863, 2.4453333026031032e-05, 1.0769183973025065e-05, 2.4229368591477396e-06, 0.00014160673890728503, 7.188889128428855e-08, 7.870982255298031e-06, 8.489974788972177e-06, 2.2743841299188716e-07, 3.851891061668056e-08, 2.1080033548059873e-05, 2.995367716918107e-07, 'warning', 2.041726787638254e-10, 2.6179970973316813e-06, 2.03364055053612e-05, 2.1112701631409436e-07, 2.368637069594115e-05, 0.0002461853146087378, 6.765327725588577e-06, 1.0851469767203525e-07, 8.752493639481903e-07, 1.6720990743124275e-06, 3.688284050440416e-05, 2.5369129019736647e-08, 1.6668782336637378e-06, 3.708400413415802e-07, 1.9817875795524742e-05, 1.4102917702984996e-05, 4.3660270421241876e-06, 7.368565547949402e-06, 6.025647181218119e-08, 1.9892745228844433e-07, 3.877581377764727e-06, 0.0015312677714973688, 1.6270951554986368e-06, 1.218593206431251e-05, 0.0005760818021371961, 8.88833042722581e-08, 2.6969701139023528e-05, 2.2957212308938324e-07, 0.0012834107037633657, 3.878858115058392e-05, 3.1955267473904314e-05, 1.4797471521887928e-05, 2.483011896980969e-05, 4.814769454242196e-06, 8.399085177357435e-10, 0.00010706575267249718, 3.716025730682304e-06, 5.496704034158029e-05, 4.150935950519852e-08, 3.067293759547359e-05, 3.7605643399274413e-07, 2.5763964686120744e-06, 5.098874883202598e-06, 3.91185749322176e-05, 1.1489289519772683e-08, 1.554971390760329e-06, 7.947207336655993e-07, 0.0029263212370338465, 0.00010154780466109514, 1.5577485328321927e-06, 4.405653258506466e-07, 4.027442628284916e-05, 5.054931726533596e-07, 1.113569214794552e-05, 1.0252950914946268e-06, 5.544456271877607e-08, 5.0103073467866466e-08, 4.9052859871778765e-06, 1.777744626470697e-06, 7.13920690031955e-06, 1.8818940219489377e-06, 0.0001188469905173406, 5.066930498287547e-06, 6.157127359074366e-07, 7.13267824063261e-07, 3.5319307052118776e-07, 6.838382304863444e-09, 9.246441550203599e-07, 3.738132292596674e-07, 0.0011352919826385667, 5.022525783715537e-06, 2.8303531507845037e-05, 4.9417604230939105e-08, 3.5376171559908798e-06, 6.602931094334963e-06, 6.924376672046151e-08, 7.602123332617339e-06, 2.7350827499124836e-07, 1.5949022724726092e-07, 1.5901154415409735e-07, 1.1153027116961312e-05, 2.962539156214916e-06, 7.809237104083877e-06, 5.480749820652164e-07]\n"
     ]
    }
   ],
   "source": [
    "scores, ranks, entropy_list, attention_list, input_text_list = get_gpt_predictions(masked_sentence_list, label_list, vocabulary=None)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloze_df['probability'] = scores\n",
    "cloze_df['ranks'] = ranks\n",
    "cloze_df['entropy'] = entropy_list\n",
    "#cloze_df['attention'] = attention_list\n",
    "cloze_df['inputtext'] = input_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloze_df.to_csv('processed_data/gpt_cloze_probabilities.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sno</th>\n",
       "      <th>Ino</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentence</th>\n",
       "      <th>masked_token</th>\n",
       "      <th>probability</th>\n",
       "      <th>ranks</th>\n",
       "      <th>entropy</th>\n",
       "      <th>inputtext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>[Der, aktuelle, Drang, zur, Emanzipation, schl...</td>\n",
       "      <td>Der</td>\n",
       "      <td>aktuelle</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>8331</td>\n",
       "      <td>8.252378</td>\n",
       "      <td>[Der]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>[Der, aktuelle, Drang, zur, Emanzipation, schl...</td>\n",
       "      <td>Der aktuelle</td>\n",
       "      <td>Drang</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22247</td>\n",
       "      <td>7.080990</td>\n",
       "      <td>[Der, Ġaktuelle]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>[Der, aktuelle, Drang, zur, Emanzipation, schl...</td>\n",
       "      <td>Der aktuelle Drang</td>\n",
       "      <td>zur</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1594</td>\n",
       "      <td>2.960689</td>\n",
       "      <td>[Der, Ġaktuelle, ĠDr, ang]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>97</td>\n",
       "      <td>3</td>\n",
       "      <td>[Der, aktuelle, Drang, zur, Emanzipation, schl...</td>\n",
       "      <td>Der aktuelle Drang zur</td>\n",
       "      <td>Emanzipation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15611</td>\n",
       "      <td>7.016135</td>\n",
       "      <td>[Der, Ġaktuelle, ĠDr, ang, Ġzur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>97</td>\n",
       "      <td>4</td>\n",
       "      <td>[Der, aktuelle, Drang, zur, Emanzipation, schl...</td>\n",
       "      <td>Der aktuelle Drang zur Emanzipation</td>\n",
       "      <td>schlägt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10851</td>\n",
       "      <td>4.642233</td>\n",
       "      <td>[Der, Ġaktuelle, ĠDr, ang, Ġzur, ĠEm, anzip, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>97</td>\n",
       "      <td>5</td>\n",
       "      <td>[Der, aktuelle, Drang, zur, Emanzipation, schl...</td>\n",
       "      <td>Der aktuelle Drang zur Emanzipation schlägt</td>\n",
       "      <td>teilweise</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7930</td>\n",
       "      <td>3.521955</td>\n",
       "      <td>[Der, Ġaktuelle, ĠDr, ang, Ġzur, ĠEm, anzip, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>97</td>\n",
       "      <td>6</td>\n",
       "      <td>[Der, aktuelle, Drang, zur, Emanzipation, schl...</td>\n",
       "      <td>Der aktuelle Drang zur Emanzipation schlägt te...</td>\n",
       "      <td>um</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1482</td>\n",
       "      <td>3.971430</td>\n",
       "      <td>[Der, Ġaktuelle, ĠDr, ang, Ġzur, ĠEm, anzip, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>97</td>\n",
       "      <td>7</td>\n",
       "      <td>[Der, aktuelle, Drang, zur, Emanzipation, schl...</td>\n",
       "      <td>Der aktuelle Drang zur Emanzipation schlägt te...</td>\n",
       "      <td>in</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>539</td>\n",
       "      <td>1.767482</td>\n",
       "      <td>[Der, Ġaktuelle, ĠDr, ang, Ġzur, ĠEm, anzip, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>97</td>\n",
       "      <td>8</td>\n",
       "      <td>[Der, aktuelle, Drang, zur, Emanzipation, schl...</td>\n",
       "      <td>Der aktuelle Drang zur Emanzipation schlägt te...</td>\n",
       "      <td>eine</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>4836</td>\n",
       "      <td>4.868682</td>\n",
       "      <td>[Der, Ġaktuelle, ĠDr, ang, Ġzur, ĠEm, anzip, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>97</td>\n",
       "      <td>9</td>\n",
       "      <td>[Der, aktuelle, Drang, zur, Emanzipation, schl...</td>\n",
       "      <td>Der aktuelle Drang zur Emanzipation schlägt te...</td>\n",
       "      <td>Rachsucht</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10705</td>\n",
       "      <td>7.187602</td>\n",
       "      <td>[Der, Ġaktuelle, ĠDr, ang, Ġzur, ĠEm, anzip, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sno Ino                                             tokens  \\\n",
       "580  97   0  [Der, aktuelle, Drang, zur, Emanzipation, schl...   \n",
       "581  97   1  [Der, aktuelle, Drang, zur, Emanzipation, schl...   \n",
       "582  97   2  [Der, aktuelle, Drang, zur, Emanzipation, schl...   \n",
       "583  97   3  [Der, aktuelle, Drang, zur, Emanzipation, schl...   \n",
       "584  97   4  [Der, aktuelle, Drang, zur, Emanzipation, schl...   \n",
       "585  97   5  [Der, aktuelle, Drang, zur, Emanzipation, schl...   \n",
       "586  97   6  [Der, aktuelle, Drang, zur, Emanzipation, schl...   \n",
       "587  97   7  [Der, aktuelle, Drang, zur, Emanzipation, schl...   \n",
       "588  97   8  [Der, aktuelle, Drang, zur, Emanzipation, schl...   \n",
       "589  97   9  [Der, aktuelle, Drang, zur, Emanzipation, schl...   \n",
       "\n",
       "                                              sentence  masked_token  \\\n",
       "580                                                Der      aktuelle   \n",
       "581                                       Der aktuelle         Drang   \n",
       "582                                 Der aktuelle Drang           zur   \n",
       "583                             Der aktuelle Drang zur  Emanzipation   \n",
       "584                Der aktuelle Drang zur Emanzipation       schlägt   \n",
       "585        Der aktuelle Drang zur Emanzipation schlägt     teilweise   \n",
       "586  Der aktuelle Drang zur Emanzipation schlägt te...            um   \n",
       "587  Der aktuelle Drang zur Emanzipation schlägt te...            in   \n",
       "588  Der aktuelle Drang zur Emanzipation schlägt te...          eine   \n",
       "589  Der aktuelle Drang zur Emanzipation schlägt te...     Rachsucht   \n",
       "\n",
       "    probability  ranks   entropy  \\\n",
       "580    0.000007   8331  8.252378   \n",
       "581         0.0  22247  7.080990   \n",
       "582    0.000008   1594  2.960689   \n",
       "583         0.0  15611  7.016135   \n",
       "584         0.0  10851  4.642233   \n",
       "585         0.0   7930  3.521955   \n",
       "586    0.000011   1482  3.971430   \n",
       "587    0.000003    539  1.767482   \n",
       "588    0.000008   4836  4.868682   \n",
       "589    0.000001  10705  7.187602   \n",
       "\n",
       "                                             inputtext  \n",
       "580                                              [Der]  \n",
       "581                                   [Der, Ġaktuelle]  \n",
       "582                         [Der, Ġaktuelle, ĠDr, ang]  \n",
       "583                   [Der, Ġaktuelle, ĠDr, ang, Ġzur]  \n",
       "584  [Der, Ġaktuelle, ĠDr, ang, Ġzur, ĠEm, anzip, a...  \n",
       "585  [Der, Ġaktuelle, ĠDr, ang, Ġzur, ĠEm, anzip, a...  \n",
       "586  [Der, Ġaktuelle, ĠDr, ang, Ġzur, ĠEm, anzip, a...  \n",
       "587  [Der, Ġaktuelle, ĠDr, ang, Ġzur, ĠEm, anzip, a...  \n",
       "588  [Der, Ġaktuelle, ĠDr, ang, Ġzur, ĠEm, anzip, a...  \n",
       "589  [Der, Ġaktuelle, ĠDr, ang, Ġzur, ĠEm, anzip, a...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloze_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### add manipulated words info as columns\n",
    "grouped_df = cloze_df.groupby(['Sno' 'Ino'], dropna=False)\n",
    "\n",
    "\n",
    "for group_name in grouped_df.groups.keys(): # sample key : ('p1', 5)\n",
    "    print('Processing : ',group_name)\n",
    "    trial_df = grouped_df.get_group(group_name)\n",
    "    sen_score = trial_df.entropy.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
